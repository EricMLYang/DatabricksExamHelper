# Question 11

## Question
A data engineer has a PySpark DataFrame with the following columns: employee_name, department, and salary. They want to assign a tier to each employee within their department based on salary, where employees earning the same salary share the same tier. The expected output is as follows:








To achieve this, they define a window by department and order by salary in descending order:




`window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())`




Which of the following functions correctly use this window to calculate the tier column?

## Options
- A. df.withColumn("tier", percent_rank().over(window_spec)) 
- B. df.withColumn("tier", row_number().over(window_spec)) 
- C. df.withColumn("tier", rank().over(window_spec)) 
- D. df.withColumn("tier", dense_rank().over(window_spec)) (Correct)

## Explanation
The `dense_rank()` function assigns consecutive rank numbers based on the ordering within each department while ensuring that employees with the same salary receive the same rank or "tier".




Unlike `rank()`, which skips numbers after ties (e.g., 1, 1, 3), `dense_rank()` produces a continuous sequence (e.g., 1, 1, 2), matching the desired output. `row_number()` would give each row a unique rank even if salaries are the same, and `percent_rank()` would instead assign fractional values between 0 and 1 rather than integer tiers.




Therefore, `dense_rank()` is the appropriate function to correctly assign salary-based tiers within each department.
