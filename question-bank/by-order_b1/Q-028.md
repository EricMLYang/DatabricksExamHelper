# Question 28

## Question
A data engineer is tasked with designing an ETL pipeline with Lakeflow Declarative Pipelines to efficiently handle near real-time data ingestion. The goal is to incrementally process incoming data streams using Auto Loader, ensuring that the data pipeline can continuously capture and load new records as they arrive while maintaining high performance and reliability.




Given this requirement, the engineer needs to choose an appropriate type of object that can best support incremental, near real-time data ingestion and processing.




Which of the following objects would be most suitable for this specific use case?

## Options
- A. Materialized view 
- B. Temporary view 
- C. Streaming table (Correct)
- D. Live table 

## Explanation
For this use case, the most suitable object is a Streaming table. Streaming tables are designed to handle near real-time data ingestion and incremental processing, allowing Lakeflow Declarative Pipelines* to continuously capture and process new records as they arrive via Auto Loader, ensuring high performance and reliability. So, streaming tables specifically support continuous, real-time updates, making them ideal for pipelines that require up-to-the-moment data freshness.




While Materialized Views (formerly known as Live Tables) provide batch-oriented or scheduled incremental processing. Temporary views, in contrast, are ephemeral and not suited for persistent, incremental streaming workloads.




* Databricks has recenlty open-sourced this solution, integrating it into the Apache Spark ecosystem under the name Spark Declarative Pipelines (SDP).
