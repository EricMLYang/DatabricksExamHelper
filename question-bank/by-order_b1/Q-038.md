# Question 38

## Question
A data engineer is configuring the following CDC data processing using AUTO CDC APIs in Lakeflow Declarative Pipelines:



```
- CREATE FLOW cdc_flow AS AUTO CDC INTO silver_transactions
- FROM stream(bronze_transactions)
- KEYS (transaction_id)
- _________________________
- COLUMNS *
```





The engineer wants to define the processing order of source records and handle late-arriving data using a composite key of multiple columns, ordering by transaction_timestamp first, and in case of ties, by version_number.




Which option correctly fills in the blank to meet this requirement?

## Options
- A. SEQUENCE BY STRUCT (transaction_timestamp, version_number) (Correct)
- B. SEQUENCE BY (transaction_timestamp, version_number) 
- C. ORDER BY STRUCT (transaction_timestamp, version_number) 
- D. ORDER BY transaction_timestamp, version_number 

## Explanation
In Lakeflow Declarative Pipelines*, `SEQUENCE BY` is used to define the processing order for CDC streams, and using `STRUCT` allows specifying a composite key of multiple columns. This ensures that records are ordered first by transaction_timestamp and, in case of ties, by version_number, which also allows handling late-arriving data correctly.




* Databricks has recenlty open-sourced this solution, integrating it into the Apache Spark ecosystem under the name Spark Declarative Pipelines (SDP).
