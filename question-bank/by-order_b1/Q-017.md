# Question 17

## Question
A junior data engineer is testing the following code block to get the newest entry for each item added in the 'sales' table since the last table update.



```
- from pyspark.sql import functions as F
- from pyspark.sql.window import Window
-  
- window = Window.partitionBy("item_id").orderBy(F.col("item_time").desc())
-  
- ranked_df = (spark.readStream
-                     .table("sales")
-                     .withColumn("rank", F.rank().over(window))
-                     .filter("rank == 1")
-                     .drop("rank")
-             )
-  
- display(ranked_df)
```





However, the command fails when executed.




Which statement explains the cause of this failure?

## Options
- A. Non-time-based window operations are not supported on streaming DataFrames. They need to be implemented inside a foreachBatch logic instead. (Correct)
- B. The query output can not be displayed. They should use spark.writeStream to persist the query result. 
- C. The item_id field is not unique. Records must be de-duplicated on the item_id using dropDuplicates function 
- D. Watermarking is missing. It should be added to allow tracking state information for the window of time. 

## Explanation
If you try to call such a window operation on a streaming DataFrames, this will generate an error indicating that "Non-time-based window operations are not supported on streaming DataFrames".

Instead, these window operations need to be implemented inside a foreachBatch logic.




Study materials from our exam preparation course on Udemy:

Hands-on
