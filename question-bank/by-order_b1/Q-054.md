# Question 54

## Question
Given the following query on the Delta table 'customers' on which Change Data Feed is enabled:



```
- spark.readStream
-         .option("readChangeFeed", "true")
-         .option("startingVersion", 0)
-         .table("customers")
-         .filter(col("_change_type").isin(["update_postimage"]))
-     .writeStream
-         .option("checkpointLocation", "dbfs:/checkpoints")
-         .trigger (availableNow=True)
-         .table("customers_updates")
```





Which statement describes the results of this query each time it is executed ?

## Options
- A. Newly updated records will overwrite the target table. 
- B. The entire history of updated records will be appended to the target table at each execution, which leads to duplicate entries. 
- C. Newly updated records will be appended to the target table. (Correct)
- D. The entire history of updated records will overwrite the target table at each execution. 

## Explanation
The query uses `spark.readStream` to read the table's changes captured by CDF as a streaming source. This leverages checkpointing to track the progress of the stream processing and continue the stream from where it left off in the last execution.




The query then appends the data to the target table at each execution since it's using the default writing mode, which is 'append'.




Study materials from our exam preparation course on Udemy:

Lecture

Hands-on
