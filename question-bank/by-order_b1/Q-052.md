# Question 52

## Question
A data engineer at a retail company is tasked with analyzing daily sales trends across hundreds of stores. The raw PySpark DataFrame contains columns store_id, date, and sales_amount. The engineer wants to calculate a 7-day rolling average of sales per store, leveraging Pandas for its convenient rolling window operations. To achieve this task, the engineer created a custom Python function called "calculate_sales" where the input and output of the function are both pandas.DataFrame.




Which of the following allows applying this function to each group of store_id while preserving Spark efficiency?

## Options
- A. pandas_udf(calculate_sales, returnType=Series) 
- B. df.groupBy("store_id").applyInPandas(calculate_sales, schema) (Correct)
- C. df.selectExpr("calculate_sales(store_id)") 
- D. df.mapInPandas("store_id", calculate_sales, schema) 

## Explanation
The `applyInPandas` function, used after a `groupBy` operation, is designed exactly for this scenario: applying a Python function that takes and returns a Pandas DataFrame to each group of data within a Spark DataFrame, while preserving state variables that are local to each group's processing logic.
