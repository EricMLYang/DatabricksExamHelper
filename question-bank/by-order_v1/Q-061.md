# Question #61

---

## 題目資訊

### 題目編號
**ID:** `Q-061`

### 來源
**來源:** Real Exam Recall

### 難度等級
**難度:** `L1-Basic`

---

## 題目內容

### 題幹

A member of the data engineering team has submitted a short notebook that they wish to schedule as part of a larger data pipeline.

Assume that the commands provided below produce the logically correct results when run as presented.

```python
Cmd 1: rawDF = spark.table("raw_data")
Cmd 2: rawDF.printSchema()
Cmd 3: flattenedDF = rawDF.select("*", "values.*")
Cmd 4: finalDF = flattenedDF.drop("values")
Cmd 5: finalDF.explain()
Cmd 6: display(finalDF)
Cmd 7: finalDF.write.mode("append").saveAsTable("flat_data")
```

Which command should be removed from the notebook before scheduling it as a job?

### 選項

- **A.** Cmd 2
- **B.** Cmd 3
- **C.** Cmd 4
- **D.** Cmd 5
- **E.** Cmd 6

---

## 標籤系統

### Topic Tags (技術主題標籤)
**Topics:** `Jobs`, `Notebooks`, `display()`, `Production-Code`

### Trap Tags (陷阱類型標籤)
**Traps:** `Interactive-vs-Production`, `Debugging-Commands`

### Knowledge Domain (知識領域)
**Domain:** `Development Practices`

---

## 答案與解析連結

### 正確答案
**正解:** `E`

### 解析檔案
**詳細解析:** [點此查看解析](../analysis/Q-061-analysis.md)

---

# 詳細解析

## 📍 考點識別

### 主要考點
**核心技術:** Job 調度與生產環境代碼最佳實踐  
**知識領域:** 開發實踐與維運自動化  
**關鍵概念:** Interactive vs Production 代碼差異、調試指令識別

### 次要考點
- Notebook 生產化最佳實踐
- Databricks Jobs 執行特性
- 調試與顯示指令的適用場景

---

## ✅ 正解說明

### 為什麼 E (Cmd 6: display(finalDF)) 是正確的？

**技術原理:**
`display()` 是 Databricks 提供的互動式資料展示函數，專為 notebook 環境設計：
- 在 notebook 中提供豐富的視覺化輸出
- 包含自動圖表生成、資料預覽等功能
- **僅在互動式環境中有效，在 Job 執行時無作用**

**符合需求:**
當 notebook 被調度為 Job 時：
- **無使用者介面:** Job 在後台執行，沒有互動式介面來顯示結果
- **資源浪費:** `display()` 會嘗試執行但無法輸出，消耗不必要的計算資源
- **執行延遲:** 可能造成額外的執行時間
- **最佳實踐:** 生產環境代碼應該移除所有調試和展示用途的指令

**實務應用:**
```python
# ❌ 不適合 Job 調度
display(finalDF)  # 在 Job 中沒有作用

# ✅ 適合 Job 調度  
finalDF.write.mode("append").saveAsTable("flat_data")  # 實際的資料處理
```

---

## ❌ 錯誤選項排除

### 選項 A - Cmd 2: rawDF.printSchema()
**錯誤原因:** printSchema() 在生產環境仍有價值

**詳細分析:**
`printSchema()` 雖然是調試功能，但在生產環境中：
- **結構驗證:** 可以輸出到 Job 日誌中，用於驗證資料結構
- **故障排除:** 當資料 schema 異常時，日誌中的 schema 資訊有助於診斷
- **執行開銷小:** 只是印出 metadata，不涉及資料掃描
- **可選保留:** 雖然可以移除，但不是必須移除的

**易混淆點:**
新手容易認為所有「看起來像調試」的指令都要移除，但要區分實用性

### 選項 B - Cmd 3: flattenedDF = rawDF.select("*", "values.*")
**錯誤原因:** 這是核心的數據處理邏輯

**詳細分析:**
這個指令執行的是業務邏輯：
- **數據扁平化:** 將巢狀結構的 `values` 欄位展開
- **核心功能:** 移除此指令會破壞整個數據處理流程
- **必要操作:** 後續的 `drop("values")` 依賴於此步驟

**易混淆點:**
不能因為包含 `select` 就認為是查詢/展示用途，要看實際的業務邏輯功能

### 選項 C - Cmd 4: finalDF = flattenedDF.drop("values")
**錯誤原因:** 這是清理步驟的核心邏輯

**詳細分析:**
這個指令的作用：
- **資料清理:** 移除已經展開的原始巢狀欄位
- **結構優化:** 確保最終 DataFrame 只包含需要的扁平化欄位
- **業務必要:** 這是資料處理流程的必要步驟

**易混淆點:**
`drop()` 看起來像是清理指令，但實際上是業務邏輯的一部分

### 選項 D - Cmd 5: finalDF.explain()
**錯誤原因:** explain() 在生產環境有監控價值

**詳細分析:**
`explain()` 的生產環境價值：
- **執行計畫記錄:** 在 Job 日誌中記錄查詢執行計畫
- **效能監控:** 幫助識別效能瓶頸或異常的執行計畫
- **故障診斷:** 當 Job 效能異常時，日誌中的執行計畫是重要線索
- **開銷極小:** 只是輸出執行計畫，不執行實際的資料操作

**易混淆點:**
容易將 `explain()` 歸類為純調試功能，但在生產監控中有實際價值

---

## 🧠 記憶法與解題技巧

### 記憶口訣
**"Display 給人看，Job 沒有人"** - `display()` 是為了給使用者看的，Job 執行時沒有使用者界面

**"互動指令要清理，邏輯指令要保留"** - 區分互動式展示指令與業務邏輯指令

### 解題步驟
1. **識別題目類型** - 看到 "schedule as a job" = 生產環境代碼優化問題
2. **分類指令功能** - 區分：業務邏輯 vs 調試展示 vs 監控日誌
3. **找出互動指令** - 專為 notebook 互動環境設計的指令
4. **確認無作用指令** - 在 Job 環境中完全無效果的指令

### 常見陷阱警示
⚠️ **陷阱 1: 過度清理** - 不是所有「看起來像調試」的指令都要移除，要考慮生產價值
⚠️ **陷阱 2: 混淆展示與日誌** - `display()` 是互動展示，`print()` 或 `show()` 會輸出到日誌

---

## 📚 官方文件與延伸閱讀

### 官方文件
1. **[Databricks Jobs Best Practices](https://docs.databricks.com/workflows/jobs/jobs.html)** - Job 調度的最佳實踐與注意事項
2. **[Notebook Production Guidelines](https://docs.databricks.com/notebooks/best-practices.html)** - 將 notebook 用於生產環境的指導原則

### 延伸閱讀
- [Interactive vs Batch Processing](https://docs.databricks.com/notebooks/notebooks-manage.html)
- [Job Monitoring and Logging](https://docs.databricks.com/workflows/jobs/monitor-job-runs.html)

### 相關題目
- `Q-001` - Databricks Jobs 基礎配置
- `Q-047` - 生產環境代碼優化策略

---

## 相關資源

### 官方文件
- [Databricks Jobs](https://docs.databricks.com/workflows/jobs/jobs.html)
- [Notebook Best Practices](https://docs.databricks.com/notebooks/best-practices.html)
