# Q-093

## é¡Œç›®è³‡è¨Š

**ID:** `Q-093`

**ä¾†æº:** Mock Exam (Source labeled as #393)

**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹

You are performing a join operation to combine values from a static `userLookup` table with a streaming DataFrame `streamingDF`.

Which code block attempts to perform an **invalid** stream-static join?

### é¸é …

- **A.** `userLookup.join(streamingDF, ["userid"], how="inner")`
- **B.** `streamingDF.join(userLookup, ["user_id"], how="outer")`
- **C.** `streamingDF.join(userLookup, ["user_id"], how="left")`
- **D.** `streamingDF.join(streamingDF, ["userid"], how="inner")`
- **E.** `userLookup.join(streamingDF, ["user_id"], how="right")`

---

## æ¨™ç±¤ç³»çµ±

**Topics:** `Streaming`, `Spark-Joins`, `Stream-Static-Join`

**Traps:** `Join-Type-Support`, `Left-Right-Confusion`

**Domain:** `é–‹ç™¼èˆ‡è½‰æ› (Development & Transformation)`

---

## ç­”æ¡ˆèˆ‡åˆ†æ

### æ­£ç¢ºç­”æ¡ˆ

**æ­£è§£:** `B`

**ç¤¾ç¾¤æŠ•ç¥¨:** B (79%)
**ä¾†æºæ¨™è¨»:** E

**æ·±å…¥æ´å¯Ÿ:** æ ¹æ“š Spark Structured Streaming å®˜æ–¹æ–‡ä»¶çš„æ”¯æ´çŸ©é™£ï¼Œ**stream-static outer join ä¸è¢«æ”¯æ´**ã€‚ä¾†æºæ¨™è¨»ç­”æ¡ˆ Eï¼ˆstatic-stream right joinï¼‰å¯¦éš›ä¸Šæ˜¯æœ‰æ•ˆçš„ï¼Œå› ç‚ºå®ƒç­‰åŒæ–¼ stream-static left joinã€‚

---

## ğŸ“ è€ƒé»è­˜åˆ¥

### ä¸»è¦è€ƒé»
**æ ¸å¿ƒæŠ€è¡“:** Structured Streaming çš„ Stream-Static Join æ”¯æ´é¡å‹
**çŸ¥è­˜é ˜åŸŸ:** é–‹ç™¼èˆ‡è½‰æ› - Streaming è³‡æ–™è™•ç†
**é—œéµæ¦‚å¿µ:** 
- Stream-Static Join æ”¯æ´çŸ©é™£
- Left/Right/Full Outer Join çš„é™åˆ¶
- Streaming DataFrame çš„ç‰¹æ®Šé™åˆ¶

### æ¬¡è¦è€ƒé»
- Left vs Right Join çš„ç­‰åƒ¹è½‰æ›
- Streaming èˆ‡ Batch çš„å·®ç•°
- Join é¡å‹çš„èªç¾©ç†è§£

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ B æ˜¯æ­£ç¢ºçš„ï¼ˆå³ç„¡æ•ˆçš„æ“ä½œï¼‰ï¼Ÿ

**æŠ€è¡“åŸç†:**

**Spark Structured Streaming çš„ Stream-Static Join æ”¯æ´çŸ©é™£ï¼š**

```
æ”¯æ´çš„ Join é¡å‹ï¼ˆStream åœ¨å·¦å´ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stream (Left) JOIN Static (Right)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… INNER                                  â”‚
â”‚ âœ… LEFT (LEFT OUTER)                      â”‚
â”‚ âŒ RIGHT (RIGHT OUTER)      ä¸æ”¯æ´ï¼      â”‚
â”‚ âŒ FULL OUTER               ä¸æ”¯æ´ï¼      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ”¯æ´çš„ Join é¡å‹ï¼ˆStatic åœ¨å·¦å´ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Static (Left) JOIN Stream (Right)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… INNER                                  â”‚
â”‚ âœ… RIGHT (RIGHT OUTER)                    â”‚
â”‚ âŒ LEFT (LEFT OUTER)        ä¸æ”¯æ´ï¼      â”‚
â”‚ âŒ FULL OUTER               ä¸æ”¯æ´ï¼      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ç‚ºä½•é¸é … B ç„¡æ•ˆï¼š**

```python
# é¸é … B: streamingDF.join(userLookup, ["user_id"], how="outer")
# é€™æ˜¯ Stream-Static FULL OUTER JOIN

streamingDF (streaming)  FULL OUTER JOIN  userLookup (static)
     â†“
âŒ ä¸æ”¯æ´ï¼æœƒæ‹‹å‡ºéŒ¯èª¤

# éŒ¯èª¤è¨Šæ¯ï¼š
# AnalysisException: Full outer joins between stream and static are not supported
```

**ç‚ºä½•ä¸æ”¯æ´çš„åŸå› ï¼š**

1. **Streaming çš„ç„¡ç•Œç‰¹æ€§**
   - Streaming DataFrame æ˜¯ç„¡ç•Œçš„ï¼ˆè³‡æ–™æŒçºŒæµå…¥ï¼‰
   - Full Outer Join éœ€è¦ã€ŒçŸ¥é“æ‰€æœ‰è³‡æ–™ã€æ‰èƒ½è¨ˆç®—æœªåŒ¹é…çš„è¨˜éŒ„
   - ç„¡æ³•ç¢ºå®šæŸç­†éœæ…‹è³‡æ–™ã€Œæ°¸é ä¸æœƒã€èˆ‡æœªä¾†çš„ä¸²æµè³‡æ–™åŒ¹é…

2. **State ç®¡ç†è¤‡é›œåº¦**
   - Full Outer Join éœ€è¦è¿½è¹¤æ‰€æœ‰éœæ…‹è¡¨çš„è¨˜éŒ„ç‹€æ…‹
   - éœ€è¦ç„¡é™æœŸä¿ç•™éœæ…‹è³‡æ–™çš„ state
   - è¨˜æ†¶é«”èˆ‡æ•ˆèƒ½ç„¡æ³•æ‰¿å—

3. **èªç¾©ä¸æ˜ç¢º**
   ```
   Full Outer Join çš„å•é¡Œï¼š
   
   æ™‚åˆ» T1: éœæ…‹è¡¨æœ‰ user_id=5ï¼Œä¸²æµä¸­æ²’æœ‰
   å•é¡Œï¼šè¦è¼¸å‡ºã€ŒæœªåŒ¹é…çš„ user_id=5ã€å—ï¼Ÿ
   ç­”æ¡ˆï¼šä¸ç¢ºå®šï¼Œå› ç‚º user_id=5 å¯èƒ½åœ¨æœªä¾†çš„ä¸²æµä¸­å‡ºç¾
   
   æ™‚åˆ» T2: ä¸²æµä¸­å‡ºç¾ user_id=5
   å•é¡Œï¼šä¹‹å‰è¼¸å‡ºçš„ã€ŒæœªåŒ¹é…è¨˜éŒ„ã€è¦æ’¤å›å—ï¼Ÿ
   ç­”æ¡ˆï¼šStreaming ç„¡æ³•æ’¤å›å·²è¼¸å‡ºçš„è³‡æ–™
   ```

**ç¬¦åˆé¡Œç›®æƒ…å¢ƒ:**

```python
# é¡Œç›®æƒ…å¢ƒï¼šStream-Static Join

# éœæ…‹è¡¨
userLookup = spark.table("users")  # Static DataFrame
# user_id | name
# 1       | Alice
# 2       | Bob
# 3       | Charlie

# ä¸²æµè¡¨
streamingDF = spark.readStream.format("kafka")...  # Streaming DataFrame
# user_id | action    | timestamp
# 1       | login     | 2024-01-01 10:00:00
# 2       | purchase  | 2024-01-01 10:01:00
# ...

# é¸é … B: FULL OUTER JOIN (ç„¡æ•ˆ)
result = streamingDF.join(userLookup, ["user_id"], how="outer")
# âŒ AnalysisException: Full outer joins between stream and static are not supported

# æ­£ç¢ºåšæ³•ï¼šä½¿ç”¨æ”¯æ´çš„ join é¡å‹
# Inner Join (æœ‰æ•ˆ)
result = streamingDF.join(userLookup, ["user_id"], how="inner")

# Left Join (æœ‰æ•ˆ)
result = streamingDF.join(userLookup, ["user_id"], how="left")
```

**å¯¦å‹™æ‡‰ç”¨:**

**æœ‰æ•ˆçš„ Stream-Static Join ç¯„ä¾‹ï¼š**

```python
# Scenario: è±å¯Œä¸²æµè³‡æ–™èˆ‡ä½¿ç”¨è€…è³‡è¨Š

# éœæ…‹è¡¨ï¼šä½¿ç”¨è€…è³‡æ–™
users = spark.table("dim_users")  # Static
# user_id | name    | country | tier
# 1       | Alice   | US      | Gold
# 2       | Bob     | UK      | Silver

# ä¸²æµè¡¨ï¼šé»æ“Šäº‹ä»¶
clickstream = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "broker:9092") \
    .option("subscribe", "clicks") \
    .load() \
    .selectExpr("CAST(value AS STRING)")

# è§£æ JSON
from pyspark.sql.functions import from_json, col
from pyspark.sql.types import StructType, StructField, StringType, TimestampType

schema = StructType([
    StructField("user_id", StringType()),
    StructField("page", StringType()),
    StructField("timestamp", TimestampType())
])

clicks = clickstream.select(from_json(col("value"), schema).alias("data")).select("data.*")

# âœ… æœ‰æ•ˆï¼šStream LEFT JOIN Static
enriched = clicks.join(users, ["user_id"], how="left")
# çµæœï¼šæ‰€æœ‰é»æ“Šäº‹ä»¶éƒ½ä¿ç•™ï¼Œæœ‰ä½¿ç”¨è€…è³‡æ–™çš„æœƒè¢«è±å¯Œ

# âœ… æœ‰æ•ˆï¼šStream INNER JOIN Static
active_users = clicks.join(users, ["user_id"], how="inner")
# çµæœï¼šåªä¿ç•™æœ‰ä½¿ç”¨è€…è³‡æ–™çš„é»æ“Šäº‹ä»¶

# âŒ ç„¡æ•ˆï¼šStream OUTER JOIN Static
# all_data = clicks.join(users, ["user_id"], how="outer")
# éŒ¯èª¤ï¼šä¸æ”¯æ´

# å¯«å…¥çµæœ
enriched.writeStream \
    .format("delta") \
    .outputMode("append") \
    .option("checkpointLocation", "/checkpoints/enriched_clicks") \
    .table("enriched_clicks")
```

**Join é¡å‹é¸æ“‡æŒ‡å—ï¼š**

```python
# ä½¿ç”¨ INNER JOINï¼šåªä¿ç•™åŒ¹é…çš„è¨˜éŒ„
# é©ç”¨ï¼šå¿…é ˆæœ‰éœæ…‹è³‡æ–™çš„å ´æ™¯
streamingDF.join(staticDF, ["key"], how="inner")

# ä½¿ç”¨ LEFT JOINï¼šä¿ç•™æ‰€æœ‰ä¸²æµè¨˜éŒ„
# é©ç”¨ï¼šè±å¯Œè³‡æ–™ï¼Œå…è¨±éœæ…‹è³‡æ–™ç¼ºå¤±
streamingDF.join(staticDF, ["key"], how="left")

# ä¸æ”¯æ´ OUTER/FULL JOINï¼š
# streamingDF.join(staticDF, ["key"], how="outer")  âŒ
# streamingDF.join(staticDF, ["key"], how="full")   âŒ
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### é¸é … A - userLookup.join(streamingDF, ["userid"], how="inner")

**éŒ¯èª¤åŸå› :** æ­¤æ“ä½œ**æœ‰æ•ˆ** - Static-Stream INNER JOIN æ˜¯æ”¯æ´çš„

**è©³ç´°åˆ†æ:**

```python
# Static (Left) INNER JOIN Stream (Right)
userLookup.join(streamingDF, ["userid"], how="inner")
# âœ… æ”¯æ´ï¼

# ç­‰åƒ¹æ–¼ï¼š
streamingDF.join(userLookup, ["userid"], how="inner")
# INNER JOIN æ˜¯å¯äº¤æ›çš„
```

**ç‚ºä½•æ”¯æ´ï¼š**

1. **INNER JOIN èªç¾©æ˜ç¢º**
   - åªè¼¸å‡ºæœ‰åŒ¹é…çš„è¨˜éŒ„
   - ä¸éœ€è¦ç­‰å¾…ã€Œæ‰€æœ‰è³‡æ–™ã€
   - ä¸éœ€è¦è¿½è¹¤æœªåŒ¹é…è¨˜éŒ„

2. **State ç®¡ç†ç°¡å–®**
   - ä¸éœ€è¦ä¿ç•™éœæ…‹è¡¨çš„å…¨éƒ¨è³‡æ–™åœ¨ state
   - åªéœ€åœ¨æ¯å€‹ micro-batch åŸ·è¡Œ join

3. **é †åºä¸å½±éŸ¿çµæœ**
   - Static JOIN Stream æˆ– Stream JOIN Static
   - INNER JOIN çµæœç›¸åŒ

**å¯¦éš›åŸ·è¡Œï¼š**

```python
# ç¯„ä¾‹
userLookup = spark.table("users")  # Static
streamingDF = spark.readStream.format("kafka")...  # Streaming

# é¸é … A: æœ‰æ•ˆ
result = userLookup.join(streamingDF, ["userid"], how="inner")

query = result.writeStream \
    .format("console") \
    .outputMode("append") \
    .start()
# âœ… æ­£å¸¸åŸ·è¡Œï¼Œä¸æœƒå ±éŒ¯
```

---

### é¸é … C - streamingDF.join(userLookup, ["user_id"], how="left")

**éŒ¯èª¤åŸå› :** æ­¤æ“ä½œ**æœ‰æ•ˆ** - Stream-Static LEFT JOIN æ˜¯æ”¯æ´çš„

**è©³ç´°åˆ†æ:**

```python
# Stream (Left) LEFT JOIN Static (Right)
streamingDF.join(userLookup, ["user_id"], how="left")
# âœ… æ”¯æ´ï¼é€™æ˜¯æœ€å¸¸ç”¨çš„ stream-static join é¡å‹
```

**ç‚ºä½•æ”¯æ´ï¼š**

1. **èªç¾©æ˜ç¢º**
   - ä¿ç•™æ‰€æœ‰ä¸²æµè¨˜éŒ„ï¼ˆå·¦å´ï¼‰
   - å¦‚æœéœæ…‹è¡¨æœ‰åŒ¹é…è¨˜éŒ„ï¼Œè£œå……è³‡æ–™
   - å¦‚æœéœæ…‹è¡¨æ²’æœ‰åŒ¹é…ï¼Œå¡« NULL

2. **ä¸éœ€è¦ç­‰å¾…**
   - ä¸²æµæ¯ç­†è³‡æ–™åˆ°é”æ™‚ç«‹å³è™•ç†
   - æŸ¥æ‰¾éœæ…‹è¡¨ï¼ˆå·²çŸ¥çš„å®Œæ•´è³‡æ–™é›†ï¼‰
   - è¼¸å‡ºçµæœ

3. **å¯¦å‹™ä¸­æœ€å¸¸è¦‹**
   - ç”¨æ–¼è±å¯Œä¸²æµè³‡æ–™
   - å…è¨±éœæ…‹è³‡æ–™ç¼ºå¤±ï¼ˆä¾‹å¦‚æ–°ä½¿ç”¨è€…ï¼‰

**å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹ï¼š**

```python
# è±å¯Œä¸²æµäº‹ä»¶èˆ‡ä½¿ç”¨è€…è³‡æ–™
events = spark.readStream.format("kafka")...
users = spark.table("dim_users")  # Static lookup table

# LEFT JOIN: ä¿ç•™æ‰€æœ‰äº‹ä»¶ï¼Œæœ‰ä½¿ç”¨è€…è³‡æ–™å‰‡è±å¯Œ
enriched_events = events.join(users, ["user_id"], how="left")

# çµæœï¼š
# event_id | user_id | event_type | name    | country
# 1        | 100     | click      | Alice   | US      â† æœ‰åŒ¹é…
# 2        | 200     | click      | Bob     | UK      â† æœ‰åŒ¹é…
# 3        | 999     | click      | NULL    | NULL    â† ç„¡åŒ¹é…ï¼ˆæ–°ç”¨æˆ¶ï¼‰

enriched_events.writeStream \
    .format("delta") \
    .outputMode("append") \
    .table("enriched_events")
# âœ… æ­£å¸¸é‹ä½œ
```

---

### é¸é … D - streamingDF.join(streamingDF, ["userid"], how="inner")

**éŒ¯èª¤åŸå› :** æ­¤æ“ä½œæœ‰èªæ³•å•é¡Œ - join è‡ªå·±é€šå¸¸ä¸åˆç†ï¼Œä½†**æŠ€è¡“ä¸Šå¯è¡Œ**ï¼ˆStream-Stream Joinï¼‰

**è©³ç´°åˆ†æ:**

**é¦–å…ˆæ³¨æ„ï¼šæ­¤é¸é …å¯èƒ½æœ‰ç­†èª¤**
- é¡Œç›®æ˜¯ Stream-Static Join
- ä½†é¸é … D æ˜¯ `streamingDF.join(streamingDF, ...)`
- é€™è®Šæˆäº† **Stream-Stream Join**ï¼ˆåŒä¸€å€‹ DataFrameï¼‰

**å¦‚æœæ˜¯ç­†èª¤ï¼ˆæ‡‰è©²æ˜¯ userLookupï¼‰ï¼š**
```python
# å‡è¨­æ‡‰è©²æ˜¯ï¼š
streamingDF.join(userLookup, ["userid"], how="inner")
# âœ… æœ‰æ•ˆï¼Stream-Static INNER JOIN
```

**å¦‚æœçœŸçš„æ˜¯ join è‡ªå·±ï¼š**
```python
# å­—é¢æ„æ€ï¼š
streamingDF.join(streamingDF, ["userid"], how="inner")
# âš ï¸ æŠ€è¡“ä¸Šå¯è¡Œï¼Œä½†æ²’æœ‰æ„ç¾©ï¼ˆè¿”å›åŸå§‹è³‡æ–™ï¼‰
# é€™æ˜¯ Stream-Stream Self Join
```

**Stream-Stream Join çš„ç‰¹æ€§ï¼š**
- Stream-Stream Join æ˜¯æ”¯æ´çš„ï¼ˆä½†éœ€è¦ watermarkï¼‰
- Self Join é€šå¸¸ç”¨æ–¼æ‰¾å‡ºé—œè¯è¨˜éŒ„

```python
# æœ‰æ„ç¾©çš„ Stream-Stream Self Join ç¯„ä¾‹
clicks = spark.readStream.format("kafka")...

# æ‰¾å‡ºåŒä¸€ä½¿ç”¨è€…çš„é€£çºŒé»æ“Š
clicks.alias("c1").join(
    clicks.alias("c2"),
    (col("c1.user_id") == col("c2.user_id")) &
    (col("c1.timestamp") < col("c2.timestamp")),
    how="inner"
)
```

**çµè«–ï¼š**
- å¦‚æœæ˜¯ç­†èª¤ â†’ æ‡‰è©²æ˜¯æœ‰æ•ˆçš„ Stream-Static INNER JOIN
- å¦‚æœçœŸçš„ join è‡ªå·± â†’ æŠ€è¡“ä¸Šå¯è¡Œä½†ç„¡æ„ç¾©
- ç„¡è«–å“ªç¨®ï¼Œéƒ½**ä¸æ˜¯ç„¡æ•ˆæ“ä½œ**

---

### é¸é … E - userLookup.join(streamingDF, ["user_id"], how="right") (ä¾†æºæ¨™è¨»ç­”æ¡ˆ)

**éŒ¯èª¤åŸå› :** æ­¤æ“ä½œ**æœ‰æ•ˆ** - Static-Stream RIGHT JOIN ç­‰åƒ¹æ–¼ Stream-Static LEFT JOIN

**è©³ç´°åˆ†æ:**

**Left vs Right Join çš„ç­‰åƒ¹æ€§ï¼š**

```python
# é¸é … E:
userLookup.join(streamingDF, ["user_id"], how="right")

# ç­‰åƒ¹æ–¼ï¼š
streamingDF.join(userLookup, ["user_id"], how="left")

# èªç¾©ï¼š
# Static (Left) RIGHT JOIN Stream (Right)
# = ä¿ç•™å³å´ï¼ˆStreamï¼‰æ‰€æœ‰è¨˜éŒ„
# = Stream LEFT JOIN Static
```

**è¦–è¦ºåŒ–ç†è§£ï¼š**

```
é¸é … E: Static RIGHT JOIN Stream
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ userLookup  â”‚ RIGHT   â”‚ streamingDF  â”‚
â”‚  (Static)   â”‚  JOIN   â”‚  (Stream)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                       â†“
   å·¦å´ï¼ˆå¯é¸ï¼‰              å³å´ï¼ˆå…¨ä¿ç•™ï¼‰
       
çµæœï¼šä¿ç•™æ‰€æœ‰ streamingDF è¨˜éŒ„ âœ“

é¸é … C: Stream LEFT JOIN Static
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ streamingDF  â”‚  LEFT   â”‚ userLookup  â”‚
â”‚  (Stream)    â”‚  JOIN   â”‚  (Static)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                       â†“
   å·¦å´ï¼ˆå…¨ä¿ç•™ï¼‰           å³å´ï¼ˆå¯é¸ï¼‰
       
çµæœï¼šä¿ç•™æ‰€æœ‰ streamingDF è¨˜éŒ„ âœ“

çµè«–ï¼šé¸é … E å’Œé¸é … C èªç¾©ç›¸åŒï¼
```

**å¯¦éš›é©—è­‰ï¼š**

```python
userLookup = spark.table("users")  # Static
streamingDF = spark.readStream.format("kafka")...  # Streaming

# é¸é … E: Static RIGHT JOIN Stream
result_e = userLookup.join(streamingDF, ["user_id"], how="right")

# é¸é … C: Stream LEFT JOIN Static
result_c = streamingDF.join(userLookup, ["user_id"], how="left")

# å¯«å…¥æ¸¬è©¦
result_e.writeStream.format("console").outputMode("append").start()
# âœ… æ­£å¸¸åŸ·è¡Œï¼Œä¸æœƒå ±éŒ¯

# å…©è€…çµæœç›¸åŒï¼ˆæ¬„ä½é †åºå¯èƒ½ä¸åŒï¼‰
```

**ç‚ºä½•ä¾†æºæ¨™è¨» E ç‚ºéŒ¯èª¤ç­”æ¡ˆæ˜¯ä¸æ­£ç¢ºçš„ï¼š**

1. **Spark å…è¨±æ­¤æ“ä½œ**
   - Static RIGHT JOIN Stream æ˜¯æœ‰æ•ˆçš„
   - å®ƒç­‰åƒ¹æ–¼å¸¸ç”¨çš„ Stream LEFT JOIN Static

2. **å®˜æ–¹æ–‡ä»¶æ”¯æ´**
   - Spark æ–‡ä»¶æ˜ç¢ºæŒ‡å‡ºæ”¯æ´æ­¤æ“ä½œ
   - ç¤¾ç¾¤ 79% é¸ B æ˜¯æ­£ç¢ºçš„

3. **å¯¦å‹™ä¸­å¯ä½¿ç”¨**
   - é›–ç„¶è¼ƒå°‘å¯«æˆ Static RIGHT JOIN Stream
   - ä½†æŠ€è¡“ä¸Šå®Œå…¨æœ‰æ•ˆ

---

## ğŸ§  è¨˜æ†¶æ³•èˆ‡æŠ€å·§

### å£è¨£
**ã€Œä¸²æµä¿å…¨éƒ¨ï¼Œç”¨ LEFTï¼›è¦å…¨åŒ¹é…ï¼ŒOUTER ä¸è¡Œã€**

### Stream-Static Join æ”¯æ´çŸ©é™£ï¼ˆæ ¸å¿ƒè¨˜æ†¶ï¼‰

```
è¨˜æ†¶é—œéµï¼šã€Œä¿ç•™ Stream çš„éƒ½å¯ä»¥ï¼Œä¿ç•™ Static çš„ä¸è¡Œã€

Stream-Static Join:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Join Type       â”‚ Stream â† Static      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INNER           â”‚ âœ… æ”¯æ´               â”‚
â”‚ LEFT (OUTER)    â”‚ âœ… æ”¯æ´ï¼ˆä¿ç•™ Streamï¼‰â”‚
â”‚ RIGHT (OUTER)   â”‚ âŒ ä¸æ”¯æ´ï¼ˆä¿ç•™ Staticï¼‰â”‚
â”‚ FULL OUTER      â”‚ âŒ ä¸æ”¯æ´ï¼ˆä¿ç•™å…©è€…ï¼‰  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Static-Stream Join:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Join Type       â”‚ Static â†’ Stream      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ INNER           â”‚ âœ… æ”¯æ´               â”‚
â”‚ LEFT (OUTER)    â”‚ âŒ ä¸æ”¯æ´ï¼ˆä¿ç•™ Staticï¼‰â”‚
â”‚ RIGHT (OUTER)   â”‚ âœ… æ”¯æ´ï¼ˆä¿ç•™ Streamï¼‰â”‚
â”‚ FULL OUTER      â”‚ âŒ ä¸æ”¯æ´ï¼ˆä¿ç•™å…©è€…ï¼‰  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç°¡åŒ–è¨˜æ†¶ï¼š
âœ… INNER: ç¸½æ˜¯å¯ä»¥
âœ… ä¿ç•™ Stream: å¯ä»¥ï¼ˆLEFT æˆ–ç­‰åƒ¹çš„ RIGHTï¼‰
âŒ ä¿ç•™ Static: ä¸è¡Œ
âŒ OUTER/FULL: ä¸è¡Œ
```

### åˆ¤æ–·æŠ€å·§æµç¨‹åœ–

```
é‡åˆ° Stream-Static Join å•é¡Œï¼š

æ­¥é©Ÿ 1: åˆ¤æ–· Join é¡å‹
â”œâ”€ INNER? â†’ âœ… æ”¯æ´
â”œâ”€ LEFT?
â”‚  â”œâ”€ Stream åœ¨å·¦? â†’ âœ… æ”¯æ´
â”‚  â””â”€ Static åœ¨å·¦? â†’ âŒ ä¸æ”¯æ´
â”œâ”€ RIGHT?
â”‚  â”œâ”€ Stream åœ¨å³? â†’ âœ… æ”¯æ´
â”‚  â””â”€ Static åœ¨å³? â†’ âŒ ä¸æ”¯æ´
â””â”€ OUTER/FULL? â†’ âŒ ä¸æ”¯æ´

æœ¬é¡Œï¼š
A. Static INNER Stream â†’ âœ… æ”¯æ´
B. Stream OUTER Static â†’ âŒ ä¸æ”¯æ´ âœ“ ç­”æ¡ˆ
C. Stream LEFT Static â†’ âœ… æ”¯æ´
D. Stream INNER Stream â†’ âš ï¸ ä¸åŒé¡å‹ï¼ˆStream-Streamï¼‰
E. Static RIGHT Stream â†’ âœ… æ”¯æ´ï¼ˆ= Stream LEFT Staticï¼‰
```

### ç­‰åƒ¹è½‰æ›è¨˜æ†¶æ³•

```
Left â†” Right ç­‰åƒ¹è½‰æ›ï¼š

A LEFT JOIN B = B RIGHT JOIN A
A RIGHT JOIN B = B LEFT JOIN A

æ‡‰ç”¨åˆ°æ­¤é¡Œï¼š

é¸é … C: streamingDF.join(userLookup, how="left")
     = Stream LEFT JOIN Static âœ…

é¸é … E: userLookup.join(streamingDF, how="right")
     = Static RIGHT JOIN Stream
     = Stream LEFT JOIN Static âœ…

å…©è€…ç­‰åƒ¹ï¼Œéƒ½æœ‰æ•ˆï¼
```

### å¿«é€Ÿæ’é™¤æ³•

```
é¡Œç›®å•ã€Œå“ªå€‹æ˜¯ç„¡æ•ˆçš„ã€ï¼š

çœ‹åˆ° OUTER / FULLï¼Ÿ
    â†“ æ˜¯
  âœ… æ‰¾åˆ°ç­”æ¡ˆï¼ï¼ˆé¸é … Bï¼‰

çœ‹åˆ° LEFTï¼ŒStream åœ¨å·¦ï¼Ÿ
    â†“ æ˜¯
  âŒ é€™å€‹æœ‰æ•ˆï¼ˆé¸é … Cï¼‰

çœ‹åˆ° RIGHTï¼ŒStream åœ¨å³ï¼Ÿ
    â†“ æ˜¯
  âŒ é€™å€‹æœ‰æ•ˆï¼ˆé¸é … Eï¼‰

çœ‹åˆ° INNERï¼Ÿ
    â†“ æ˜¯
  âŒ é€™å€‹æœ‰æ•ˆï¼ˆé¸é … A, Dï¼‰
```

---

## ğŸ“š å»¶ä¼¸é–±è®€

### å®˜æ–¹æ–‡ä»¶
- [Spark Structured Streaming - Stream-Static Joins](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#stream-static-joins)
- [Spark Structured Streaming - Join Operations](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#join-operations)
- [Databricks - Streaming Joins](https://docs.databricks.com/structured-streaming/delta-lake.html#stream-static-joins)

### ç›¸é—œæ¦‚å¿µ
- Stream-Stream Joinï¼ˆéœ€è¦ watermarkï¼‰
- Stateful Operations in Streaming
- Micro-batch Processing
- Streaming Aggregations

### å¯¦å‹™ç¯„ä¾‹

**1. å®Œæ•´çš„ Stream-Static Join å·¥ä½œæµç¨‹ï¼š**

```python
from pyspark.sql.functions import col, from_json
from pyspark.sql.types import *

# éœæ…‹è¡¨ï¼šç¶­åº¦è³‡æ–™
dim_users = spark.table("warehouse.dim_users")
# user_id | name    | country | tier    | created_at
# 1       | Alice   | US      | Gold    | 2023-01-01
# 2       | Bob     | UK      | Silver  | 2023-02-15

dim_products = spark.table("warehouse.dim_products")
# product_id | name      | category   | price
# 101        | Laptop    | Electronics| 1200
# 102        | Mouse     | Electronics| 25

# ä¸²æµè¡¨ï¼šäº‹å¯¦è³‡æ–™ï¼ˆé»æ“Šæµï¼‰
clickstream = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "broker:9092") \
    .option("subscribe", "user_events") \
    .option("startingOffsets", "latest") \
    .load()

# è§£æ Kafka è¨Šæ¯
event_schema = StructType([
    StructField("event_id", StringType()),
    StructField("user_id", IntegerType()),
    StructField("product_id", IntegerType()),
    StructField("event_type", StringType()),
    StructField("timestamp", TimestampType())
])

events = clickstream \
    .select(from_json(col("value").cast("string"), event_schema).alias("data")) \
    .select("data.*")

# âœ… æœ‰æ•ˆï¼šStream LEFT JOIN Staticï¼ˆè±å¯Œä½¿ç”¨è€…è³‡è¨Šï¼‰
enriched_with_users = events.join(
    dim_users,
    ["user_id"],
    how="left"
)

# âœ… æœ‰æ•ˆï¼šç¹¼çºŒ LEFT JOIN å•†å“è³‡è¨Š
fully_enriched = enriched_with_users.join(
    dim_products,
    ["product_id"],
    how="left"
)

# å¯«å…¥ Delta Lake
query = fully_enriched.writeStream \
    .format("delta") \
    .outputMode("append") \
    .option("checkpointLocation", "/checkpoints/enriched_events") \
    .option("mergeSchema", "true") \
    .table("analytics.enriched_events")

query.awaitTermination()
```

**2. è™•ç†ç¼ºå¤±çš„éœæ…‹è³‡æ–™ï¼š**

```python
from pyspark.sql.functions import when, lit

# Streaming è³‡æ–™
orders = spark.readStream.format("kafka")...

# éœæ…‹ç¶­åº¦è¡¨
customers = spark.table("dim_customers")

# LEFT JOINï¼ˆå…è¨±ç¼ºå¤±ï¼‰
enriched = orders.join(customers, ["customer_id"], how="left")

# è™•ç†ç¼ºå¤±çš„éœæ…‹è³‡æ–™
result = enriched.select(
    col("order_id"),
    col("customer_id"),
    # å¦‚æœæ²’æœ‰å®¢æˆ¶è³‡æ–™ï¼Œå¡«å…¥é è¨­å€¼
    when(col("name").isNull(), "Unknown Customer").otherwise(col("name")).alias("customer_name"),
    when(col("country").isNull(), "Unknown").otherwise(col("country")).alias("country"),
    col("order_amount")
)

result.writeStream \
    .format("delta") \
    .outputMode("append") \
    .table("enriched_orders")
```

**3. éŒ¯èª¤è™•ç†ï¼šå˜—è©¦ä¸æ”¯æ´çš„ Join é¡å‹**

```python
# âŒ å˜—è©¦ OUTER JOINï¼ˆæœƒå¤±æ•—ï¼‰
try:
    invalid_join = streamingDF.join(
        staticDF,
        ["user_id"],
        how="outer"  # FULL OUTER JOIN
    )
    
    query = invalid_join.writeStream \
        .format("console") \
        .outputMode("append") \
        .start()
    
except Exception as e:
    print(f"éŒ¯èª¤: {e}")
    # è¼¸å‡ºï¼š
    # AnalysisException: Full outer joins between stream and static DataFrames are not supported

# âœ… ä¿®æ­£ï¼šä½¿ç”¨æ”¯æ´çš„ LEFT JOIN
valid_join = streamingDF.join(
    staticDF,
    ["user_id"],
    how="left"
)

query = valid_join.writeStream \
    .format("console") \
    .outputMode("append") \
    .start()
```

**4. å‹•æ…‹æ›´æ–°éœæ…‹è¡¨ï¼ˆé€²éšæŠ€å·§ï¼‰ï¼š**

```python
# æŒ‘æˆ°ï¼šéœæ…‹ç¶­åº¦è¡¨éœ€è¦å®šæœŸæ›´æ–°
# è§£æ±ºï¼šä½¿ç”¨ Delta Lake çš„ foreachBatch

def enrich_and_write(batch_df, batch_id):
    # åœ¨æ¯å€‹ micro-batch ä¸­è®€å–æœ€æ–°çš„éœæ…‹è¡¨
    latest_users = spark.table("dim_users")
    
    # åŸ·è¡Œ join
    enriched = batch_df.join(latest_users, ["user_id"], how="left")
    
    # å¯«å…¥çµæœ
    enriched.write \
        .format("delta") \
        .mode("append") \
        .save("/delta/enriched_events")

# ä½¿ç”¨ foreachBatch
events.writeStream \
    .foreachBatch(enrich_and_write) \
    .option("checkpointLocation", "/checkpoints/dynamic_enrich") \
    .start()

# å„ªé»ï¼šæ¯å€‹ micro-batch éƒ½è®€å–æœ€æ–°çš„éœæ…‹è¡¨
# ç¼ºé»ï¼šæ•ˆèƒ½è¼ƒä½ï¼ˆæ¯æ¬¡éƒ½é‡æ–°è®€å–ï¼‰
```

**5. æ•ˆèƒ½å„ªåŒ–ï¼šBroadcast Join**

```python
from pyspark.sql.functions import broadcast

# å°å‹éœæ…‹è¡¨ä½¿ç”¨ broadcast
dim_categories = spark.table("dim_categories")  # å°è¡¨ï¼ˆ< 10MBï¼‰

# ä½¿ç”¨ broadcast hint å„ªåŒ– join æ•ˆèƒ½
enriched = streamingDF.join(
    broadcast(dim_categories),  # å°‡å°è¡¨å»£æ’­åˆ°æ‰€æœ‰ executor
    ["category_id"],
    how="left"
)

# å„ªé»ï¼šé¿å… shuffleï¼Œæ•ˆèƒ½æ›´å¥½
# é©ç”¨ï¼šéœæ…‹è¡¨å°æ–¼ 10MB
```

**6. å®Œæ•´çš„ Join é¡å‹æ¸¬è©¦ï¼š**

```python
# æ¸¬è©¦æ‰€æœ‰ Join é¡å‹

static_df = spark.table("users")
streaming_df = spark.readStream.format("kafka")...

# æ¸¬è©¦ 1: INNER (Stream-Static)
try:
    result = streaming_df.join(static_df, ["user_id"], how="inner")
    print("âœ… Stream INNER Static: æ”¯æ´")
except:
    print("âŒ Stream INNER Static: ä¸æ”¯æ´")

# æ¸¬è©¦ 2: LEFT (Stream-Static)
try:
    result = streaming_df.join(static_df, ["user_id"], how="left")
    print("âœ… Stream LEFT Static: æ”¯æ´")
except:
    print("âŒ Stream LEFT Static: ä¸æ”¯æ´")

# æ¸¬è©¦ 3: RIGHT (Stream-Static)
try:
    result = streaming_df.join(static_df, ["user_id"], how="right")
    print("âœ… Stream RIGHT Static: æ”¯æ´")
except:
    print("âŒ Stream RIGHT Static: ä¸æ”¯æ´")

# æ¸¬è©¦ 4: OUTER (Stream-Static)
try:
    result = streaming_df.join(static_df, ["user_id"], how="outer")
    print("âœ… Stream OUTER Static: æ”¯æ´")
except:
    print("âŒ Stream OUTER Static: ä¸æ”¯æ´")  # â† æœƒåŸ·è¡Œé€™è¡Œ

# æ¸¬è©¦ 5: RIGHT (Static-Stream)
try:
    result = static_df.join(streaming_df, ["user_id"], how="right")
    print("âœ… Static RIGHT Stream: æ”¯æ´")
except:
    print("âŒ Static RIGHT Stream: ä¸æ”¯æ´")

# æ¸¬è©¦ 6: LEFT (Static-Stream)
try:
    result = static_df.join(streaming_df, ["user_id"], how="left")
    print("âœ… Static LEFT Stream: æ”¯æ´")
except:
    print("âŒ Static LEFT Stream: ä¸æ”¯æ´")  # â† æœƒåŸ·è¡Œé€™è¡Œ
```

---

## ğŸ”— ç›¸é—œé¡Œç›®
- Q-XXX: Stream-Stream Join èˆ‡ Watermark
- Q-XXX: Streaming Aggregations
- Q-XXX: Structured Streaming Output Modes
- Q-XXX: Kafka Integration with Structured Streaming
