# Question #119

---

## 題目資訊

### 題目編號
**ID:** `Q-119`

### 來源
**來源:** Mock Exam / Community Contributed

### 難度等級
**難度:** `L2-Intermediate`

---

## 題目內容

### 題幹

Which statement regarding **Spark configuration** on the Databricks platform is **true**?

### 選項

- **A.** The Databricks REST API can be used to modify the Spark configuration properties for an interactive cluster **without interrupting jobs** currently running on the cluster
- **B.** Spark configurations set within a notebook will affect **all SparkSessions** attached to the same interactive cluster
- **C.** When the same Spark configuration property is set for an interactive cluster and a notebook attached to that cluster, the **notebook setting will always be ignored**
- **D.** Spark configuration properties set for an interactive cluster with the Clusters UI will **impact all notebooks** attached to that cluster

---

## 標籤系統

### Topic Tags (技術主題標籤)
**Topics:** `Spark-Configuration`, `Cluster-Management`, `Configuration-Scope`

### Trap Tags (陷阱類型標籤)
**Traps:** `Configuration-Priority`, `Cluster-Restart-Behavior`

### Knowledge Domain (知識領域)
**Domain:** Data Engineering / Operations

---

## 答案與來源

### 正確答案
**正解:** `D`

### 答案來源
- **來源標註答案:** D
- **社群共識:** D (83%)
- **關聯題目:** 與 Question 90 高度雷同

### 社群討論重點
- **選項 A:** 修改 Cluster 配置會導致 **Cluster 重啟**，會中斷正在運行的作業
- **選項 D (正確):** hamzaKhribi 實測確認，Cluster UI 設定的 Spark 配置會影響所有連接的 Notebook
- **優先級:** Notebook 內設定（Session level）**優先於** Cluster level，所以選項 C 錯誤

---

# 題目解析

---

## 📍 考點識別

**核心技術:** Spark Configuration Scope & Priority  
**關鍵概念:** Cluster-level vs Notebook-level 配置、配置優先級

---

## ✅ 正解說明

### D - Cluster UI 設定影響所有 Notebooks

**配置層級架構：**

```
🖥️ Cluster Level Configuration (Clusters UI)
  ├─ 影響範圍：所有連接此 Cluster 的 Notebooks
  ├─ 設定方式：Cluster UI → Spark Config
  └─ 例如：spark.sql.shuffle.partitions = 200
      │
      ├─ 📓 Notebook 1 (未設定) → 使用 200 ✅
      ├─ 📓 Notebook 2 (未設定) → 使用 200 ✅
      └─ 📓 Notebook 3 (設定為 100) → 使用 100 (覆蓋)
```

**設定範例：**

```python
# Cluster UI 中設定：
spark.sql.shuffle.partitions 200
spark.executor.memory 4g

# 所有連接的 Notebook 都會繼承這些設定
spark.conf.get("spark.sql.shuffle.partitions")
# 輸出: "200"
```

---

## ❌ 錯誤選項排除（精簡版）

### A - 修改配置不會中斷作業？❌

**錯誤：** 修改 Cluster Spark 配置**會觸發 Cluster 重啟**，導致：
- 正在運行的 Jobs 中斷
- 所有 SparkSession 重建
- 需要等待 Cluster 重新啟動

### B - Notebook 配置影響所有 Sessions？❌

**錯誤：** Notebook 內設定只影響**該 Notebook 的 SparkSession**，不會影響其他 Notebooks：

```python
# Notebook A
spark.conf.set("spark.sql.shuffle.partitions", "100")
# 只影響 Notebook A

# Notebook B (同一個 Cluster)
spark.conf.get("spark.sql.shuffle.partitions")
# 輸出: "200" (Cluster 預設值，不受 Notebook A 影響)
```

### C - Notebook 設定總是被忽略？❌

**錯誤：** 實際上**優先級相反**：

```
配置優先級（高 → 低）：
1. Notebook/Session Level (最高)
2. Cluster Level
3. Spark Default
```

範例：
```python
# Cluster 設定: shuffle.partitions = 200
# Notebook 設定:
spark.conf.set("spark.sql.shuffle.partitions", "50")
# 實際使用: 50 ✅ (Notebook 覆蓋 Cluster)
```

---

## 🧠 記憶法

### 口訣
**「Cluster 設定全共享，Notebook 覆蓋更優先」**

### 配置優先級金字塔

```
        📓 Notebook Level (最高優先級)
              ↓ 覆蓋
        🖥️ Cluster Level
              ↓ 覆蓋
        ⚙️ Spark Default
```

### 快速判斷表

| 情境 | Cluster 設定 | Notebook 設定 | 實際使用 |
|------|-------------|--------------|---------|
| 情境 1 | 200 | 未設定 | **200** (Cluster) |
| 情境 2 | 200 | 100 | **100** (Notebook 覆蓋) |
| 情境 3 | 未設定 | 50 | **50** (Notebook) |

---

## 💡 實務重點

### 最佳實務

```python
# ✅ Cluster 設定：通用配置
# 在 Cluster UI 設定基本配置
spark.sql.adaptive.enabled true
spark.sql.shuffle.partitions 200

# ✅ Notebook 設定：特殊需求
# 大資料量處理
spark.conf.set("spark.sql.shuffle.partitions", "400")

# 小資料量處理
spark.conf.set("spark.sql.shuffle.partitions", "10")
```

### 常見陷阱

⚠️ **修改 Cluster 配置 = Cluster 重啟**  
⚠️ **Notebook 設定不會影響其他 Notebooks**  
⚠️ **優先級：Notebook > Cluster > Default**

---

## 📚 參考文件

- [Databricks Docs - Spark Configuration](https://docs.databricks.com/clusters/configure.html#spark-configuration)
- [Apache Spark Docs - Configuration](https://spark.apache.org/docs/latest/configuration.html)

---

## 🎯 考試技巧

**關鍵判斷：**
- 看到「**without interrupting**」→ 通常是錯的（配置變更需重啟）
- 看到「**all notebooks**」在 Cluster level → 正確
- 看到「**always be ignored**」→ 檢查優先級（通常 Notebook > Cluster）

**快速記憶：**
- Cluster 配置 = **共享基礎設定**
- Notebook 配置 = **個別覆蓋設定**
- 修改 Cluster = **重啟**（會中斷）
