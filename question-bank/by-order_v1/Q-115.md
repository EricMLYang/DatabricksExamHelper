# Question #115

---

## é¡Œç›®è³‡è¨Š

### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-115`

### ä¾†æº
**ä¾†æº:** Mock Exam / Community Contributed

### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹

When using **CLI or REST API** to get results from **jobs with multiple tasks**, which statement correctly describes the response structure?

### é¸é …

- **A.** Each run of a job will have a unique `job_id`; all tasks within this job will have a unique `job_id`
- **B.** Each run of a job will have a unique `job_id`; all tasks within this job will have a unique `task_id`
- **C.** Each run of a job will have a unique `orchestration_id`; all tasks within this job will have a unique `run_id`
- **D.** Each run of a job will have a unique `run_id`; all tasks within this job will have a unique `task_id`
- **E.** Each run of a job will have a unique `run_id`; all tasks within this job will also have a unique `run_id`

---

## æ¨™ç±¤ç³»çµ±

### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Jobs-API`, `Multi-Task-Jobs`, `Workflow-Orchestration`

### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `ID-Naming-Confusion`, `Job-vs-Run-vs-Task`

### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Operations

---

## ç­”æ¡ˆèˆ‡ä¾†æº

### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `D`

### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** D
- **ç¤¾ç¾¤å…±è­˜:** D (100%)

### ç¤¾ç¾¤è¨è«–é‡é»
- **MDWPartners:** é¸æ“‡ Dï¼Œé€™æ˜¯æ­£ç¢ºçš„
- **è£œå……èªªæ˜:** æ­¤é¡Œæ¸¬é©— Databricks Jobs API å°æ–¼ Multi-task job run çš„è­˜åˆ¥çµæ§‹ã€‚ç•¶è§¸ç™¼ä¸€æ¬¡ Job æ™‚ï¼Œæœƒç”¢ç”Ÿä¸€å€‹å…¨åŸŸå”¯ä¸€çš„ `run_id` (Parent Run)ã€‚è©² Job å…§åŒ…å«çš„å¤šå€‹ Task åœ¨åŸ·è¡Œæ™‚ï¼Œé€šå¸¸åœ¨ API å›æ‡‰çµæ§‹ä¸­æœƒä»¥ tasks é™£åˆ—å‘ˆç¾ï¼Œæ¯å€‹ Task æœƒæœ‰å…¶å°æ‡‰çš„è­˜åˆ¥ç¬¦ (`task_id` æˆ– `task_key`) ä»¥åŠè©² Task åŸ·è¡Œçš„ `run_id`

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥

**æ ¸å¿ƒæŠ€è¡“:** Databricks Jobs API & Multi-Task Workflows  
**é—œéµæ¦‚å¿µ:** Job èˆ‡ Run çš„å±¤ç´šé—œä¿‚ã€Task è­˜åˆ¥æ©Ÿåˆ¶

**é¡Œç›®é—œéµå­—ï¼š**
- **Jobs with multiple tasks** (å¤šä»»å‹™å·¥ä½œæµ)
- **CLI or REST API** (API å›æ‡‰çµæ§‹)
- **Response structure** (å›æ‡‰è³‡æ–™çµæ§‹)

**è€ƒç¶±å°æ‡‰:**
- Part 2: ç¶­é‹èˆ‡è‡ªå‹•åŒ– â†’ Jobs API & Workflow Orchestration

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ D (run_id + task_id) æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**æŠ€è¡“åŸç†ï¼š**

Databricks Jobs API çš„è­˜åˆ¥å±¤ç´šï¼š

```
ğŸ“¦ Job (å®šç¾©)
 â”œâ”€â”€ job_id: 1234567890  â† éœæ…‹ IDï¼ˆJob å»ºç«‹æ™‚ç”¢ç”Ÿï¼‰
 â”‚
 â””â”€â”€ ğŸƒ Run (åŸ·è¡Œå¯¦ä¾‹)
      â”œâ”€â”€ run_id: 98765  â† å‹•æ…‹ IDï¼ˆæ¯æ¬¡è§¸ç™¼ç”¢ç”Ÿï¼‰
      â”‚
      â””â”€â”€ ğŸ“‹ Tasks (ä»»å‹™åˆ—è¡¨)
           â”œâ”€â”€ Task 1
           â”‚   â”œâ”€â”€ task_id: "data_ingestion"  â† éœæ…‹ IDï¼ˆå®šç¾©æ™‚æŒ‡å®šï¼‰
           â”‚   â””â”€â”€ run_id: 98765-task-1       â† è©² Task çš„åŸ·è¡Œ run_id
           â”‚
           â”œâ”€â”€ Task 2
           â”‚   â”œâ”€â”€ task_id: "data_transform"
           â”‚   â””â”€â”€ run_id: 98765-task-2
           â”‚
           â””â”€â”€ Task 3
               â”œâ”€â”€ task_id: "data_validation"
               â””â”€â”€ run_id: 98765-task-3
```

**API å›æ‡‰ç¯„ä¾‹ï¼š**

```json
{
  "job_id": 1234567890,           // â† Job å®šç¾© ID (å›ºå®š)
  "run_id": 98765,                // â† æ­¤æ¬¡åŸ·è¡Œçš„ Run ID (å”¯ä¸€)
  "state": {
    "life_cycle_state": "RUNNING"
  },
  "tasks": [                      // â† Tasks é™£åˆ—
    {
      "task_key": "data_ingestion",  // â† Task è­˜åˆ¥ç¬¦ (task_id)
      "run_id": 98765,                // â† æ­¤ Task å±¬æ–¼é€™å€‹ Run
      "state": "SUCCESS"
    },
    {
      "task_key": "data_transform",
      "run_id": 98765,
      "state": "RUNNING"
    },
    {
      "task_key": "data_validation",
      "run_id": 98765,
      "state": "PENDING"
    }
  ]
}
```

**æ ¸å¿ƒæ¦‚å¿µå°æ¯”ï¼š**

| ID é¡å‹ | å”¯ä¸€æ€§ | ç”¢ç”Ÿæ™‚æ©Ÿ | èªªæ˜ |
|---------|--------|----------|------|
| **job_id** | å›ºå®šä¸è®Š | Job å»ºç«‹æ™‚ | è­˜åˆ¥ Job å®šç¾©æœ¬èº« |
| **run_id** | æ¯æ¬¡åŸ·è¡Œå”¯ä¸€ | è§¸ç™¼ Job æ™‚ | è­˜åˆ¥æŸæ¬¡å…·é«”åŸ·è¡Œ |
| **task_id / task_key** | åœ¨ Job å…§å”¯ä¸€ | Job å®šç¾©æ™‚ | è­˜åˆ¥ Job å…§çš„æŸå€‹ Task |

**é¸é … D çš„æ­£ç¢ºæ€§ï¼š**

```python
# ä½¿ç”¨ Databricks CLI æŸ¥è©¢ Job Run
databricks runs get --run-id 98765

# å›æ‡‰çµæ§‹
{
  "run_id": 98765,  # âœ… æ¯æ¬¡ Run æœ‰å”¯ä¸€çš„ run_id
  "tasks": [
    {
      "task_key": "data_ingestion",  # âœ… æ¯å€‹ Task æœ‰å”¯ä¸€çš„ task_id
      "run_id": 98765                # Task å±¬æ–¼é€™å€‹ Run
    }
  ]
}
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### A - job_id + job_id

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

```
âŒ é¸é … A çš„éŒ¯èª¤çµæ§‹ï¼š
æ¯æ¬¡åŸ·è¡Œæœ‰å”¯ä¸€çš„ job_id  â† éŒ¯èª¤ï¼æ‡‰è©²æ˜¯ run_id
æ¯å€‹ Task æœ‰å”¯ä¸€çš„ job_id â† éŒ¯èª¤ï¼æ‡‰è©²æ˜¯ task_id
```

**éŒ¯èª¤ç†ç”±ï¼š**

| å•é¡Œ | èªªæ˜ |
|------|------|
| **job_id æ˜¯éœæ…‹çš„** | job_id åœ¨ Job å»ºç«‹æ™‚å°±å›ºå®šäº†ï¼Œä¸æœƒæ¯æ¬¡åŸ·è¡Œéƒ½ç”¢ç”Ÿæ–°çš„ |
| **Task ä¸ä½¿ç”¨ job_id** | Task ä½¿ç”¨ `task_key` æˆ– `task_id` ä¾†è­˜åˆ¥ï¼Œä¸æ˜¯ `job_id` |
| **æ¦‚å¿µæ··æ·†** | æ··æ·†äº†ã€ŒJob å®šç¾©ã€èˆ‡ã€ŒJob åŸ·è¡Œã€ |

**å¯¦éš›å°æ¯”ï¼š**

```python
# ç¬¬ä¸€æ¬¡åŸ·è¡Œ
{"job_id": 123, "run_id": 1001, "tasks": [...]}

# ç¬¬äºŒæ¬¡åŸ·è¡Œï¼ˆåŒä¸€å€‹ Jobï¼‰
{"job_id": 123, "run_id": 1002, "tasks": [...]}
# â†‘ job_id ç›¸åŒï¼Œä½† run_id ä¸åŒ
```

---

### B - job_id + task_id

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

```
âŒ é¸é … B çš„éŒ¯èª¤ï¼š
æ¯æ¬¡åŸ·è¡Œæœ‰å”¯ä¸€çš„ job_id  â† éŒ¯èª¤ï¼æ‡‰è©²æ˜¯ run_id
æ¯å€‹ Task æœ‰å”¯ä¸€çš„ task_id â† æ­£ç¢ºï¼ä½†å‰åŠéŒ¯äº†
```

**éŒ¯èª¤ç†ç”±ï¼š**

| å•é¡Œ | èªªæ˜ |
|------|------|
| **job_id ä¸ä»£è¡¨åŸ·è¡Œ** | æ¯æ¬¡åŸ·è¡Œæ‡‰è©²ç”¨ `run_id` è­˜åˆ¥ï¼Œè€Œé `job_id` |
| **å¾ŒåŠæ­£ç¢º** | Task ç¢ºå¯¦ä½¿ç”¨ `task_id`ï¼Œä½†æ•´é«”ç­”æ¡ˆéŒ¯èª¤ |

---

### C - orchestration_id + run_id

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

```
âŒ é¸é … C çš„éŒ¯èª¤ï¼š
æ¯æ¬¡åŸ·è¡Œæœ‰å”¯ä¸€çš„ orchestration_id  â† ä¸å­˜åœ¨æ­¤æ¬„ä½ï¼
æ¯å€‹ Task æœ‰å”¯ä¸€çš„ run_id          â† ä¸æ­£ç¢ºï¼
```

**éŒ¯èª¤ç†ç”±ï¼š**

| å•é¡Œ | èªªæ˜ |
|------|------|
| **orchestration_id ä¸å­˜åœ¨** | Databricks API æ²’æœ‰é€™å€‹æ¬„ä½åç¨± |
| **Task ä¸ç”¨ run_id è­˜åˆ¥** | Task ç”¨ `task_key` æˆ– `task_id` è­˜åˆ¥ |
| **å®Œå…¨éŒ¯èª¤** | å…©å€‹éƒ¨åˆ†éƒ½ä¸ç¬¦åˆå¯¦éš› API çµæ§‹ |

---

### E - run_id + run_id

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

```
âŒ é¸é … E çš„éŒ¯èª¤ï¼š
æ¯æ¬¡åŸ·è¡Œæœ‰å”¯ä¸€çš„ run_id  â† æ­£ç¢ºï¼
æ¯å€‹ Task ä¹Ÿæœ‰å”¯ä¸€çš„ run_id â† éŒ¯èª¤ï¼æ‡‰è©²æ˜¯ task_id
```

**éŒ¯èª¤ç†ç”±ï¼š**

| å•é¡Œ | èªªæ˜ |
|------|------|
| **Task ä¸ç”¨ run_id è­˜åˆ¥** | Task ä½¿ç”¨ `task_key` (æˆ– `task_id`)ï¼Œä¸æ˜¯ `run_id` |
| **æ¦‚å¿µæ··æ·†** | æ··æ·†äº†ã€Œè­˜åˆ¥ Taskã€èˆ‡ã€ŒTask æ‰€å±¬çš„ Runã€ |

**é‡æ¸…æ¦‚å¿µï¼š**

```json
{
  "run_id": 98765,          // â† Job Run çš„ ID
  "tasks": [
    {
      "task_key": "task_1",  // â† è­˜åˆ¥é€™æ˜¯å“ªå€‹ Task (ä¸æ˜¯ run_id)
      "run_id": 98765        // â† é€™å€‹ Task å±¬æ–¼ run_id=98765 é€™æ¬¡åŸ·è¡Œ
    }
  ]
}
```

Task æœ‰å…©å€‹ç›¸é—œçš„ IDï¼š
- **task_key/task_id** â†’ è­˜åˆ¥ã€Œé€™æ˜¯å“ªå€‹ Taskã€ï¼ˆä¾‹å¦‚ï¼šdata_ingestionï¼‰
- **run_id** â†’ è­˜åˆ¥ã€Œé€™å€‹ Task å±¬æ–¼å“ªæ¬¡ Runã€

---

## ğŸ§  è¨˜æ†¶æ³•èˆ‡å°æ¯”

### å£è¨£è¨˜æ†¶
**ã€ŒRun ç”¨ run_idï¼ŒTask ç”¨ task_idã€**  
**ã€ŒåŸ·è¡Œçœ‹ runï¼Œä»»å‹™çœ‹ taskã€**

### ä¸‰å±¤ç´šè­˜åˆ¥çµæ§‹

```
ğŸ“¦ Job Level
   â””â”€ job_id (å›ºå®š ID)
      â”‚
      ğŸƒ Run Level (æ¯æ¬¡åŸ·è¡Œ)
         â””â”€ run_id (å‹•æ…‹ ID)
            â”‚
            ğŸ“‹ Task Level
               â””â”€ task_id / task_key (å›ºå®š ID)
```

### å°æ¯”è¡¨ï¼šID é¡å‹

| ID åç¨± | å±¤ç´š | å”¯ä¸€æ€§ç¯„åœ | ç”¢ç”Ÿæ™‚æ©Ÿ | ç”¨é€” |
|---------|------|-----------|----------|------|
| **job_id** | Job | å…¨åŸŸå”¯ä¸€ | Job å»ºç«‹æ™‚ | è­˜åˆ¥ Job å®šç¾© |
| **run_id** | Run | å…¨åŸŸå”¯ä¸€ | æ¯æ¬¡è§¸ç™¼æ™‚ | è­˜åˆ¥æŸæ¬¡åŸ·è¡Œ |
| **task_key / task_id** | Task | Job å…§å”¯ä¸€ | Job å®šç¾©æ™‚ | è­˜åˆ¥ Job å…§çš„ Task |

### å¯¦å‹™ç¯„ä¾‹å°æ¯”

```python
# æƒ…å¢ƒï¼šåŒä¸€å€‹ Job åŸ·è¡Œ 3 æ¬¡

# ç¬¬ 1 æ¬¡åŸ·è¡Œ
{
  "job_id": 123,      # â† å›ºå®šä¸è®Š
  "run_id": 1001,     # â† å”¯ä¸€
  "tasks": [
    {"task_key": "ingest"},  # â† å›ºå®šä¸è®Š
    {"task_key": "transform"}
  ]
}

# ç¬¬ 2 æ¬¡åŸ·è¡Œ
{
  "job_id": 123,      # â† ç›¸åŒ
  "run_id": 1002,     # â† ä¸åŒï¼ˆæ–°åŸ·è¡Œï¼‰
  "tasks": [
    {"task_key": "ingest"},  # â† ç›¸åŒï¼ˆåŒæ¨£çš„ Task å®šç¾©ï¼‰
    {"task_key": "transform"}
  ]
}

# ç¬¬ 3 æ¬¡åŸ·è¡Œ
{
  "job_id": 123,      # â† ç›¸åŒ
  "run_id": 1003,     # â† ä¸åŒï¼ˆåˆä¸€æ¬¡æ–°åŸ·è¡Œï¼‰
  "tasks": [
    {"task_key": "ingest"},  # â† ç›¸åŒ
    {"task_key": "transform"}
  ]
}
```

---

## ğŸ’¡ å¯¦å‹™æ‡‰ç”¨

### ä½¿ç”¨ Databricks CLI æŸ¥è©¢

```bash
# æŸ¥è©¢ç‰¹å®š Job çš„æ‰€æœ‰åŸ·è¡Œ
databricks jobs runs list --job-id 123

# æŸ¥è©¢ç‰¹å®š Run çš„è©³ç´°è³‡è¨Š
databricks runs get --run-id 1001

# æŸ¥è©¢ç‰¹å®š Task çš„åŸ·è¡Œçµæœ
databricks runs get-output --run-id 1001 --task-key ingest
```

### ä½¿ç”¨ REST API æŸ¥è©¢

```python
import requests

# API Endpoint
base_url = "https://<databricks-instance>/api/2.1"

# æŸ¥è©¢ Run è©³æƒ…
response = requests.get(
    f"{base_url}/jobs/runs/get",
    headers={"Authorization": f"Bearer {token}"},
    params={"run_id": 1001}
)

data = response.json()
print(f"Run ID: {data['run_id']}")
print(f"Job ID: {data['job_id']}")

# éæ­· Tasks
for task in data['tasks']:
    print(f"Task: {task['task_key']}, State: {task['state']}")
```

### ç›£æ§ Multi-Task Job

```python
def monitor_job_run(run_id):
    """ç›£æ§ Multi-Task Job çš„åŸ·è¡Œç‹€æ…‹"""
    response = requests.get(
        f"{base_url}/jobs/runs/get",
        headers={"Authorization": f"Bearer {token}"},
        params={"run_id": run_id}
    )
    
    data = response.json()
    
    print(f"ğŸ“¦ Job ID: {data['job_id']}")
    print(f"ğŸƒ Run ID: {data['run_id']}")
    print(f"ğŸ“Š Overall State: {data['state']['life_cycle_state']}")
    print("\nğŸ“‹ Tasks:")
    
    for task in data['tasks']:
        task_id = task['task_key']  # â† Task è­˜åˆ¥ç¬¦
        task_state = task['state']['life_cycle_state']
        print(f"  - {task_id}: {task_state}")

# ä½¿ç”¨ç¯„ä¾‹
monitor_job_run(98765)

# è¼¸å‡ºï¼š
# ğŸ“¦ Job ID: 1234567890
# ğŸƒ Run ID: 98765
# ğŸ“Š Overall State: RUNNING
# 
# ğŸ“‹ Tasks:
#   - data_ingestion: SUCCESS
#   - data_transform: RUNNING
#   - data_validation: PENDING
```

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶åƒè€ƒ

1. **Jobs API 2.1:**
   - [Databricks Docs - Jobs API](https://docs.databricks.com/api/workspace/jobs)

2. **Multi-Task Jobs:**
   - [Databricks Docs - Create Multi-Task Jobs](https://docs.databricks.com/workflows/jobs/jobs.html)

3. **Runs API:**
   - [Databricks Docs - Runs API](https://docs.databricks.com/api/workspace/jobs/getruns)

---

## ğŸ¯ è€ƒè©¦æŠ€å·§

**é‡åˆ° Jobs API é¡Œç›®æ™‚ï¼š**

1. âœ… **å€åˆ†ä¸‰å€‹å±¤ç´š** â†’ Job / Run / Task
2. âœ… **è¨˜ä½ ID å‘½å** â†’ job_id / run_id / task_key
3. âœ… **ç†è§£å”¯ä¸€æ€§** â†’ run_id æ¯æ¬¡åŸ·è¡Œå”¯ä¸€ï¼Œtask_key åœ¨ Job å…§å”¯ä¸€

**é—œéµåˆ¤æ–·ï¼š**

| é—œéµå­— | å°æ‡‰ ID |
|--------|---------|
| **æ¯æ¬¡åŸ·è¡Œ** / **Each run** | â†’ run_id |
| **ä»»å‹™** / **Task** | â†’ task_key / task_id |
| **å·¥ä½œå®šç¾©** / **Job definition** | â†’ job_id |

**é™·é˜±è­¦ç¤ºï¼š**
- âš ï¸ ä¸è¦æ··æ·† `job_id`ï¼ˆéœæ…‹ï¼‰èˆ‡ `run_id`ï¼ˆå‹•æ…‹ï¼‰
- âš ï¸ æ³¨æ„ API æ–‡ä»¶ä½¿ç”¨ `task_key`ï¼Œä½†æ¦‚å¿µä¸Šä¹Ÿç¨±ç‚º `task_id`
- âš ï¸ `orchestration_id` ä¸å­˜åœ¨æ–¼ Databricks API
