# Question #49

---

## 題目資訊

### 題目編號
**ID:** `Q-049`

### 來源
**來源:** Real Exam Recall

### 難度等級
**難度:** `L2-Intermediate`

---

## 題目內容

### 題幹

A user new to Databricks is trying to troubleshoot long execution times for some pipeline logic they are working on.

Presently, the user is executing code cell-by-cell, using display() calls to confirm code is producing the logically correct results as new transformations are added to an operation.

To get a measure of average time to execute, the user is running each cell multiple times interactively.

Which of the following adjustments will get a more accurate measure of how code is likely to perform in production?

### 選項

- **A.** Scala is the only language that can be accurately tested using interactive notebooks; because the best performance is achieved by using Scala code compiled to JARs, all PySpark and Spark SQL logic should be refactored.
- **B.** The only way to meaningfully troubleshoot code execution times in development notebooks is to use production-sized data and production-sized clusters with Run All execution.
- **C.** Production code development should only be done using an IDE; executing code against a local build of open source Spark and Delta Lake will provide the most accurate benchmarks for how code will perform in production.
- **D.** Calling display() forces a job to trigger, while many transformations will only add to the logical query plan; because of caching, repeated execution of the same logic does not provide meaningful results.
- **E.** The Jobs UI should be leveraged to occasionally run the notebook as a job and track execution time during incremental code development because Photon can only be enabled on clusters launched for scheduled jobs.

---

## 標籤系統

### Topic Tags (技術主題標籤)
**Topics:** `Performance-Testing`, `Notebooks`, `Lazy-Evaluation`, `Caching`, `display()`

### Trap Tags (陷阱類型標籤)
**Traps:** `Interactive-vs-Production`, `Caching-Effects`

### Knowledge Domain (知識領域)
**Domain:** `Development Practices`

---

## 答案與解析連結

### 正確答案
**正解:** `D`

### 解析檔案
**詳細解析:** [點此查看解析](../analysis/Q-049-analysis.md)

---

## 相關資源

### 官方文件
- [Lazy Evaluation in Spark](https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-operations)
- [display() Function](https://docs.databricks.com/notebooks/visualizations/index.html)
- [Databricks Caching](https://docs.databricks.com/optimizations/disk-cache.html)
