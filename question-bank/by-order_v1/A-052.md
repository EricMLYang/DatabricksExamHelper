# Q-052 é¡Œç›®è§£æ

---

## é¡Œç›®å›é¡§

### é¡Œç›®ç·¨è™Ÿèˆ‡é€£çµ

**é¡Œç›® ID:** `Q-052`
**é¡Œç›®é€£çµ:** [é»æ­¤è¿”å›é¡Œç›®](Q-052.md)

### åŸæ–‡é¡Œç›®

**Review the following error traceback:**

```python
AnalysisException
<command-3293767849433948> in <module>
----> 1 display(df.select(3 * "heartrate"))
AnalysisException: cannot resolve 'heartrateheartrateheartrate' given input columns: [spark_catalog.database.table.device_id, spark_catalog.database.table.heartrate, spark_catalog.database.table.name, spark_catalog.database.table.time]
```

**Which statement describes the error being raised?**

**é¸é …ï¼š**
- A. The code executed was PySpark but was executed in a Scala notebook.
- B. There is no column in the table named heartrateheartrateheartrate
- C. There is a type error because a column object cannot be multiplied.
- D. There is a type error because a DataFrame object cannot be multiplied.
- E. There is a syntax error because the heartrate column is not correctly identified as a column.

### æ­£ç¢ºç­”æ¡ˆ

**æ­£è§£:** `E`

---

## ğŸ“ è€ƒé»è­˜åˆ¥

### ä¸»è¦è€ƒé»

**æ ¸å¿ƒæŠ€è¡“:** PySpark Column Reference Syntax
**çŸ¥è­˜é ˜åŸŸ:** PySpark DataFrame Operations
**é—œéµæ¦‚å¿µ:** `Column Objects`, `String Multiplication`, `df.col()` vs `"column_name"`

### æ¬¡è¦è€ƒé»

* Python å­—ä¸²ä¹˜æ³•é‹ç®—çš„è¡Œç‚º
* PySpark ä¸­å¦‚ä½•æ­£ç¢ºå¼•ç”¨æ¬„ä½
* éŒ¯èª¤è¨Šæ¯çš„è§£è®€èƒ½åŠ›

---

## ğŸ”¤ é‡è¦è‹±æ–‡è©èªè¬›è§£ï¼ˆå…ˆç·´é€™äº›å†è§£é¡Œï¼‰

* **error traceback**ï¼šéŒ¯èª¤å›æº¯ï¼ˆé¡¯ç¤ºéŒ¯èª¤ç™¼ç”Ÿçš„ç¨‹å¼ç¢¼ä½ç½®èˆ‡è¨Šæ¯ï¼‰
* **cannot resolve**ï¼šç„¡æ³•è§£æï¼ˆSpark æ‰¾ä¸åˆ°å°æ‡‰çš„æ¬„ä½ï¼‰
* **given input columns**ï¼šçµ¦å®šçš„è¼¸å…¥æ¬„ä½ï¼ˆè¡¨ç¤º DataFrame å¯¦éš›æœ‰å“ªäº›æ¬„ä½ï¼‰
* **syntax error**ï¼šèªæ³•éŒ¯èª¤ï¼ˆå¯«æ³•ä¸ç¬¦åˆè¦å‰‡ï¼‰
* **type error**ï¼šé¡å‹éŒ¯èª¤ï¼ˆè³‡æ–™å‹åˆ¥ä¸å°ï¼‰
* **correctly identified as a column**ï¼šæ­£ç¢ºåœ°è¢«è­˜åˆ¥ç‚ºæ¬„ä½ï¼ˆé—œéµï¼ï¼‰

âœ… **é¡Œç›®è¨Šè™Ÿå¾ˆæ˜ç¢ºï¼š**ã€Œ`3 * "heartrate"`ã€ï¼‹ã€Œcannot resolve 'heartrateheartrateheartrate'ã€ï¼ **æ¬„ä½å¼•ç”¨èªæ³•éŒ¯èª¤**ã€‚

---

## ğŸ§© Databricks / Spark å‰æè³‡è¨Šï¼ˆæ­£è§£èªªæ˜ä¹‹å‰å…ˆè£œåº•å±¤æ¦‚å¿µï¼‰

### PySpark ä¸­å¼•ç”¨æ¬„ä½çš„æ­£ç¢ºæ–¹å¼

åœ¨ PySpark è£¡ï¼Œè¦å¼•ç”¨ä¸€å€‹ DataFrame çš„æ¬„ä½ï¼ˆColumnï¼‰ï¼Œæœ‰å¹¾ç¨®æ­£ç¢ºå¯«æ³•ï¼š

```python
# æ–¹æ³• 1ï¼šä½¿ç”¨ col() å‡½å¼ï¼ˆæ¨è–¦ï¼‰
from pyspark.sql.functions import col
df.select(col("heartrate"))

# æ–¹æ³• 2ï¼šä½¿ç”¨ DataFrame çš„å±¬æ€§èªæ³•
df.select(df.heartrate)
df.select(df["heartrate"])

# æ–¹æ³• 3ï¼šåœ¨æŸäº›å‡½å¼ä¸­å¯ä»¥ç›´æ¥ç”¨å­—ä¸²ï¼ˆä½†æœ‰é™åˆ¶ï¼‰
df.select("heartrate")  # é€™å€‹å¯ä»¥ï¼Œå› ç‚º select() æœƒè‡ªå‹•è½‰æ›
```

### éŒ¯èª¤å¯«æ³•ï¼šç›´æ¥ç”¨å­—ä¸²é€²è¡Œé‹ç®—

```python
# âŒ éŒ¯èª¤ï¼šPython æœƒæŠŠ "heartrate" ç•¶æˆå­—ä¸²ï¼Œä¸æ˜¯ Column ç‰©ä»¶
df.select(3 * "heartrate")

# é€™æœƒè§¸ç™¼ Python çš„å­—ä¸²ä¹˜æ³•ï¼š
3 * "heartrate"  # çµæœæ˜¯ "heartrateheartrateheartrate"

# Spark æ¥è‘—å˜—è©¦æŠŠé€™å€‹å­—ä¸²ç•¶æˆæ¬„ä½åç¨±å»æŸ¥æ‰¾
# â†’ æ‰¾ä¸åˆ°åç‚º "heartrateheartrateheartrate" çš„æ¬„ä½
# â†’ å™´å‡º AnalysisException
```

### Python å­—ä¸²ä¹˜æ³•çš„è¡Œç‚º

é€™æ˜¯ Python çš„åŸºæœ¬ç‰¹æ€§ï¼ˆä¸æ˜¯ Spark å°ˆå±¬ï¼‰ï¼š

```python
"abc" * 3      # çµæœï¼š'abcabcabc'
3 * "heartrate"  # çµæœï¼š'heartrateheartrateheartrate'
```

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ E æ˜¯æ­£ç¢ºçš„ï¼Ÿ

**æŠ€è¡“åŸç†ï¼š**
ç¨‹å¼ç¢¼ä¸­çš„ `"heartrate"` æ˜¯ä¸€å€‹ **Python å­—ä¸²ï¼ˆstringï¼‰**ï¼Œä¸æ˜¯ **PySpark Column ç‰©ä»¶**ã€‚ç•¶ä½ å¯« `3 * "heartrate"` æ™‚ï¼ŒPython åŸ·è¡Œçš„æ˜¯ã€Œå­—ä¸²ä¹˜æ³•ã€ï¼Œç”¢ç”Ÿ `"heartrateheartrateheartrate"`ï¼Œç„¶å¾Œ Spark å˜—è©¦æŠŠé€™å€‹å­—ä¸²ç•¶æˆæ¬„ä½åç¨±å»æŸ¥æ‰¾ï¼Œä½† DataFrame è£¡æ²’æœ‰é€™å€‹æ¬„ä½ã€‚

**é¡Œç›®å°æ‡‰ï¼š**

* ã€Œsyntax errorã€â†’ å¼•ç”¨æ¬„ä½çš„å¯«æ³•ä¸æ­£ç¢º
* ã€Œthe heartrate column is not correctly identified as a columnã€â†’ `"heartrate"` æ²’æœ‰è¢«æ­£ç¢ºè­˜åˆ¥ç‚º Column ç‰©ä»¶

**æ ¹æœ¬åŸå› ï¼š**
ç¨‹å¼è¨­è¨ˆè€…æƒ³è¦ã€Œå°‡ heartrate æ¬„ä½ä¹˜ä»¥ 3ã€ï¼Œä½†ç”¨éŒ¯äº†èªæ³•ã€‚æ­£ç¢ºå¯«æ³•æ‡‰è©²æ˜¯ï¼š

```python
# âœ… æ­£ç¢ºå¯«æ³• 1ï¼šä½¿ç”¨ col()
from pyspark.sql.functions import col
display(df.select(3 * col("heartrate")))

# âœ… æ­£ç¢ºå¯«æ³• 2ï¼šä½¿ç”¨ df["column"]
display(df.select(3 * df["heartrate"]))

# âœ… æ­£ç¢ºå¯«æ³• 3ï¼šä½¿ç”¨ df.column
display(df.select(3 * df.heartrate))
```

**å¯¦å‹™æ‡‰ç”¨ï¼ˆDatabricks å¸¸è¦‹éŒ¯èª¤ï¼‰ï¼š**

é€™æ˜¯åˆå­¸è€…æœ€å¸¸çŠ¯çš„éŒ¯èª¤ä¹‹ä¸€ï¼è¨˜ä½ï¼š

* **ç›´æ¥å­—ä¸²** `"column_name"` â†’ åªèƒ½ç”¨åœ¨ `select()`, `groupBy()` ç­‰ã€Œæœƒè‡ªå‹•è½‰æ›ã€çš„å‡½å¼ä¸­
* **éœ€è¦é‹ç®—** æ™‚ â†’ ä¸€å®šè¦ç”¨ `col()` æˆ– `df["column"]` ä¾†å–å¾— Column ç‰©ä»¶

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### é¸é … A - The code executed was PySpark but was executed in a Scala notebook.

**éŒ¯èª¤åŸå› :** èˆ‡éŒ¯èª¤è¨Šæ¯ç„¡é—œ
**è©³ç´°åˆ†æï¼š**

* å¦‚æœæ˜¯èªè¨€ä¸ç¬¦çš„å•é¡Œï¼ŒéŒ¯èª¤è¨Šæ¯æœƒæ˜¯ã€Œèªæ³•éŒ¯èª¤ã€æˆ–ã€Œç„¡æ³•è­˜åˆ¥çš„èªæ³•ã€
* é€™è£¡çš„éŒ¯èª¤æ˜¯ `AnalysisException: cannot resolve`ï¼Œé€™æ˜¯ **Spark åœ¨åˆ†æéšæ®µæ‰¾ä¸åˆ°æ¬„ä½**çš„éŒ¯èª¤
* è€Œä¸”å¾ `display()` å’Œ `df.select()` çš„èªæ³•çœ‹ï¼Œé€™ç¢ºå¯¦æ˜¯ PySpark ç¨‹å¼ç¢¼

---

### é¸é … B - There is no column in the table named heartrateheartrateheartrate

**éŒ¯èª¤åŸå› :** é€™æ˜¯è¡¨è±¡ï¼Œä¸æ˜¯æ ¹æœ¬åŸå› 
**è©³ç´°åˆ†æï¼š**

* **è¡¨é¢ä¸Šçœ‹æ˜¯å°çš„ï¼š** ç¢ºå¯¦æ²’æœ‰åç‚º `heartrateheartrateheartrate` çš„æ¬„ä½
* **ä½†é€™ä¸æ˜¯ã€Œæ ¹æœ¬å•é¡Œã€ï¼š** é€™å€‹å¥‡æ€ªçš„æ¬„ä½åç¨±æ˜¯ã€Œçµæœã€ï¼Œä¸æ˜¯ã€ŒåŸå› ã€

âš ï¸ **é€™æ˜¯æœ€å¤§çš„é™·é˜±ï¼** é¡Œç›®å•çš„æ˜¯ã€Œdescribes the error being raisedã€ï¼ˆæè¿°éŒ¯èª¤çš„ä¾†æºï¼‰ï¼Œä¸æ˜¯ã€ŒéŒ¯èª¤è¨Šæ¯çš„å­—é¢å…§å®¹ã€ã€‚

âœ… é—œéµå·®ç•°ï¼š

* é¸é … Bï¼šæè¿°ã€Œç—‡ç‹€ã€ï¼ˆSpark æ‰¾ä¸åˆ°é€™å€‹æ¬„ä½ï¼‰
* é¸é … Eï¼šæè¿°ã€Œç—…å› ã€ï¼ˆæ¬„ä½å¼•ç”¨èªæ³•éŒ¯èª¤å°è‡´ç”¢ç”ŸéŒ¯èª¤çš„æ¬„ä½åç¨±ï¼‰

**ç‚ºä»€éº¼ E æ¯” B æ›´å¥½ï¼Ÿ**

* **E æŒ‡å‡ºäº†ç¨‹å¼è¨­è¨ˆè€…çš„éŒ¯èª¤ï¼š** æ²’æœ‰æ­£ç¢ºè­˜åˆ¥æ¬„ä½ï¼ˆæ‡‰è©²ç”¨ `col("heartrate")` è€Œä¸æ˜¯ `"heartrate"`ï¼‰
* **B åªæ˜¯æè¿°çµæœï¼š** ç•¶ç„¶æ²’æœ‰é€™å€‹æ¬„ä½ï¼Œå› ç‚ºå®ƒæ˜¯å­—ä¸²ä¹˜æ³•ç”¢ç”Ÿçš„

---

### é¸é … C - There is a type error because a column object cannot be multiplied.

**éŒ¯èª¤åŸå› :** äº‹å¯¦ç›¸å
**è©³ç´°åˆ†æï¼š**

* PySpark Column ç‰©ä»¶ **å¯ä»¥** é€²è¡Œæ•¸å­¸é‹ç®—ï¼ˆä¹˜æ³•ã€åŠ æ³•ç­‰ï¼‰
* æ­£ç¢ºçš„å¯«æ³• `3 * col("heartrate")` æ˜¯å®Œå…¨åˆæ³•çš„

```python
# âœ… Column ç‰©ä»¶å¯ä»¥é€²è¡Œé‹ç®—
df.select(col("heartrate") * 3)  # åˆæ³•
df.select(col("value") + 100)    # åˆæ³•
df.select(col("price") / 2)      # åˆæ³•
```

---

### é¸é … D - There is a type error because a DataFrame object cannot be multiplied.

**éŒ¯èª¤åŸå› :** èˆ‡é¡Œç›®ç„¡é—œ
**è©³ç´°åˆ†æï¼š**

* é¡Œç›®ä¸­æ²’æœ‰å° DataFrame ç‰©ä»¶æœ¬èº«é€²è¡Œä¹˜æ³•é‹ç®—
* `df.select(...)` æ˜¯å° DataFrame å‘¼å« `select()` æ–¹æ³•ï¼Œä¸æ˜¯å° `df` é€²è¡Œä¹˜æ³•

---

## ğŸ§  è¨˜æ†¶æ³•èˆ‡è§£é¡ŒæŠ€å·§

### è¨˜æ†¶å£è¨£

**PySpark Column å¼•ç”¨å£è¨£ï¼š**

* **è¦é‹ç®— â†’ ç”¨ `col()` æˆ– `df[]`**
* **ç´”é¸æ“‡ â†’ å¯ä»¥ç”¨å­—ä¸²**

```python
# ç´”é¸æ“‡ï¼ˆOKï¼‰
df.select("heartrate")

# è¦é‹ç®—ï¼ˆå¿…é ˆç”¨ Column ç‰©ä»¶ï¼‰
df.select(3 * col("heartrate"))  # âœ…
df.select(3 * "heartrate")       # âŒ
```

### è§£é¡Œæ­¥é©Ÿ

1. **çœ‹éŒ¯èª¤è¨Šæ¯ï¼š** `'heartrateheartrateheartrate'` â†’ é€™æ˜¯å­—ä¸²é‡è¤‡ 3 æ¬¡
2. **æ‰¾åŸå› ï¼š** `3 * "heartrate"` â†’ Python å­—ä¸²ä¹˜æ³•
3. **åˆ¤æ–·å•é¡Œï¼š** `"heartrate"` æ˜¯å­—ä¸²ï¼Œä¸æ˜¯ Column ç‰©ä»¶
4. **é¸æ“‡ç­”æ¡ˆï¼š** E - æ¬„ä½æ²’æœ‰è¢«æ­£ç¢ºè­˜åˆ¥ç‚º Column

### å¸¸è¦‹é™·é˜±è­¦ç¤º

âš ï¸ **é™·é˜±ï¼šè¢«é¸é … B èª¤å°**
â†’ é›–ç„¶ã€Œç¢ºå¯¦æ²’æœ‰é€™å€‹æ¬„ä½ã€ï¼Œä½†é¡Œç›®è¦çš„æ˜¯ã€Œç‚ºä»€éº¼æœƒç”¢ç”Ÿé€™å€‹éŒ¯èª¤ã€ï¼Œä¸æ˜¯ã€ŒéŒ¯èª¤è¨Šæ¯èªªä»€éº¼ã€

âš ï¸ **é™·é˜±ï¼šä»¥ç‚º Column ä¸èƒ½ä¹˜æ³•**
â†’ Column ç‰©ä»¶å®Œå…¨å¯ä»¥é€²è¡Œæ•¸å­¸é‹ç®—ï¼Œå•é¡Œæ˜¯ä½ æ ¹æœ¬æ²’ç”¨ Column ç‰©ä»¶ï¼ˆç”¨çš„æ˜¯å­—ä¸²ï¼‰

âš ï¸ **é™·é˜±ï¼šä»¥ç‚ºæ˜¯ Scala/Python èªè¨€æ··ç”¨å•é¡Œ**
â†’ éŒ¯èª¤è¨Šæ¯æ˜¯ `AnalysisException`ï¼ˆSpark åˆ†æéšæ®µï¼‰ï¼Œä¸æ˜¯èªæ³•éŒ¯èª¤

---

## ğŸ“š å»¶ä¼¸çŸ¥è­˜ï¼ˆé¸è®€ï¼‰

### PySpark ä¸­å­—ä¸²èˆ‡ Column çš„è‡ªå‹•è½‰æ›è¦å‰‡

ä¸¦éæ‰€æœ‰åœ°æ–¹éƒ½éœ€è¦æ˜ç¢ºä½¿ç”¨ `col()`ï¼Œæœ‰äº›å‡½å¼æœƒè‡ªå‹•è½‰æ›ï¼š

```python
# é€™äº›æœƒè‡ªå‹•è½‰æ›å­—ä¸²ç‚º Columnï¼ˆOKï¼‰
df.select("heartrate")
df.groupBy("device_id")
df.orderBy("time")

# é€™äº›éœ€è¦æ˜ç¢ºçš„ Column ç‰©ä»¶ï¼ˆéœ€è¦ col()ï¼‰
df.select(col("heartrate") * 3)
df.filter(col("heartrate") > 100)
df.withColumn("new_col", col("old_col") + 1)
```

### Python å­—ä¸²ä¹˜æ³• vs PySpark Column ä¹˜æ³•

```python
# Python å­—ä¸²ä¹˜æ³•ï¼ˆç”¢ç”Ÿé‡è¤‡å­—ä¸²ï¼‰
3 * "abc"  # çµæœï¼š'abcabcabc'

# PySpark Column ä¹˜æ³•ï¼ˆå°æ¯å€‹å€¼é€²è¡Œæ•¸å­¸é‹ç®—ï¼‰
3 * col("heartrate")  # çµæœï¼šColumn ç‰©ä»¶ï¼Œæ¯å€‹å€¼ä¹˜ä»¥ 3
```

### åœ¨ Databricks Notebook ä¸­é™¤éŒ¯çš„æŠ€å·§

```python
# æª¢æŸ¥è¡¨é”å¼çš„é¡å‹
print(type("heartrate"))              # <class 'str'>
print(type(col("heartrate")))         # <class 'pyspark.sql.column.Column'>
print(type(3 * "heartrate"))          # <class 'str'>
print(type(3 * col("heartrate")))     # <class 'pyspark.sql.column.Column'>

# å°å‡ºå¯¦éš›çš„å€¼
print(3 * "heartrate")  # heartrateheartrateheartrate
```

---

## ğŸ·ï¸ æ¨™ç±¤èˆ‡åˆ†é¡

**Topics:** `PySpark`, `Column-Operations`, `Error-Handling`, `Column-Reference`, `Syntax`
**Traps:** `String-Multiplication`, `Surface-vs-Root-Cause`, `Column-vs-String`
**Difficulty:** `L2-Intermediate`
**Domain:** `PySpark`

---

## ç›¸é—œè³‡æº

### å®˜æ–¹æ–‡ä»¶
- [PySpark Column Operations](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/column.html)
- [DataFrame Select](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.select.html)
- [PySpark SQL Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html)
