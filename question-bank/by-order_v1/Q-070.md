# Question #70

---

## é¡Œç›®è³‡è¨Š

### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-070`

### ä¾†æº
**ä¾†æº:** Community Contributed (Real Exam-style)

### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹
A data ingestion task requires a one-TB JSON dataset to be written out to Parquet with a target part-file size of 512 MB. Because Parquet is being used instead of Delta Lake, built-in file-sizing features such as Auto-Optimize & Auto-Compaction cannot be used.

Which strategy will yield the best performance without shuffling data?

### é¸é …
- **A.** Set `spark.sql.files.maxPartitionBytes` to 512 MB, ingest the data, execute the narrow transformations, and then write to Parquet.
- **B.** Set `spark.sql.shuffle.partitions` to 2,048 partitions (1 TB Ã— 1024 Ã— 1024 Ã· 512), ingest the data, execute the narrow transformations, optimize the data by sorting it (which automatically repartitions the data), and then write to Parquet.
- **C.** Set `spark.sql.adaptive.advisoryPartitionSizeInBytes` to 512 MB bytes, ingest the data, execute the narrow transformations, coalesce to 2,048 partitions (1 TB Ã— 1024 Ã— 1024 Ã· 512) and then write to Parquet.
- **D.** Ingest the data, execute the narrow transformations, repartition to 2,048 partitions (1 TB Ã— 1024 Ã— 1024 Ã· 512), and then write to Parquet.
- **E.** Set `spark.sql.shuffle.partitions` to 512, ingest the data, execute the narrow transformations, and then write to Parquet.

---

## æ¨™ç±¤ç³»çµ±

### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Spark-Performance`, `Partitioning`, `File-Formats`

### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Performance-Misconception`, `Execution-Behavior`

### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** `Spark`

---

## ç­”æ¡ˆèˆ‡è§£æé€£çµ

### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `A`

### è§£ææª”æ¡ˆ
**è©³ç´°è§£æ:** ä¸‹æ–¹æ•´åˆè§£æ

---

## ç›¸é—œè³‡æº

### å®˜æ–¹æ–‡ä»¶
- [Spark Performance Tuning](https://spark.apache.org/docs/latest/sql-performance-tuning.html)
- [spark.sql.files.maxPartitionBytes](https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration)

---

## è§£é¡Œè§£æï¼ˆæ•´åˆï¼‰

### ç‚ºä»€éº¼ A æ˜¯æ­£ç¢ºçš„ï¼Ÿ
- `spark.sql.files.maxPartitionBytes` æ§åˆ¶è®€å–æ™‚çš„åˆ†å‰²å¤§å°ä¸¦å½±éŸ¿è¼¸å‡ºåˆ†å€è¦åŠƒï¼Œè¨­å®šç‚º 512 MB å¯è®“è¼¸å‡ºæª”æ¡ˆè‡ªç„¶è²¼è¿‘ç›®æ¨™å¤§å°ã€‚
- é¡Œç›®æ˜ç¢ºå¼·èª¿ã€ŒåªåŸ·è¡Œçª„è½‰æ›ã€ï¼Œå› æ­¤ä¸éœ€è¦é‡æ–°åˆ†å‰²æˆ–æ´—ç‰Œï¼›ä¿æŒç¾æœ‰åˆ†å€é¿å… shuffle èƒ½ç²å¾—æœ€ä½³æ•ˆèƒ½ã€‚
- ç¤¾ç¾¤å¤šæ•¸ï¼ˆ53%ï¼‰æ”¯æŒ Aï¼ŒåŒæ¨£ç†ç”±ï¼šç„¡é ˆè§¸ç™¼ shuffle ä¹Ÿèƒ½é”æˆç›®æ¨™æª”æ¡ˆå¤§å°ã€‚

### éŒ¯èª¤é¸é …æ’é™¤
- **B**ï¼šèª¿é«˜ `spark.sql.shuffle.partitions` ä¸¦æ’åºæœƒè§¸ç™¼å¯¬è½‰æ›åŠ shuffleï¼Œèˆ‡ã€Œä¸æ´—ç‰Œã€è¦æ±‚è¡çªï¼Œä¸”æ’åºç‚ºé¡å¤–æˆæœ¬ã€‚
- **C**ï¼š`advisoryPartitionSizeInBytes` æ˜¯è‡ªé©æ‡‰å»ºè­°å€¼ï¼Œéœ€è¦è§¸ç™¼ AQE shuffle éšæ®µæ‰æœƒç”Ÿæ•ˆï¼›è‹¥åªæœ‰çª„è½‰æ›ï¼Œè¨­å®šç„¡æ•ˆä¸” coalesce æœƒç”¢ç”Ÿé‡æ–°åˆ†é…é–‹éŠ·ã€‚
- **D**ï¼š`repartition` å¼·åˆ¶ shuffle åˆ†å€ï¼Œé•åä¸æ´—ç‰Œçš„æ¢ä»¶ã€‚
- **E**ï¼šèª¿æ•´ `spark.sql.shuffle.partitions` ä»æœƒåœ¨å¯«å…¥æ™‚è§¸ç™¼ shuffle åˆ†å€è¨­å®šï¼›ä¸” 512 åˆ†å€æœƒç”¢ç”Ÿé å¤§æ–¼ 512 MB çš„æª”æ¡ˆï¼Œç„¡æ³•é”åˆ°ç›®æ¨™å¤§å°ã€‚

### è¨˜æ†¶å£è¨£
- **ã€Œç„¡éœ€æ´—ç‰Œ â†’ æ§åˆ†å‰² â†’ maxPartitionBytesã€**ï¼šè‹¥éœ€æ±‚æ˜¯æ§åˆ¶æª”æ¡ˆå¤§å°ä¸”åªæœ‰çª„è½‰æ›ï¼Œå…ˆç”¨ `spark.sql.files.maxPartitionBytes`ï¼Œä¸è¦å‹•ç”¨ `repartition` æˆ–æ’åºã€‚

### è§£é¡Œæ­¥é©Ÿ
1. è®€é¡Œé—œéµï¼šç›®æ¨™æª”æ¡ˆå¤§å° 512 MBã€åƒ…çª„è½‰æ›ã€ä¸å¾—ä¾è³´ Delta Auto-Optimize/Compactionã€é¿å… shuffleã€‚
2. å…ˆæ‰¾èƒ½åœ¨è®€/å¯«éšæ®µæ§åˆ¶åˆ†å‰²å¤§å°ä¸”ä¸è§¸ç™¼ shuffle çš„è¨­å®š â†’ `spark.sql.files.maxPartitionBytes`ã€‚
3. æ’é™¤æœƒå°è‡´ shuffle çš„æ“ä½œï¼š`repartition`ã€æ’åºã€ä¾è³´ shuffle partitionsã€AQE åˆ†å€èª¿æ•´ã€‚
4. é©—è­‰è¼¸å‡ºæª”æ¡ˆå¤§å°èˆ‡æ¢ä»¶ â†’ A æœ€ç¬¦åˆã€‚

### å¸¸è¦‹é™·é˜±è­¦ç¤º
- âš ï¸ **æŠŠ shuffle partitions ç•¶æˆè¼¸å‡ºæª”æ¡ˆå¤§å°æ§åˆ¶**ï¼š`spark.sql.shuffle.partitions` åªå½±éŸ¿ shuffle åˆ†å€ï¼Œä»éœ€è§¸ç™¼ shuffle æ‰ç”Ÿæ•ˆã€‚
- âš ï¸ **èª¤ä»¥ç‚º AQE å»ºè­°å€¼æœƒè‡ªå‹•å¥—ç”¨åœ¨çª„è½‰æ›**ï¼š`advisoryPartitionSizeInBytes` éœ€è¦æœ‰ shuffle/AQE æ‰æœƒèª¿æ•´åˆ†å€ã€‚
- âš ï¸ **èª¤æŠŠæ’åºç•¶æœ€ä½³åŒ–**ï¼šæ’åºæœƒç”¢ç”Ÿå¯¬è½‰æ›èˆ‡ shuffleï¼Œèˆ‡é¡Œç›®ã€Œä¸æ´—ç‰Œã€è¦æ±‚è¡çªã€‚

---

## ğŸ·ï¸ æ¨™ç±¤èˆ‡åˆ†é¡
**Topics:** `Spark-Performance`, `Partitioning`, `File-Formats`
**Traps:** `Performance-Misconception`, `Execution-Behavior`
**Difficulty:** `L2-Intermediate`
