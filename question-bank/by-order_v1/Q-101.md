# Question #101

---

## é¡Œç›®è³‡è¨Š

### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-101`

### ä¾†æº
**ä¾†æº:** Mock Exam / Community Contributed

### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹

Which indicators would you look for in the Spark UI's **Storage** tab to signal that a cached table is **not performing optimally**? Assume you are using Spark's **MEMORY_ONLY** storage level.

### é¸é …

- **A.** Size on Disk < Size in Memory
- **B.** The RDD Block Name includes the "*" annotation signaling a failure to cache
- **C.** Size on Disk > 0
- **D.** The number of Cached Partitions > the number of Spark Partitions
- **E.** On Heap Memory Usage is within 75% of Off Heap Memory Usage

---

## æ¨™ç±¤ç³»çµ±

### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Performance-Tuning`, `Caching`, `Spark-UI`

### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Storage-Level-Confusion`, `Metric-Interpretation`

### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Performance Optimization

---

## ç­”æ¡ˆèˆ‡ä¾†æº

### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `C`

### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** C
- **ç¤¾ç¾¤æŠ•ç¥¨ç­”æ¡ˆ:** C (100%)

---

# é¡Œç›®è§£æ

---

## é¡Œç›®å›é¡§

### é¡Œç›®ç·¨è™Ÿèˆ‡é€£çµ
**é¡Œç›® ID:** `Q-101`
**é¡Œç›®é€£çµ:** [é»æ­¤è¿”å›é¡Œç›®](#question-101)

### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `C`

---

## ğŸ“ è€ƒé»è­˜åˆ¥

### ä¸»è¦è€ƒé»
**æ ¸å¿ƒæŠ€è¡“:** Spark Caching & Storage Levels Behavior
**çŸ¥è­˜é ˜åŸŸ:** Performance Optimization / Spark Internals
**é—œéµæ¦‚å¿µ:**
- Spark Storage Level çš„è¡Œç‚ºç‰¹æ€§ï¼ˆMEMORY_ONLY vs MEMORY_AND_DISKï¼‰
- Spark UI Storage Tab çš„æŒ‡æ¨™è§£è®€
- Cache æ•ˆèƒ½ç•°å¸¸çš„è¨ºæ–·æ–¹æ³•

### æ¬¡è¦è€ƒé»
- Spark è¨˜æ†¶é«”ç®¡ç†æ©Ÿåˆ¶
- RDD/DataFrame Cache çš„å¯¦ä½œåŸç†

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ C æ˜¯æ­£ç¢ºçš„ï¼Ÿ

**æŠ€è¡“åŸç†:**

**1. MEMORY_ONLY Storage Level çš„è¡Œç‚ºï¼š**

`MEMORY_ONLY` æ˜¯ Spark çš„å¿«å–å„²å­˜ç­‰ç´šä¹‹ä¸€ï¼Œå…¶ç‰¹æ€§ï¼š
- âœ… **åªä½¿ç”¨è¨˜æ†¶é«”**ï¼ˆRAMï¼‰å„²å­˜å¿«å–è³‡æ–™
- âŒ **ä¸æœƒå¯«å…¥ç£ç¢Ÿ**ï¼ˆDiskï¼‰
- âš ï¸ å¦‚æœè¨˜æ†¶é«”ä¸è¶³ï¼Œè¶…å‡ºçš„åˆ†å€ï¼ˆpartitionsï¼‰æœƒ **è¢«ä¸Ÿæ£„ï¼ˆevictedï¼‰**ï¼Œä¸æœƒ spill åˆ°ç£ç¢Ÿ

**2. æ­£å¸¸æƒ…æ³çš„æŒ‡æ¨™ï¼š**

ä½¿ç”¨ `MEMORY_ONLY` æ™‚ï¼ŒSpark UI Storage Tab æ‡‰è©²é¡¯ç¤ºï¼š
```
Size in Memory: > 0 (å¿«å–è³‡æ–™å„²å­˜åœ¨è¨˜æ†¶é«”ä¸­)
Size on Disk: 0   (ä¸ä½¿ç”¨ç£ç¢Ÿ)
```

**3. æ•ˆèƒ½ç•°å¸¸çš„è¨Šè™Ÿï¼ˆé¸é … Cï¼‰ï¼š**

**å¦‚æœ `Size on Disk > 0`ï¼Œè¡¨ç¤ºï¼š**

âŒ **é…ç½®éŒ¯èª¤æˆ–ä¸ä¸€è‡´** - å¯èƒ½åŸå› ï¼š
- Cache æ“ä½œä½¿ç”¨äº† `MEMORY_AND_DISK` è€Œé `MEMORY_ONLY`
- Storage level è¢«æ„å¤–æ›´æ”¹
- ç¨‹å¼ç¢¼é‚è¼¯éŒ¯èª¤ï¼ˆä¾‹å¦‚é‡æ–° cache æ™‚ä½¿ç”¨äº†ä¸åŒçš„ storage levelï¼‰

âš ï¸ **æ•ˆèƒ½è­¦è¨Š** - å½±éŸ¿ï¼š
- ç£ç¢Ÿ I/O é æ…¢æ–¼è¨˜æ†¶é«”å­˜å–ï¼ˆæ•¸é‡ç´šå·®ç•°ï¼‰
- Cache çš„ç›®çš„æ˜¯åŠ é€ŸæŸ¥è©¢ï¼Œå¯«å…¥ç£ç¢Ÿé•èƒŒåˆè¡·
- å¯èƒ½å°è‡´æŸ¥è©¢æ•ˆèƒ½ä¸å¦‚é æœŸ

**ç¬¦åˆéœ€æ±‚:**

é¡Œç›®å•çš„æ˜¯ã€Œä¸æ­£å¸¸ï¼ˆnot performing optimallyï¼‰çš„æŒ‡æ¨™ã€ï¼š
- `MEMORY_ONLY` æ¨¡å¼ä¸‹å‡ºç¾ç£ç¢Ÿä½¿ç”¨ = **é…ç½®éŒ¯èª¤æˆ–ç•°å¸¸è¡Œç‚º**
- é€™æ˜¯æ˜ç¢ºçš„æ•ˆèƒ½å•é¡Œè¨Šè™Ÿ

**å¯¦å‹™ç¯„ä¾‹:**

```python
# âœ… æ­£ç¢ºï¼šä½¿ç”¨ MEMORY_ONLY
df.cache()  # é è¨­ä½¿ç”¨ MEMORY_ONLY
# æˆ–æ˜ç¢ºæŒ‡å®š
from pyspark import StorageLevel
df.persist(StorageLevel.MEMORY_ONLY)

# Spark UI Storage Tab æ‡‰è©²é¡¯ç¤ºï¼š
# Size in Memory: 2.5 GB
# Size on Disk: 0 B          â† æ­£å¸¸æƒ…æ³

# âŒ ç•°å¸¸ï¼šSize on Disk > 0 å‡ºç¾åœ¨ MEMORY_ONLY æ¨¡å¼
# Spark UI Storage Tab é¡¯ç¤ºï¼š
# Size in Memory: 2.5 GB
# Size on Disk: 1.2 GB       â† âš ï¸ è­¦è¨Šï¼ä¸æ‡‰è©²æœ‰ç£ç¢Ÿä½¿ç”¨

# å¯èƒ½åŸå›  1ï¼šæ„å¤–ä½¿ç”¨äº† MEMORY_AND_DISK
df.persist(StorageLevel.MEMORY_AND_DISK)  # â† éŒ¯èª¤çš„ storage level

# å¯èƒ½åŸå›  2ï¼šå¤šæ¬¡ cache ä½¿ç”¨ä¸åŒ storage level
df.cache()  # MEMORY_ONLY
df.unpersist()
df.persist(StorageLevel.MEMORY_AND_DISK)  # æ”¹è®Šäº† storage level
```

**è¨ºæ–·èˆ‡ä¿®å¾©æµç¨‹ï¼š**

```python
# 1. æª¢æŸ¥ç•¶å‰ storage level
print(df.storageLevel)
# è¼¸å‡ºï¼šStorageLevel(True, False, False, False, 1)
#      (useDisk, useMemory, useOffHeap, deserialized, replication)

# 2. å¦‚æœç™¼ç¾ä½¿ç”¨äº†ç£ç¢Ÿï¼Œæ¸…é™¤ä¸¦é‡æ–° cache
df.unpersist()
df.persist(StorageLevel.MEMORY_ONLY)

# 3. é©—è­‰ Spark UI ä¸­ Size on Disk æ˜¯å¦è®Šç‚º 0

# 4. å¦‚æœè¨˜æ†¶é«”ä¸è¶³å°è‡´é »ç¹ evictionï¼Œè€ƒæ…®ï¼š
#    - å¢åŠ  executor è¨˜æ†¶é«”
#    - æ¸›å°‘å¿«å–è³‡æ–™é‡ï¼ˆç¯©é¸æˆ–æŠ½æ¨£ï¼‰
#    - ä½¿ç”¨ MEMORY_AND_DISKï¼ˆä½†è¦äº†è§£æ•ˆèƒ½å½±éŸ¿ï¼‰
```

**Storage Level å°æ¯”ï¼š**

| Storage Level | ä½¿ç”¨è¨˜æ†¶é«” | ä½¿ç”¨ç£ç¢Ÿ | è¨˜æ†¶é«”ä¸è¶³æ™‚è¡Œç‚º |
|--------------|----------|---------|---------------|
| **MEMORY_ONLY** | âœ… æ˜¯ | âŒ å¦ | ä¸Ÿæ£„åˆ†å€ï¼ˆéœ€é‡æ–°è¨ˆç®—ï¼‰ |
| **MEMORY_AND_DISK** | âœ… æ˜¯ | âœ… æ˜¯ | Spill åˆ°ç£ç¢Ÿï¼ˆè¼ƒæ…¢ä½†ä¸æœƒä¸Ÿå¤±ï¼‰ |
| **DISK_ONLY** | âŒ å¦ | âœ… æ˜¯ | å…¨éƒ¨å¯«å…¥ç£ç¢Ÿ |
| **MEMORY_ONLY_SER** | âœ… æ˜¯ï¼ˆåºåˆ—åŒ–ï¼‰ | âŒ å¦ | ä¸Ÿæ£„åˆ†å€ |

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### é¸é … A - "Size on Disk < Size in Memory"

**éŒ¯èª¤åŸå› :** é€™æ˜¯ MEMORY_ONLY çš„æ­£å¸¸ç‹€æ…‹ï¼Œä¸æ˜¯æ•ˆèƒ½å•é¡Œ

**è©³ç´°åˆ†æ:**
- `MEMORY_ONLY` æ¨¡å¼ä¸‹ï¼Œ`Size on Disk` **æ‡‰è©²ç‚º 0**
- `0 < Size in Memory` æ˜¯å®Œå…¨æ­£å¸¸çš„æƒ…æ³
- é€™å€‹æ¯”è¼ƒé—œä¿‚æ²’æœ‰ä»»ä½•è¨ºæ–·åƒ¹å€¼

**æ˜“æ··æ·†é»:**
å¯èƒ½èª¤ä»¥ç‚ºã€Œç£ç¢Ÿå°æ–¼è¨˜æ†¶é«”ã€è¡¨ç¤ºæœ‰å•é¡Œï¼Œä½†å¯¦éš›ä¸Šç£ç¢Ÿæ‡‰è©²å®Œå…¨ä¸ä½¿ç”¨ã€‚

---

### é¸é … B - "The RDD Block Name includes the '*' annotation signaling a failure to cache"

**éŒ¯èª¤åŸå› :** æœæ’°çš„åŠŸèƒ½ï¼ŒSpark UI æ²’æœ‰é€™ç¨®æ¨™è¨»

**è©³ç´°åˆ†æ:**
- Spark UI Storage Tab é¡¯ç¤ºçš„è³‡è¨ŠåŒ…æ‹¬ï¼š
  - RDD/DataFrame åç¨±
  - Storage Level
  - Cached Partitions / Total Partitions
  - Size in Memory / Size on Disk
  - **æ²’æœ‰** ä½¿ç”¨ "*" ç¬¦è™Ÿæ¨™ç¤ºå¿«å–å¤±æ•—
- å¦‚æœå¿«å–å¤±æ•—ï¼Œè©² RDD æ ¹æœ¬ä¸æœƒå‡ºç¾åœ¨ Storage Tab ä¸­

**æ˜“æ··æ·†é»:**
è½èµ·ä¾†åƒæ˜¯åˆç†çš„ UI è¨­è¨ˆï¼Œä½†é€™æ˜¯è™›æ§‹çš„åŠŸèƒ½ã€‚

---

### é¸é … D - "The number of Cached Partitions > the number of Spark Partitions"

**éŒ¯èª¤åŸå› :** é‚è¼¯ä¸Šä¸å¯èƒ½ç™¼ç”Ÿ

**è©³ç´°åˆ†æ:**
- **Cached Partitionsï¼ˆå·²å¿«å–åˆ†å€æ•¸ï¼‰** æ°¸é  â‰¤ **Total Partitionsï¼ˆç¸½åˆ†å€æ•¸ï¼‰**
- ä¸å¯èƒ½å¿«å–çš„åˆ†å€æ•¸å¤šæ–¼ç¸½åˆ†å€æ•¸
- æ­£å¸¸æƒ…æ³ï¼š
  - è¨˜æ†¶é«”å……è¶³ï¼šCached Partitions = Total Partitions
  - è¨˜æ†¶é«”ä¸è¶³ï¼ˆMEMORY_ONLYï¼‰ï¼šCached Partitions < Total Partitionsï¼ˆéƒ¨åˆ†è¢« evictï¼‰

**Spark UI ç¯„ä¾‹ï¼š**
```
RDD Name: my_dataframe
Storage Level: Memory Deserialized 1x Replicated
Cached Partitions: 150 / 200     â† 150 å€‹å¿«å–ï¼Œ50 å€‹è¢« evict
Size in Memory: 3.2 GB
Size on Disk: 0 B
```

**æ˜“æ··æ·†é»:**
å¯èƒ½èª¤è®€ã€ŒCached Partitions > Total Partitionsã€ç‚ºæ•ˆèƒ½å•é¡Œï¼Œä½†é€™åœ¨æ•¸å­¸ä¸Šä¸å¯èƒ½ã€‚

---

### é¸é … E - "On Heap Memory Usage is within 75% of Off Heap Memory Usage"

**éŒ¯èª¤åŸå› :** èˆ‡ Storage Tab çš„å¿«å–è¨ºæ–·ç„¡é—œï¼Œä¸”æŒ‡æ¨™æ„ç¾©ä¸æ˜

**è©³ç´°åˆ†æ:**
- **On-Heap vs Off-Heap Memory** æ˜¯ JVM è¨˜æ†¶é«”ç®¡ç†çš„æ¦‚å¿µï¼š
  - **On-Heap**: JVM å †è¨˜æ†¶é«”ï¼ˆå— GC ç®¡ç†ï¼‰
  - **Off-Heap**: ç›´æ¥è¨˜æ†¶é«”ï¼ˆä¸å— GC å½±éŸ¿ï¼Œä¾‹å¦‚ Tungstenï¼‰
- é€™å€‹æ¯”ä¾‹ **ä¸æ˜¯** Storage Tab çš„ä¸»è¦æŒ‡æ¨™
- ã€Œwithin 75%ã€çš„é–¾å€¼æ˜¯ä»»æ„çš„ï¼Œæ²’æœ‰æ¨™æº–å®šç¾©
- å³ä½¿é€™å€‹æ¯”ä¾‹å­˜åœ¨ï¼Œä¹Ÿä¸èƒ½ç›´æ¥åˆ¤æ–·å¿«å–æ•ˆèƒ½

**æ˜“æ··æ·†é»:**
æ¶‰åŠé€²éšè¨˜æ†¶é«”ç®¡ç†æ¦‚å¿µï¼Œçœ‹èµ·ä¾†å°ˆæ¥­ï¼Œä½†èˆ‡é¡Œç›®çš„å¿«å–è¨ºæ–·ç„¡é—œã€‚

---

## ğŸ§  è¨˜æ†¶æ³•èˆ‡å°æ¯”

### è¨˜æ†¶å£è¨£
**ã€ŒMEMORY_ONLY ä¸ç¢°ç›¤ï¼ŒSize on Disk å¿…ç‚ºé›¶ã€**
- **ä¸ç¢°ç›¤**: MEMORY_ONLY ä¸ä½¿ç”¨ç£ç¢Ÿ
- **å¿…ç‚ºé›¶**: Size on Disk æ‡‰è©²ç­‰æ–¼ 0ï¼Œå¤§æ–¼ 0 å°±æ˜¯ç•°å¸¸

### é—œéµå°æ¯”è¡¨

| Storage Level | Size on Disk æ­£å¸¸å€¼ | è¨˜æ†¶é«”ä¸è¶³æ™‚è¡Œç‚º | é©ç”¨æƒ…å¢ƒ |
|--------------|-------------------|---------------|---------|
| **MEMORY_ONLY** | **0** | ä¸Ÿæ£„åˆ†å€ï¼ˆrecomputeï¼‰ | è¨˜æ†¶é«”å……è¶³ + è¿½æ±‚æœ€é«˜é€Ÿåº¦ |
| **MEMORY_AND_DISK** | â‰¥ 0ï¼ˆå¯èƒ½ > 0ï¼‰ | Spill åˆ°ç£ç¢Ÿ | è¨˜æ†¶é«”æœ‰é™ + é¿å…é‡æ–°è¨ˆç®— |
| **DISK_ONLY** | > 0ï¼ˆå…¨éƒ¨åœ¨ç£ç¢Ÿï¼‰ | - | ç¯€çœè¨˜æ†¶é«”ï¼ˆä½†å¾ˆæ…¢ï¼‰ |

### Spark UI Storage Tab æŒ‡æ¨™è§£è®€

| æŒ‡æ¨™ | æ­£å¸¸ç¯„åœï¼ˆMEMORY_ONLYï¼‰ | ç•°å¸¸è¨Šè™Ÿ |
|------|----------------------|---------|
| **Size in Memory** | > 0 | = 0ï¼ˆæ²’æœ‰å¿«å–ï¼‰ |
| **Size on Disk** | **= 0** | **> 0ï¼ˆé…ç½®éŒ¯èª¤ï¼‰** â† æœ¬é¡Œé‡é» |
| **Cached Partitions** | â‰¤ Total Partitions | = 0ï¼ˆå¿«å–å¤±æ•—ï¼‰æˆ– < Totalï¼ˆè¨˜æ†¶é«”ä¸è¶³ï¼‰ |
| **Fraction Cached** | 0-100% | < 100%ï¼ˆéƒ¨åˆ† evictionï¼‰ |

### è¨ºæ–·æ±ºç­–æ¨¹

```
Spark UI Storage Tab é¡¯ç¤ºå¿«å–è³‡æ–™
â”œâ”€ ä½¿ç”¨ MEMORY_ONLYï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ æª¢æŸ¥ Size on Disk
â”‚  â”‚  â”œâ”€ = 0 â†’ âœ… æ­£å¸¸
â”‚  â”‚  â””â”€ > 0 â†’ âš ï¸ ç•°å¸¸ï¼æª¢æŸ¥ storage level é…ç½®
â”‚  â””â”€ å¦ï¼ˆMEMORY_AND_DISKï¼‰â†’ Size on Disk > 0 å¯èƒ½æ­£å¸¸
â”œâ”€ Cached Partitions < Total Partitionsï¼Ÿ
â”‚  â”œâ”€ æ˜¯ â†’ âš ï¸ è¨˜æ†¶é«”ä¸è¶³ï¼Œéƒ¨åˆ†åˆ†å€è¢« evict
â”‚  â”‚  â””â”€ è€ƒæ…®ï¼šå¢åŠ è¨˜æ†¶é«” æˆ– æ”¹ç”¨ MEMORY_AND_DISK
â”‚  â””â”€ å¦ â†’ âœ… å…¨éƒ¨å¿«å–æˆåŠŸ
â””â”€ Size in Memory = 0ï¼Ÿ
   â””â”€ æ˜¯ â†’ âŒ å¿«å–å¤±æ•—æˆ–å·²è¢«å®Œå…¨ evict
```

---

## ğŸ“š å»¶ä¼¸å­¸ç¿’

### å®˜æ–¹æ–‡ä»¶
- [Spark RDD Persistence](https://spark.apache.org/docs/latest/rdd-programming-guide.html#rdd-persistence)
- [Spark Storage Levels](https://spark.apache.org/docs/latest/rdd-programming-guide.html#which-storage-level-to-choose)
- [Spark Web UI - Storage Tab](https://spark.apache.org/docs/latest/web-ui.html#storage-tab)

### ç›¸é—œé¡Œç›®
- Q-XXX: Spark Cache vs Persist çš„å·®ç•°
- Q-XXX: Spark è¨˜æ†¶é«”ç®¡ç†èˆ‡èª¿å„ª
- Q-XXX: Spark UI æ•ˆèƒ½è¨ºæ–·æŠ€å·§

---

## ğŸ¯ é‡é»æé†’

> **æ ¸å¿ƒè§€å¿µ:** MEMORY_ONLY storage level **ä¸æœƒä½¿ç”¨ç£ç¢Ÿ**ï¼Œå¦‚æœ Spark UI Storage Tab é¡¯ç¤º `Size on Disk > 0`ï¼Œè¡¨ç¤ºé…ç½®éŒ¯èª¤æˆ–æ„å¤–ä½¿ç”¨äº†å…¶ä»– storage levelï¼Œé€™æ˜¯æ˜ç¢ºçš„æ•ˆèƒ½ç•°å¸¸è¨Šè™Ÿã€‚

**è€ƒè©¦é™·é˜±:**
- âŒ é¸é … A æ˜¯æ­£å¸¸ç‹€æ…‹ï¼Œä¸æ˜¯å•é¡Œï¼ˆç£ç¢Ÿ < è¨˜æ†¶é«” æ˜¯é æœŸçš„ï¼‰
- âŒ é¸é … B æœæ’°åŠŸèƒ½ï¼ˆSpark UI æ²’æœ‰ "*" æ¨™è¨»ï¼‰
- âŒ é¸é … D é‚è¼¯ä¸å¯èƒ½ï¼ˆå¿«å–åˆ†å€ä¸å¯èƒ½å¤šæ–¼ç¸½åˆ†å€ï¼‰

**æ­£ç¢ºæ€ç¶­:**
- âœ… MEMORY_ONLY â†’ Size on Disk **å¿…é ˆ** = 0
- âœ… Size on Disk > 0 åœ¨ MEMORY_ONLY æ¨¡å¼ = **é…ç½®éŒ¯èª¤**
- âœ… è¨ºæ–·å¿«å–æ•ˆèƒ½ï¼šå„ªå…ˆæª¢æŸ¥ storage level èˆ‡å¯¦éš›ä½¿ç”¨æ˜¯å¦ä¸€è‡´

**å¯¦å‹™æª¢æŸ¥æ¸…å–®:**
```python
# 1. é©—è­‰ storage level
df.storageLevel
# é æœŸï¼šStorageLevel(False, True, False, True, 1)
#       (useDisk=False è¡¨ç¤º MEMORY_ONLY)

# 2. æª¢æŸ¥ Spark UI Storage Tab
# Size on Disk æ‡‰è©² = 0 B

# 3. å¦‚æœç™¼ç¾ç•°å¸¸ï¼Œé‡æ–°å¿«å–
df.unpersist()
df.cache()  # æˆ– df.persist(StorageLevel.MEMORY_ONLY)
```