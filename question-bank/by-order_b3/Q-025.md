# Question 25

## Question
A data engineer has implemented the following streaming ingestion code using Databricks Auto Loader:



```

- spark.readStream \
-      .format("cloudFiles") \
-      .schema(expected_schema) \
-      .option("cloudFiles.format", "json") \
-      .option("cloudFiles.schemaEvolutionMode", "failOnNewColumns") \
-      .load("s3://vendor/raw/sales/json/") \
-     .writeStream \
-      .option("checkpointLocation", "s3://vendor/checkpoints/sales") \
-      .start("sales_table")
```





What is the expected behavior of this streaming job if a new column appears in the incoming JSON files that is not part of the original schema?




If a new column appears in the incoming JSON files that is not present in the existing schema, what will happen to the streaming job?

## Options
- A. The stream fails and will not restart unless the schema is manually updated or the problematic data file is removed. (Correct)
- B. The stream fails temporarily but continues by ignoring the new columns without schema update. 
- C. The stream fails, but it automatically restarts after updating the schema with the new columns. 
- D. The stream fails, and all new columns are saved in a rescued data column for later processing. 

## Explanation
With the `failOnNewColumns` mode, the stream detects any new columns and fails immediately to enforce strict schema consistency. It will not automatically restart until the schema has been manually updated to include the new columns or the data files causing the schema mismatch are removed. This prevents silent schema drift and ensures deliberate schema management.
