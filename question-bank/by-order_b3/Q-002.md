# Question #002

---

## é¡Œç›®è³‡è¨Š
### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-002`
### ä¾†æº
**ä¾†æº:** Community
### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹
### é¡Œå¹¹
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
The data engineering team maintains the following join logic between three Delta tables:

```python
df_students = spark.table("students")
df_courses = spark.table("courses")
df_enrollments = spark.table("enrollments")

df_join_1 = (df_students.join(df_enrollments, df_students.student_id == df_enrollments.student_id)
                        .select(df_students.student_id,
                                df_students.student_name,
                                df_enrollments.course_id)
            )

df_join_2 = (df_join_1.join(df_courses, df_join_1.course_id == df_courses.course_id)
                       .select(df_join_1.student_id,
                               df_join_1.student_name,
                               df_courses.course_name)
            )

(df_join_2.write
.mode("overwrite")
.table("students_courses_details"))
```

Which statement describes the result of this code block each time it is executed?

### é¸é …
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
- **A.** All records in the current version of the source tables will be considered in the join operations. The unmatched records will overwrite the students_courses_details table.
- **B.** Only newly added records to any of the source tables will be considered in the join operations. The matched records will overwrite the students_courses_details table.
- **C.** Only newly added records to any of the source tables will be considered in the join operations. The unmatched records will overwrite the students_courses_details table.
- **D.** All records in the current version of the source tables will be considered in the join operations. The matched records will overwrite the students_courses_details table.

---

## æ¨™ç±¤ç³»çµ±
### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Spark-Joins`, `DataFrames`, `PySpark`
### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Execution-Behavior`, `Default-Value`
### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Development

---

## ç­”æ¡ˆèˆ‡ä¾†æº
### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `D`
### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** D
- **ç¤¾ç¾¤å…±è­˜:** D

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥
**æ ¸å¿ƒæŠ€è¡“:** Spark DataFrame Join / Batch Processing
**é—œéµæ¦‚å¿µ:** spark.table() è¡Œç‚ºã€Inner Join é è¨­ã€Overwrite æ¨¡å¼
**é¡Œç›®é—œéµå­—ï¼š**
- **spark.table()**: éœæ…‹è®€å–ç•¶å‰ç‰ˆæœ¬
- **join()**: é è¨­ Inner Join
- **mode("overwrite")**: å®Œå…¨è¦†å¯«ç›®æ¨™è¡¨

---

## âœ… æ­£è§£èªªæ˜
### ç‚ºä»€éº¼ D æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

é€™æ®µç¨‹å¼ç¢¼æ˜¯**æ‰¹æ¬¡è™•ç†**é‚è¼¯ï¼Œæ¯æ¬¡åŸ·è¡Œéƒ½æœƒï¼š
1. è®€å–**æ‰€æœ‰**ç•¶å‰ç‰ˆæœ¬çš„è³‡æ–™
2. åŸ·è¡Œ **Inner Join**ï¼ˆåªä¿ç•™åŒ¹é…è¨˜éŒ„ï¼‰
3. **Overwrite** æ•´å€‹ç›®æ¨™è¡¨

#### spark.table() çš„è¡Œç‚º
```python
df = spark.table("table_name")
# ç­‰åŒæ–¼
df = spark.read.table("table_name")
```
- è®€å–è¡¨æ ¼çš„**ç•¶å‰ç‰ˆæœ¬**æ‰€æœ‰è³‡æ–™
- æ˜¯**éœæ…‹è®€å–**ï¼Œä¸æ˜¯ä¸²æµ
- æ¯æ¬¡åŸ·è¡Œéƒ½æœƒè®€å–å®Œæ•´è³‡æ–™

#### Join é è¨­è¡Œç‚º
```python
df1.join(df2, condition)  # é è¨­æ˜¯ Inner Join
df1.join(df2, condition, "inner")  # ç­‰åŒä¸Šé¢
```
- **Inner Join** åªä¿ç•™å…©é‚Šéƒ½åŒ¹é…çš„è¨˜éŒ„
- ä¸åŒ¹é…çš„è¨˜éŒ„æœƒè¢«æ’é™¤

#### åŸ·è¡Œæµç¨‹
```
åŸ·è¡Œæµç¨‹ï¼š
1. spark.table("students")     â†’ è®€å–æ‰€æœ‰å­¸ç”Ÿ
2. spark.table("courses")      â†’ è®€å–æ‰€æœ‰èª²ç¨‹
3. spark.table("enrollments")  â†’ è®€å–æ‰€æœ‰é¸èª²è¨˜éŒ„
4. Inner Join (students â‹ˆ enrollments) â†’ åŒ¹é…çš„è¨˜éŒ„
5. Inner Join (result â‹ˆ courses)       â†’ åŒ¹é…çš„è¨˜éŒ„
6. write.mode("overwrite")     â†’ è¦†å¯«æ•´å€‹ç›®æ¨™è¡¨
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### A. ... The unmatched records will overwrite ...
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **Inner Join ç”¢ç”ŸåŒ¹é…è¨˜éŒ„**ï¼Œä¸æ˜¯ unmatched
- åªæœ‰ LEFT ANTI JOIN æˆ– OUTER JOIN æ‰æœƒè™•ç†ä¸åŒ¹é…è¨˜éŒ„

### B. Only newly added records ...
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **spark.table() è®€å–æ‰€æœ‰è³‡æ–™**ï¼Œä¸æ˜¯åªè®€å–æ–°å¢çš„
- é€™ä¸æ˜¯ä¸²æµè™•ç†ï¼Œæ²’æœ‰å¢é‡è®€å–çš„åŠŸèƒ½
- å¢é‡è™•ç†éœ€è¦ä½¿ç”¨ `readStream` æˆ– CDF

### C. Only newly added records ... unmatched records ...
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- çµåˆäº† B å’Œ A çš„éŒ¯èª¤
- æ—¢ä¸æ˜¯å¢é‡è®€å–ï¼Œä¹Ÿä¸æ˜¯è¼¸å‡ºä¸åŒ¹é…è¨˜éŒ„

---

## ğŸ§  è¨˜æ†¶æ³•
### å£è¨£
**ã€Œspark.table è®€å…¨éƒ¨ï¼ŒJoin é è¨­å…§é€£æ¥ã€**

### Spark è®€å–æ–¹å¼æ¯”è¼ƒ
| æ–¹å¼ | è®€å–ç¯„åœ | è™•ç†æ¨¡å¼ |
|------|----------|----------|
| `spark.table()` | å…¨éƒ¨è³‡æ–™ | æ‰¹æ¬¡ |
| `spark.read.table()` | å…¨éƒ¨è³‡æ–™ | æ‰¹æ¬¡ |
| `spark.readStream.table()` | æ–°å¢è³‡æ–™ | ä¸²æµ |

### Join é¡å‹æ¯”è¼ƒ
| Join é¡å‹ | çµæœ |
|-----------|------|
| **inner (é è¨­)** | åªæœ‰åŒ¹é…è¨˜éŒ„ |
| left | å·¦é‚Šå…¨éƒ¨ + å³é‚ŠåŒ¹é… |
| right | å³é‚Šå…¨éƒ¨ + å·¦é‚ŠåŒ¹é… |
| outer | å…¨éƒ¨è¨˜éŒ„ |
| left_anti | å·¦é‚Šä¸åŒ¹é…çš„è¨˜éŒ„ |

### Write Mode æ¯”è¼ƒ
| Mode | è¡Œç‚º |
|------|------|
| **overwrite** | å®Œå…¨è¦†å¯«ç›®æ¨™è¡¨ |
| append | è¿½åŠ åˆ°ç›®æ¨™è¡¨ |
| ignore | å¦‚æœè¡¨å­˜åœ¨å‰‡ä¸å¯«å…¥ |
| error | å¦‚æœè¡¨å­˜åœ¨å‰‡å ±éŒ¯ |

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶
- [DataFrame.join()](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.join.html)
- [spark.table()](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.table.html)
- [DataFrameWriter.mode()](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrameWriter.mode.html)

---

**[è¿”å›é¡Œç›®](#question-002)**
