# Question #015

---

## é¡Œç›®è³‡è¨Š
### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-015`
### ä¾†æº
**ä¾†æº:** Community
### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹
### é¡Œå¹¹
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
A data engineer has a PySpark DataFrame with the following columns: employee_name, department, and salary. They want to assign a tier to each employee within their department based on salary, where employees earning the same salary share the same tier. The expected output is as follows:

To achieve this, they define a window by department and order by salary in descending order:

`window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())`

Which of the following functions correctly use this window to calculate the tier column?

### é¸é …
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
- **A.** df.withColumn("tier", row_number().over(window_spec))
- **B.** df.withColumn("tier", dense_rank().over(window_spec))
- **C.** df.withColumn("tier", rank().over(window_spec))
- **D.** df.withColumn("tier", percent_rank().over(window_spec))

---

## æ¨™ç±¤ç³»çµ±
### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Spark-DataFrame`, `Spark-SQL`
### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Concept-Confusion`
### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Data Transformation

---

## ç­”æ¡ˆèˆ‡ä¾†æº
### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `C`
### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** C
- **ç¤¾ç¾¤å…±è­˜:** C

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥
**æ ¸å¿ƒæŠ€è¡“:** Window Functions / Ranking Functions
**é—œéµæ¦‚å¿µ:** rank() vs dense_rank() vs row_number()
**é¡Œç›®é—œéµå­—ï¼š**
- **same salary share the same tier**: ç›¸åŒè–ªè³‡å…±äº«ç›¸åŒç­‰ç´š
- **Window.partitionBy**: è¦–çª—åˆ†å€
- **tier**: ç­‰ç´šæ’åï¼ˆæœ‰è·³è™Ÿï¼‰

---

## âœ… æ­£è§£èªªæ˜
### ç‚ºä»€éº¼ C æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**`rank()`** å‡½æ•¸æœƒçµ¦ç›¸åŒå€¼**ç›¸åŒæ’å**ï¼Œä¸¦ä¸”åœ¨ä¸‹ä¸€å€‹ä¸åŒå€¼æ™‚**è·³è™Ÿ**ã€‚

#### rank() çš„è¡Œç‚º
```
ç¯„ä¾‹è³‡æ–™ï¼ˆHR éƒ¨é–€ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ employee â”‚ departmentâ”‚salaryâ”‚ tier â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ Eve      â”‚ HR        â”‚ 4000 â”‚  1   â”‚ â† ç›¸åŒè–ªè³‡
â”‚ Frank    â”‚ HR        â”‚ 4000 â”‚  1   â”‚ â† ç›¸åŒæ’å
â”‚ David    â”‚ HR        â”‚ 3900 â”‚  3   â”‚ â† è·³é 2ï¼
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

rank() é‚è¼¯ï¼š
â”œâ”€â”€ Eve å’Œ Frank è–ªè³‡ç›¸åŒ â†’ éƒ½æ˜¯ tier 1
â””â”€â”€ David æ˜¯ç¬¬ 3 å€‹äºº â†’ tier 3ï¼ˆè·³é 2ï¼‰
```

#### ä¸‰ç¨®æ’åå‡½æ•¸æ¯”è¼ƒ
| å‡½æ•¸ | ç›¸åŒå€¼ | ä¸‹ä¸€å€‹å€¼ | ç‰¹æ€§ |
|------|--------|----------|------|
| **rank()** | ç›¸åŒæ’å | è·³è™Ÿ | 1,1,3,4 |
| **dense_rank()** | ç›¸åŒæ’å | ä¸è·³è™Ÿ | 1,1,2,3 |
| **row_number()** | ä¸åŒæ’å | é€£çºŒ | 1,2,3,4 |

#### è¦–è¦ºåŒ–æ¯”è¼ƒ
```
è³‡æ–™ï¼š100, 100, 90, 80

row_number(): 1, 2, 3, 4  â† æ¯å€‹éƒ½ä¸åŒ
dense_rank(): 1, 1, 2, 3  â† ç›¸åŒå€¼ç›¸åŒæ’åï¼Œä¸è·³è™Ÿ
rank():       1, 1, 3, 4  â† ç›¸åŒå€¼ç›¸åŒæ’åï¼Œè·³è™Ÿ
```

#### ç¨‹å¼ç¢¼ç¯„ä¾‹
```python
from pyspark.sql import Window
from pyspark.sql.functions import rank, dense_rank, row_number

window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())

# rank() - é¡Œç›®è¦æ±‚çš„è¡Œç‚º
df.withColumn("tier", rank().over(window_spec))
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### A. row_number()
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **æ¯ä¸€è¡Œéƒ½æœƒæœ‰ä¸åŒçš„ç·¨è™Ÿ**
- ä¸ç®¡å€¼æ˜¯å¦ç›¸åŒ
- ç›¸åŒè–ªè³‡çš„å“¡å·¥æœƒå¾—åˆ°ä¸åŒçš„ tier

```
row_number() çµæœï¼š
â”œâ”€â”€ Eve: tier = 1
â”œâ”€â”€ Frank: tier = 2  â† éŒ¯èª¤ï¼æ‡‰è©²ä¹Ÿæ˜¯ 1
â””â”€â”€ David: tier = 3
```

### B. dense_rank()
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- é›–ç„¶ç›¸åŒå€¼æœƒå¾—åˆ°ç›¸åŒæ’å
- ä½†ä¸‹ä¸€å€‹å€¼**ä¸æœƒè·³è™Ÿ**
- é¡Œç›®é¡¯ç¤ºéœ€è¦è·³è™Ÿï¼ˆ1,1,3 è€Œä¸æ˜¯ 1,1,2ï¼‰

```
dense_rank() çµæœï¼š
â”œâ”€â”€ Eve: tier = 1
â”œâ”€â”€ Frank: tier = 1
â””â”€â”€ David: tier = 2  â† æ‡‰è©²æ˜¯ 3ï¼
```

### D. percent_rank()
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **è¿”å› 0 åˆ° 1 ä¹‹é–“çš„ç™¾åˆ†æ¯”æ’å**
- ä¸æ˜¯æ•´æ•¸æ’å
- å®Œå…¨ä¸ç¬¦åˆéœ€æ±‚

```
percent_rank() çµæœï¼š
â”œâ”€â”€ Eve: tier = 0.0
â”œâ”€â”€ Frank: tier = 0.0
â””â”€â”€ David: tier = 1.0
```

---

## ğŸ§  è¨˜æ†¶æ³•
### å£è¨£
**ã€Œrank æœƒè·³è™Ÿï¼Œdense ä¸è·³è™Ÿï¼Œrow_number éƒ½ä¸åŒã€**

### æ’åå‡½æ•¸é¸æ“‡æŒ‡å—
```
å¦‚ä½•é¸æ“‡æ’åå‡½æ•¸ï¼Ÿ

Q1: ç›¸åŒå€¼éœ€è¦ç›¸åŒæ’åå—ï¼Ÿ
â”œâ”€â”€ å¦ â†’ row_number()
â””â”€â”€ æ˜¯ â†’ ç¹¼çºŒ Q2

Q2: éœ€è¦è·³è™Ÿå—ï¼Ÿ
â”œâ”€â”€ æ˜¯ â†’ rank()
â””â”€â”€ å¦ â†’ dense_rank()
```

### å¸¸è¦‹ä½¿ç”¨å ´æ™¯
| å‡½æ•¸ | ä½¿ç”¨å ´æ™¯ |
|------|----------|
| **row_number()** | åˆ†é ã€å–æ¯çµ„å‰ N ç­† |
| **rank()** | æ¯”è³½æ’åï¼ˆä¸¦åˆ—å¾Œè·³è™Ÿï¼‰ |
| **dense_rank()** | ç­‰ç´šåˆ†é¡ï¼ˆä¸è·³è™Ÿï¼‰ |

### Window å‡½æ•¸å®Œæ•´ç¯„ä¾‹
```python
from pyspark.sql import Window
from pyspark.sql.functions import rank, dense_rank, row_number, percent_rank

window_spec = Window.partitionBy("department").orderBy(F.desc("salary"))

df.select(
    "employee_name",
    "department",
    "salary",
    row_number().over(window_spec).alias("row_num"),      # 1,2,3,4
    rank().over(window_spec).alias("rank"),               # 1,1,3,4
    dense_rank().over(window_spec).alias("dense_rank"),   # 1,1,2,3
    percent_rank().over(window_spec).alias("pct_rank")    # 0.0,0.0,0.67,1.0
)
```

### è€ƒè©¦æŠ€å·§
```
çœ‹åˆ°æ’åé¡Œç›®æ™‚ï¼š
â”œâ”€â”€ æ‰¾é—œéµå­—ã€Œè·³è™Ÿã€æˆ–ã€Œgapã€â†’ rank()
â”œâ”€â”€ æ‰¾é—œéµå­—ã€Œé€£çºŒã€æˆ–ã€Œconsecutiveã€â†’ dense_rank()
â”œâ”€â”€ æ‰¾é—œéµå­—ã€Œå”¯ä¸€ã€æˆ–ã€Œuniqueã€â†’ row_number()
â””â”€â”€ æ‰¾é—œéµå­—ã€Œç™¾åˆ†æ¯”ã€â†’ percent_rank()
```

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶
- [Window Functions](https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#window-functions)
- [rank vs dense_rank](https://docs.databricks.com/sql/language-manual/functions/rank.html)
- [PySpark Window Functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html#window-functions)

---

**[è¿”å›é¡Œç›®](#question-015)**
