# Question 15

## Question
A data engineer has a PySpark DataFrame with the following columns: employee_name, department, and salary. They want to assign a tier to each employee within their department based on salary, where employees earning the same salary share the same tier. The expected output is as follows:








To achieve this, they define a window by department and order by salary in descending order:




`window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())`




Which of the following functions correctly use this window to calculate the tier column?

## Options
- A. df.withColumn("tier", row_number().over(window_spec)) 
- B. df.withColumn("tier", dense_rank().over(window_spec)) 
- C. df.withColumn("tier", rank().over(window_spec)) (Correct)
- D. df.withColumn("tier", percent_rank().over(window_spec)) 

## Explanation
The correct function to use is `rank()` because it assigns the same rank (or tier) to employees with identical salaries within each department while maintaining the correct order when salaries differ. In this case, employees with the same salary value share the same tier number, and the next unique salary receives a rank that accounts for the number of preceding entries, which results in skipped tier numbers when ties occur. This matches the expected output, where, for example, Eve and Frank in the HR department both have a salary of 4000 and share tier 1, while David, with a lower salary of 3900, gets tier 3.




Other functions such as `row_number()` would assign unique sequential numbers even for ties, `dense_rank() `would not skip numbers after ties, and `percent_rank()` would assign fractional ranks between 0 and 1, none of which align with the desired behavior.
