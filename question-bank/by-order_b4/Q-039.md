# Question 39

## Question
A data engineer is configuring the follwoing Databricks Auto Loader stream to ingest JSON data from an S3 bucket:



```
spark.readStream \
     .format("cloudFiles") \
     .option("cloudFiles.format", "json") \
     .option("cloudFiles.schemaLocation", "s3://shop/checkpoints/orders")
     .option("cloudFiles.schemaEvolutionMode", "_______________") \
     .load("s3://shop/raw/orders/json/") \
    .writeStream \
     .option("checkpointLocation", "s3://shop/checkpoints/orders") \
     .start("orders_table")
```





The pipeline should fail when new columns are detected in the incoming data, but those new columns should still be added to the schema so that subsequent runs can resume successfully with the updated schema. Existing columns must retain their data types.




Which option correctly fills in the blank to meet the specified requirement?

## Options
- A. addNewColumns (Correct)
- B. none 
- C. rescue 
- D. failOnNewColumns 

## Explanation
The `addNewColumns` mode is the default schema evolution behavior in Auto Loader. In this mode, when a new column is detected, the stream fails, but the new column is added to the schema. This allows the job to be restarted and continue processing with the updated schema. Importantly, existing columns' data types are not changed.
