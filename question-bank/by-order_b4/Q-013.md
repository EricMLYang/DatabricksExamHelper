# Question 13

## Question
The data engineering team needs to share a dataset containing Social Security numbers with an external analytics vendor. They want to ensure that the original values are not exposed, while still allowing the vendor to perform matching operations. To achieve this, they implemented the following code:



```

- df_masked = df_original.withColumn("ssn_hash", sha2("ssn", 256))
- df_masked.write.saveAsTable("masked_analytics")
```





However, this code still exposes the original values.




Which of the following statements correctly explains the reason for this behavior?

## Options
- A. The `sha2` function is not available in PySpark. The table masked_analytics should be created in Spark SQL using a CTAS statement. 
- B. The code adds a new column to df_masked instead of overriding the original value. They need to use `withColumn("ssn", sha2("ssn", 256))` instead. (Correct)
- C. The `sha2` function doesn't apply to numerical values. They need to use `withColumn("ssn_hash", sha1("ssn"))` instead. 
- D. The code adds a new column to df_masked without dropping the original value. It must be followed by a `.drop("ssn_hash")` command. 

## Explanation
In PySpark, the withColumn function creates a new column or replaces an existing column in a DataFrame based on the given expression. The code in this question adds a new column (ssn_hash) to df_masked but does not remove or overwrite the original ssn column, so the original Social Security numbers are still present in the table.




To properly mask the data, the team should either overwrite the ssn column with the hash (`withColumn("ssn", sha2("ssn", 256))`) or drop the original column after hashing.
