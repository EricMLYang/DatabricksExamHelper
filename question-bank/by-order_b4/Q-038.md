# Question 38

## Question
A data engineer in an international school has implemented the following PySpark code:



```
from pyspark.sql.window import Window
from pyspark.sql.functions import avg, col
 
window_spec = Window.partitionBy("student_id").orderBy("exam_date")\
                .rowsBetween(Window.unboundedPreceding, Window.currentRow)
 
df_new = df_student_results.withColumn("avg_score", avg("score").over(window_spec))
```





Which of the following correctly describes what this code does?

## Options
- A. It adds a column showing the overall average score of each student, ordered by exam date. 
- B. It adds a column showing the cumulative average score of each exam from the first enrolled student to and including the current student. 
- C. It adds a column showing the cumulative average score of each student from their first exam up to and including the current exam. (Correct)
- D. It adds a column showing the overall average score of each exam, regardless of student. 

## Explanation
The PySpark code uses a Window function to calculate a cumulative or running average score for each student.
- 

Window.partitionBy("student_id"): This divides the data into partitions (groups) based on the student_id. The average calculation will be performed independently within each student's set of results.
- 

.orderBy("exam_date"): This sorts the rows within each student's partition by the exam_date (oldest to newest). This is crucial for a running calculation.
- 

.rowsBetween(Window.unboundedPreceding, Window.currentRow): This defines the frame for the window.
- 

Window.unboundedPreceding means the frame starts at the very first row in the current student's partition (the first exam).
- 

Window.currentRow means the frame ends at the current row being processed (the current exam).
- 

This combination ensures that for any given row, the calculation includes all preceding rows and the current row, effectively defining a cumulative set of data.
- 

avg("score").over(window_spec): The avg("score") function is applied over the defined window_spec. Because the window is partitioned by student_id and is cumulative over exam_date, the result in the new avg_score column is the cumulative average score for that specific student up to that specific exam date.
