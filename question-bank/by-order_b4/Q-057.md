# Question 57

## Question
A data engineer is using a foreachBatch logic to upsert data in a target Delta table.




The function to be called at each new microbatch processing is displayed below with a blank:



```
def upsert_data(microBatchDF, batch_id):
    microBatchDF.createOrReplaceTempView("sales_microbatch")
 
    sql_query = """
                MERGE INTO sales_silver a
                USING sales_microbatch b
                ON a.item_id=b.item_id
                    AND a.item_timestamp=b.item_timestamp
                WHEN NOT MATCHED THEN INSERT *
                """
 
    ________________
```





Which option correctly fills in the blank to execute the sql query in the function on a cluster with Databricks Runtime below 10.5 ?

## Options
- A. microBatchDF.sparkSession.sql(sql_query) 
- B. spark.sql(sql_query) 
- C. microBatchDF._jdf.sparkSession().sql(sql_query) (Correct)
- D. microBatchDF.sql(sql_query) 

## Explanation
Usually, we use spark.sq() function to run SQL queries. However, in this particular case, the spark session can not be accessed from within the microbatch process. Instead, we can access the local spark session from the microbatch dataframe.




For clusters with Databricks Runtime version below 10.5, the syntax to access the local spark session is:

`microBatchDF._jdf.sparkSession().sql(sql_query)`




For additional clarification, refer to the official Databricks documentation (Python syntax) at the following link: https://docs.databricks.com/aws/en/structured-streaming/delta-lake?language=Python#upsert-from-streaming-queries-using-foreachbatch 





Study materials from our exam preparation course on Udemy:

Hands-on
