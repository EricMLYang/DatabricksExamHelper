# Question 29

## Question
Given the following Structured Streaming query:



```

- (spark.table("orders")
-         .withColumn("total_after_tax", col("total")+col("tax"))
-     .writeStream
-         .option("checkpointLocation", checkpointPath)
-         .outputMode("append")
-         ._____________
-         .table("new_orders")
- )
```





Fill in the blank to make the query executes a micro-batch to process data every 2 minutes

## Options
- A. trigger("2 minutes") 
- B. trigger(processingTime="2 minutes") (Correct)
- C. processingTime("2 minutes") 
- D. trigger(once="2 minutes") 

## Explanation
In Spark Structured Streaming, in order to process data in micro-batches at a user-specified intervals, you can use the processingTime trigger method. This allows you to specify a time duration as a string. By default, it's "500ms".




Study materials from our exam preparation course on Udemy:
- 

Lecture (Associate course)
