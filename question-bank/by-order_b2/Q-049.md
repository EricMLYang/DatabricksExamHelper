# Question 49

## Question
A data engineer has a PySpark DataFrame with the following columns: employee_name, department, and salary. They want to assign a tier to each employee within their department based on salary, where each employee has a unique tier number, even if they have the same salary. The expected output is as follows:








To achieve this, they define a window by department and order by salary in descending order:




`window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())`




Which of the following functions correctly use this window to calculate the tier column?

## Options
- A. df.withColumn("tier", rank().over(window_spec)) 
- B. df.withColumn("tier", row_number().over(window_spec)) (Correct)
- C. df.withColumn("tier", dense_rank().over(window_spec)) 
- D. df.withColumn("tier", percent_rank().over(window_spec)) 

## Explanation
The expected output has a unique tier number to each employee within their department based on salary, even when multiple employees have the same salary. To achieve this, the data engineer should use the `row_number()` function. This is because r`ow_number()` generates a sequential number for each row within the specified window, guaranteeing uniqueness regardless of duplicate salary values.




In this case, the window is defined by department and ordered by salary in descending order:

`window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())`




Using `row_number().over(window_spec)` will assign 1, 2, 3, â€¦ to employees in order of their salaries within each department, exactly matching the expected output.




Functions like `rank()` or `dense_rank()` would assign the same number to employees with identical salaries, and `percent_rank()` would produce fractional values between 0 and 1, so they would not meet the requirement of unique tier numbers.
