# Question 22

## Question
A data engineer wants to optimize the following join operation by allowing the smaller dataFrame to be sent to all executor nodes in the cluster:



```

- largeDF.join(smallerDF, ["key"], "inner")
```





Which of the following functions can be used to mark a dataFrame as small enough to fit in memory on all executors ?

## Options
- A. pyspark.sql.functions.distribute 
- B. pyspark.sql.functions.broadcast (Correct)
- C. pyspark.sql.functions.explode 
- D. pyspark.sql.functions.shuffle 

## Explanation
`pyspark.sql.functions.broadcast` function marks a DataFrame as small enough for use in broadcast joins.




Study materials from our exam preparation course on Udemy:

Hands-on
