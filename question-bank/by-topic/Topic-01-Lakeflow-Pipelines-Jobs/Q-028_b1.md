# Question #028

---

## é¡Œç›®è³‡è¨Š
### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-028`

### ä¾†æº
**ä¾†æº:** Sample / Batch 1

### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹
### é¡Œå¹¹
A data engineer is tasked with designing an ETL pipeline with Lakeflow Declarative Pipelines to efficiently handle near real-time data ingestion. The goal is to incrementally process incoming data streams using Auto Loader, ensuring that the data pipeline can continuously capture and load new records as they arrive while maintaining high performance and reliability.

Given this requirement, the engineer needs to choose an appropriate type of object that can best support incremental, near real-time data ingestion and processing.

Which of the following objects would be most suitable for this specific use case?

### é¸é …
- **A.** Materialized view

- **B.** Temporary view

- **C.** Streaming table

- **D.** Live table

---

## æ¨™ç±¤ç³»çµ±
### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Streaming`, `Auto-Loader`

### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Concept-Confusion`

### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / ETL Pipelines

---

## ç­”æ¡ˆèˆ‡ä¾†æº
### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `C`

### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** C
- **ç¤¾ç¾¤å…±è­˜:** C

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥

**æ ¸å¿ƒæŠ€è¡“:** Lakeflow Declarative Pipelines (formerly DLT) ç‰©ä»¶é¡å‹

**é—œéµæ¦‚å¿µ:**
- Streaming Table vs Materialized View
- è¿‘å³æ™‚ (near real-time) è³‡æ–™è™•ç†
- Auto Loader çš„æ•´åˆæ–¹å¼

**é¡Œç›®é—œéµå­—ï¼š**
- **near real-time**: è¿‘å³æ™‚è™•ç†ï¼Œéœ€è¦ä¸²æµæ¶æ§‹
- **incrementally process**: å¢é‡è™•ç†
- **continuously capture**: æŒçºŒæ•ç²æ–°è³‡æ–™
- **Auto Loader**: ä¸²æµè³‡æ–™è¼‰å…¥å™¨

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ C æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**æŠ€è¡“åŸç†ï¼š**

**Streaming Table** å°ˆç‚º**è¿‘å³æ™‚ã€æŒçºŒæ€§çš„è³‡æ–™æ”å–**è¨­è¨ˆã€‚å®ƒèƒ½å¤ ï¼š
1. æŒçºŒç›£æ§æ–°è³‡æ–™çš„åˆ°é”
2. è‡ªå‹•å¢é‡è™•ç†
3. ç¶­è­· exactly-once èªç¾©

#### Streaming Table çš„ç‰¹æ€§

| ç‰¹æ€§ | èªªæ˜ |
|------|------|
| **è™•ç†æ¨¡å¼** | ä¸²æµï¼ˆStreamingï¼‰ |
| **è³‡æ–™æ–°é®®åº¦** | è¿‘å³æ™‚ï¼ˆç§’ç´šåˆ°åˆ†é˜ç´šï¼‰ |
| **è™•ç†æ–¹å¼** | åªè™•ç†æ–°åˆ°é”çš„è³‡æ–™ |
| **ç‹€æ…‹ç®¡ç†** | è‡ªå‹•è¿½è¹¤è™•ç†é€²åº¦ï¼ˆcheckpointï¼‰ |
| **é©ç”¨å ´æ™¯** | IoTã€æ—¥èªŒã€CDCã€å³æ™‚äº‹ä»¶ |

#### Streaming Table èˆ‡ Auto Loader æ•´åˆ

```python
import dlt

@dlt.table
def raw_events():
    """ä½¿ç”¨ Auto Loader å»ºç«‹ Streaming Table"""
    return (
        spark.readStream
            .format("cloudFiles")
            .option("cloudFiles.format", "json")
            .option("cloudFiles.schemaLocation", "/schema/events")
            .load("/data/events/")
    )
```

```sql
-- SQL èªæ³•
CREATE OR REFRESH STREAMING TABLE raw_events
AS SELECT *
FROM cloud_files(
    "/data/events/",
    "json",
    map("cloudFiles.schemaLocation", "/schema/events")
)
```

#### è™•ç†æµç¨‹

```
è³‡æ–™åˆ°é”                    Streaming Table              ä¸‹æ¸¸è™•ç†
   â”‚                            â”‚                          â”‚
   â–¼                            â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Auto Loader   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Continuous   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–°æª”æ¡ˆ  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ å¢é‡è®€å– â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚ å³æ™‚æ›´æ–° â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                          è‡ªå‹•è¿½è¹¤é€²åº¦
                          (checkpoint)
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### é¸é … A
**Materialized view**

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

1. **Materialized View æ˜¯æ‰¹æ¬¡è™•ç†**ï¼š
   - å®šæœŸæˆ–è§¸ç™¼å¼æ›´æ–°ï¼Œä¸æ˜¯æŒçºŒä¸²æµ
   - é©åˆèšåˆå ±è¡¨ã€å®šæœŸåˆ·æ–°çš„è³‡æ–™

2. **è™•ç†æ¨¡å¼æ¯”è¼ƒ**ï¼š

| ç‰¹æ€§ | Streaming Table | Materialized View |
|------|-----------------|-------------------|
| **è™•ç†æ¨¡å¼** | ä¸²æµï¼ˆæŒçºŒï¼‰ | æ‰¹æ¬¡ï¼ˆå®šæœŸï¼‰ |
| **æ›´æ–°é »ç‡** | å³æ™‚ | æ’ç¨‹æˆ–è§¸ç™¼ |
| **è³‡æ–™æ–°é®®åº¦** | ç§’ç´š | åˆ†é˜åˆ°å°æ™‚ç´š |
| **é©ç”¨å ´æ™¯** | åŸå§‹è³‡æ–™æ”å– | èšåˆã€è½‰æ›çµæœ |

3. **Materialized View ç¯„ä¾‹**ï¼š
```python
@dlt.table
def sales_summary():
    """é€™æ˜¯ Materialized Viewï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰"""
    return spark.sql("""
        SELECT date, SUM(amount) as total
        FROM sales
        GROUP BY date
    """)
```

---

### é¸é … B
**Temporary view**

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

1. **Temporary View æ˜¯æš«å­˜çš„**ï¼š
   - åªå­˜åœ¨æ–¼ç•¶å‰ Spark Session
   - Session çµæŸå¾Œå°±æ¶ˆå¤±
   - æ²’æœ‰æŒä¹…åŒ–å„²å­˜

2. **ä¸é©åˆç”Ÿç”¢ç’°å¢ƒçš„ ETL Pipeline**ï¼š
   - ç„¡æ³•è·¨ Session ä½¿ç”¨
   - æ²’æœ‰ checkpoint æ©Ÿåˆ¶
   - ç„¡æ³•ä¿è­‰è³‡æ–™å®Œæ•´æ€§

```python
# Temporary View åªæ˜¯ Session å…§çš„åˆ¥å
df.createOrReplaceTempView("temp_view")
# Session çµæŸå¾Œï¼Œé€™å€‹ view å°±ä¸å­˜åœ¨äº†
```

---

### é¸é … D
**Live table**

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

1. **åè©å·²éæ™‚**ï¼š
   - ã€ŒLive Tableã€æ˜¯ DLT æ—©æœŸçš„è¡“èª
   - ç¾åœ¨å·²è¢«æ›´æ˜ç¢ºçš„ **Materialized View** å’Œ **Streaming Table** å–ä»£

2. **åœ¨æ–°ç‰ˆ Lakeflow Declarative Pipelines ä¸­**ï¼š
   - æ‰¹æ¬¡è™•ç†ä½¿ç”¨ **Materialized View**
   - ä¸²æµè™•ç†ä½¿ç”¨ **Streaming Table**
   - ã€ŒLive Tableã€ä¸å†æ˜¯å®˜æ–¹æ¨è–¦è¡“èª

3. **è¡“èªæ¼”é€²**ï¼š
```
èˆŠè¡“èª                    æ–°è¡“èª
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Live Table (æ‰¹æ¬¡)    â†’   Materialized View
Live Table (ä¸²æµ)    â†’   Streaming Table
```

---

## ğŸ§  è¨˜æ†¶æ³•

### å£è¨£
**ã€Œå³æ™‚ä¸²æµé¸ Streamingï¼Œæ‰¹æ¬¡èšåˆé¸ Materializedã€**
â†’ è¿‘å³æ™‚è™•ç†ç”¨ Streaming Tableï¼Œå®šæœŸæ›´æ–°ç”¨ Materialized View

### Lakeflow Declarative Pipelines ç‰©ä»¶é¡å‹

| ç‰©ä»¶é¡å‹ | è™•ç†æ¨¡å¼ | é©ç”¨å ´æ™¯ | è³‡æ–™ä¾†æº |
|---------|---------|---------|---------|
| **Streaming Table** | ä¸²æµ | åŸå§‹è³‡æ–™æ”å– | Auto Loader, Kafka |
| **Materialized View** | æ‰¹æ¬¡ | èšåˆã€è½‰æ› | å…¶ä»– Tables/Views |

### é¸æ“‡æ±ºç­–æ¨¹

```
éœ€è¦è¿‘å³æ™‚è™•ç†ï¼Ÿ
    â”‚
    â”œâ”€â”€ æ˜¯ â†’ ä½¿ç”¨ Streaming Table
    â”‚         é©åˆï¼šAuto Loader, Kafka, Event Hubs
    â”‚
    â””â”€â”€ å¦ â†’ ä½¿ç”¨ Materialized View
              é©åˆï¼šèšåˆå ±è¡¨ã€å®šæœŸè½‰æ›
```

### Auto Loader + Streaming Table æœ€ä½³å¯¦è¸

```python
import dlt

# Bronze Layer: ä½¿ç”¨ Streaming Table
@dlt.table(
    comment="Raw events from Auto Loader"
)
def bronze_events():
    return (
        spark.readStream
            .format("cloudFiles")
            .option("cloudFiles.format", "json")
            .load("/data/events/")
    )

# Silver Layer: å¯ä»¥ç¹¼çºŒä½¿ç”¨ Streaming Table
@dlt.table(
    comment="Cleaned events"
)
def silver_events():
    return dlt.read_stream("bronze_events").filter("status = 'valid'")

# Gold Layer: ä½¿ç”¨ Materialized View åšèšåˆ
@dlt.table(
    comment="Daily aggregates"
)
def gold_daily_summary():
    return dlt.read("silver_events").groupBy("date").count()
```

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶

- [Streaming Tables](https://docs.databricks.com/en/delta-live-tables/streaming.html)
- [Materialized Views vs Streaming Tables](https://docs.databricks.com/en/delta-live-tables/index.html)
- [Auto Loader with DLT](https://docs.databricks.com/en/ingestion/auto-loader/index.html)
- [Lakeflow Declarative Pipelines](https://docs.databricks.com/en/delta-live-tables/index.html)

---

**[è¿”å›é¡Œç›®](#question-028)**
