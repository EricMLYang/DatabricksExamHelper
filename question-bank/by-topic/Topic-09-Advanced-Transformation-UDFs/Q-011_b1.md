# Question #011

---

## é¡Œç›®è³‡è¨Š
### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-011`
### ä¾†æº
**ä¾†æº:** Sample
### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹
### é¡Œå¹¹
A data engineer has a PySpark DataFrame with the following columns: `employee_name`, `department`, and `salary`. They want to assign a tier to each employee within their department based on salary, where employees earning the same salary share the same tier.

To achieve this, they define a window by department and order by salary in descending order:

```python
window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())
```

Which of the following functions correctly use this window to calculate the tier column?

### é¸é …
- **A.** `df.withColumn("tier", percent_rank().over(window_spec))`
- **B.** `df.withColumn("tier", row_number().over(window_spec))`
- **C.** `df.withColumn("tier", rank().over(window_spec))`
- **D.** `df.withColumn("tier", dense_rank().over(window_spec))`

---

## æ¨™ç±¤ç³»çµ±
### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `PySpark`, `DataFrames`, `Spark-SQL`
### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Similar-Function`, `Concept-Confusion`
### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Development

---

## ç­”æ¡ˆèˆ‡ä¾†æº
### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `D`
### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** D
- **ç¤¾ç¾¤å…±è­˜:** D

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥
**æ ¸å¿ƒæŠ€è¡“:** PySpark Window Functions (Ranking Functions)
**é—œéµæ¦‚å¿µ:** dense_rank() vs rank() vs row_number() vs percent_rank()
**é¡Œç›®é—œéµå­—ï¼š**
- **Window Function**: åœ¨ç‰¹å®šåˆ†å€å…§é€²è¡Œè¨ˆç®—çš„å‡½æ•¸
- **partitionBy**: æŒ‰éƒ¨é–€åˆ†çµ„
- **Ranking Functions**: æ’åå‡½æ•¸å®¶æ—çš„å·®ç•°
- **Consecutive Tiers**: é€£çºŒçš„ç­‰ç´šç·¨è™Ÿï¼ˆç›¸åŒè–ªè³‡åŒç­‰ç´šï¼‰

---

## âœ… æ­£è§£èªªæ˜
### ç‚ºä»€éº¼ D æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**æŠ€è¡“åŸç†ï¼š**

é¡Œç›®è¦æ±‚ï¼š
1. **ç›¸åŒè–ªè³‡ = ç›¸åŒç­‰ç´š**ï¼ˆåŒä¸€ tierï¼‰
2. **é€£çºŒç·¨è™Ÿ**ï¼ˆ1, 1, 2 è€Œé 1, 1, 3ï¼‰

`dense_rank()` æ­£å¥½ç¬¦åˆé€™å…©å€‹éœ€æ±‚ï¼š

```python
from pyspark.sql.window import Window
from pyspark.sql.functions import dense_rank

window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())
df_with_tier = df.withColumn("tier", dense_rank().over(window_spec))
```

**ç¯„ä¾‹è¼¸å‡ºï¼š**

| employee_name | department | salary | tier |
|---------------|------------|--------|------|
| Alice         | Sales      | 8000   | 1    |
| Bob           | Sales      | 8000   | 1    |
| Charlie       | Sales      | 7000   | 2    | â† é€£çºŒç·¨è™Ÿ
| David         | Sales      | 6000   | 3    |
| Eve           | Engineering| 9000   | 1    |
| Frank         | Engineering| 8500   | 2    |

**ç‚ºä»€éº¼æ˜¯ dense_rank()ï¼Ÿ**
- âœ… **è™•ç†ç›¸åŒå€¼**ï¼šç›¸åŒè–ªè³‡çµ¦äºˆç›¸åŒæ’å
- âœ… **é€£çºŒç·¨è™Ÿ**ï¼šä¸æœƒè·³è™Ÿï¼ˆ1, 1, 2, 3...ï¼‰
- âœ… **åˆ†å€ç¨ç«‹**ï¼šæ¯å€‹éƒ¨é–€ç¨ç«‹è¨ˆç®—æ’å

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### A. `percent_rank().over(window_spec)`
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **å›å‚³å€¼é¡å‹éŒ¯èª¤**ï¼š`percent_rank()` å›å‚³ 0 åˆ° 1 ä¹‹é–“çš„**å°æ•¸**ï¼Œè€Œéæ•´æ•¸ç­‰ç´š
- **è¨ˆç®—å…¬å¼**ï¼š`(rank - 1) / (total_rows - 1)`
- **ç¯„ä¾‹è¼¸å‡º**ï¼š0.0, 0.0, 0.5, 1.0ï¼ˆä¸ç¬¦åˆæ•´æ•¸ tier éœ€æ±‚ï¼‰

```python
# éŒ¯èª¤è¼¸å‡ºç¯„ä¾‹
| employee | salary | percent_rank |
|----------|--------|--------------|
| Alice    | 8000   | 0.0          |
| Bob      | 8000   | 0.0          |
| Charlie  | 7000   | 0.666        |
| David    | 6000   | 1.0          |
```

### B. `row_number().over(window_spec)`
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **ç„¡æ³•è™•ç†ç›¸åŒå€¼**ï¼šå³ä½¿è–ªè³‡ç›¸åŒï¼Œæ¯ä¸€è¡Œä¹Ÿæœƒå¾—åˆ°**å”¯ä¸€çš„ç·¨è™Ÿ**
- **ä¸ç¬¦åˆéœ€æ±‚**ï¼šç›¸åŒè–ªè³‡æ‡‰è©²æœ‰ç›¸åŒ tier

```python
# éŒ¯èª¤è¼¸å‡ºç¯„ä¾‹
| employee | salary | row_number |
|----------|--------|------------|
| Alice    | 8000   | 1          |
| Bob      | 8000   | 2          | â† æ‡‰è©²æ˜¯ 1
| Charlie  | 7000   | 3          |
```

### C. `rank().over(window_spec)`
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **æœƒè·³è™Ÿ**ï¼šé‡åˆ°ç›¸åŒå€¼å¾Œï¼Œä¸‹ä¸€å€‹æ’åæœƒ**è·³éä¸­é–“çš„æ•¸å­—**
- **ä¸é€£çºŒ**ï¼šç”¢ç”Ÿ 1, 1, 3, 4ï¼ˆè€Œé 1, 1, 2, 3ï¼‰

```python
# éŒ¯èª¤è¼¸å‡ºç¯„ä¾‹
| employee | salary | rank |
|----------|--------|------|
| Alice    | 8000   | 1    |
| Bob      | 8000   | 1    |
| Charlie  | 7000   | 3    | â† è·³é 2
| David    | 6000   | 4    |
```

**é™·é˜±è¨­è¨ˆï¼š**
`rank()` èˆ‡ `dense_rank()` æœ€å®¹æ˜“æ··æ·†ï¼Œå·®åˆ¥åƒ…åœ¨æ–¼æ˜¯å¦è·³è™Ÿã€‚

---

## ğŸ§  è¨˜æ†¶æ³•

### å£è¨£
**ã€ŒDense ä¸è·³è™Ÿï¼ŒRank æœƒè·³è™Ÿï¼ŒRow å…¨å”¯ä¸€ï¼ŒPercent è®Šå°æ•¸ã€**

### æ¯”è¼ƒè¡¨ï¼šå››å¤§æ’åå‡½æ•¸

| å‡½æ•¸ | ç›¸åŒå€¼è™•ç† | ç·¨è™Ÿç‰¹æ€§ | å›å‚³é¡å‹ | ä½¿ç”¨å ´æ™¯ |
|------|-----------|---------|---------|---------|
| **dense_rank()** | âœ… ç›¸åŒæ’å | é€£çºŒä¸è·³è™Ÿ (1,1,2,3) | æ•´æ•¸ | ğŸ¯ **é€£çºŒç­‰ç´šåˆ†å±¤** |
| **rank()** | âœ… ç›¸åŒæ’å | æœƒè·³è™Ÿ (1,1,3,4) | æ•´æ•¸ | ç«¶è³½æ’åï¼ˆä¸¦åˆ—ç¬¬ä¸€ï¼Œæ²’æœ‰ç¬¬äºŒåï¼‰ |
| **row_number()** | âŒ å”¯ä¸€ç·¨è™Ÿ | é€£çºŒ (1,2,3,4) | æ•´æ•¸ | éœ€è¦å”¯ä¸€è­˜åˆ¥ç¢¼ |
| **percent_rank()** | âœ… ç›¸åŒæ’å | 0-1 ä¹‹é–“ | å°æ•¸ | ç™¾åˆ†ä½æ’å |

### è¦–è¦ºåŒ–å°æ¯”

```
è–ªè³‡: 100, 100, 90, 80

dense_rank():   1,  1,  2,  3  â† ä¸è·³è™Ÿ âœ…
rank():         1,  1,  3,  4  â† è·³è™Ÿ
row_number():   1,  2,  3,  4  â† å…¨å”¯ä¸€
percent_rank(): 0, 0, 0.66, 1  â† å°æ•¸
```

### è¨˜æ†¶é»
- **Dense** = **å¯†é›†**çš„ï¼Œæ‰€ä»¥æ•¸å­—å¯†é›†ä¸è·³è™Ÿ
- **Rank** = å‚³çµ±æ’åï¼Œä¸¦åˆ—å¾Œæœƒç©ºä½
- **Row Number** = è¡Œè™Ÿï¼Œç•¶ç„¶æ¯è¡Œå”¯ä¸€
- **Percent Rank** = ç™¾åˆ†æ¯”ï¼Œç•¶ç„¶æ˜¯å°æ•¸

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶
- [Window Functions - PySpark Documentation](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html#window-functions)
- [dense_rank() Function](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dense_rank.html)

---

**[è¿”å›é¡Œç›®](#question-011)**


## è£œå……1ï¼šæ€éº¼è®€æ‡‚é€™å€‹ window_spec

Window.partitionBy("department").orderBy(col("salary").desc()) å¯ä»¥æŠŠå®ƒæƒ³æˆå…©æ­¥ï¼š
	1.	partitionBy("department")ï¼šå…ˆæŠŠè³‡æ–™åˆ†æˆå¤šå€‹éƒ¨é–€åˆ†å€ï¼Œæ¯å€‹éƒ¨é–€å„è‡ªè¨ˆç®—ï¼Œäº’ä¸å¹²æ“¾ã€‚
	2.	orderBy(salary desc)ï¼šå†åœ¨æ¯å€‹éƒ¨é–€åˆ†å€å…§ï¼Œä¾è–ªè³‡ç”±é«˜åˆ°ä½æ’åºï¼›å¾ŒçºŒçš„æ’å/æ¯”è¼ƒå‡½æ•¸ï¼Œéƒ½æ˜¯åŸºæ–¼é€™å€‹æ’åºä½ç½®ä¾†ç®—ã€‚

## è£œå……2ï¼š å…¶ä»–å¸¸è€ƒ
ä¸‹é¢éƒ½æ²¿ç”¨åŒä¸€å€‹æ¦‚å¿µï¼šæ¯å€‹ department è‡ªå·±ä¸€çµ„ï¼ˆpartitionByï¼‰ï¼Œçµ„å…§ä¾ salary ç”±é«˜åˆ°ä½æ’åºï¼ˆorderBy descï¼‰ã€‚

from pyspark.sql import functions as F
from pyspark.sql.window import Window

window_spec = Window.partitionBy("department").orderBy(F.col("salary").desc())

1) Running / Rolling èšåˆï¼ˆsum/avg/min/max + frameï¼‰

A. Runningï¼ˆåˆ°ç›®å‰ç‚ºæ­¢ç´¯è¨ˆ/ç´¯ç©å¹³å‡ï¼‰

w_running = window_spec.rowsBetween(Window.unboundedPreceding, Window.currentRow)

df2 = (df
  .withColumn("running_sum_salary", F.sum("salary").over(w_running))
  .withColumn("running_avg_salary", F.avg("salary").over(w_running))
)

**è§£é‡‹ï¼š**åœ¨æ¯å€‹éƒ¨é–€å…§ï¼ŒæŒ‰è–ªè³‡ç”±é«˜åˆ°ä½æ’ï¼Œå°ã€Œå¾ç¬¬ä¸€ç­†åˆ°ç›®å‰é€™ç­†ã€åšç´¯è¨ˆ/ç´¯ç©å¹³å‡ã€‚

B. Rollingï¼ˆæœ€è¿‘ N ç­†çš„ç§»å‹•å¹³å‡/ç§»å‹•æœ€å¤§ï¼‰

w_rolling_3 = window_spec.rowsBetween(-2, 0)  # å«è‡ªå·±åœ¨å…§çš„æœ€è¿‘3ç­†ï¼ˆä¾æ’åºï¼‰

df3 = (df
  .withColumn("rolling3_avg_salary", F.avg("salary").over(w_rolling_3))
  .withColumn("rolling3_max_salary", F.max("salary").over(w_rolling_3))
)

**è§£é‡‹ï¼š**åœ¨æ¯å€‹éƒ¨é–€å…§ï¼Œå°ã€Œç›®å‰é€™ç­† + å‰é¢å…©ç­†ï¼ˆä¾æ’åºï¼‰ã€åšç§»å‹•è¨ˆç®—ã€‚

é€™è£¡çš„ã€Œå‰é¢ã€æ˜¯æŒ‡æ’åºå¾Œåœ¨ä½ å‰é¢çš„åˆ—ï¼ˆè–ªè³‡æ›´é«˜æˆ–åŒé«˜ï¼‰ã€‚

â¸»

2) lag / lead å‰å¾ŒæœŸæ¯”è¼ƒï¼ˆç›¸é„°åˆ—ï¼‰

A. è·Ÿä¸Šä¸€å€‹äººæ¯”ï¼ˆè–ªè³‡å·®ï¼‰

df4 = (df
  .withColumn("prev_salary", F.lag("salary", 1).over(window_spec))
  .withColumn("diff_vs_prev", F.col("salary") - F.col("prev_salary"))
)

**è§£é‡‹ï¼š**åŒéƒ¨é–€å…§ã€æŒ‰è–ªè³‡æ’åºå¾Œï¼Œæ‹¿ã€Œä¸Šä¸€åˆ—ã€çš„è–ªè³‡ä¾†åšå·®ï¼ˆç¬¬ä¸€åˆ—æœƒæ˜¯ nullï¼‰ã€‚

B. è·Ÿä¸‹ä¸€å€‹äººæ¯”ï¼ˆè–ªè³‡å·®æˆ–æ¯”ç‡ï¼‰

df5 = (df
  .withColumn("next_salary", F.lead("salary", 1).over(window_spec))
  .withColumn("diff_vs_next", F.col("salary") - F.col("next_salary"))
  .withColumn("ratio_vs_next", F.col("salary") / F.col("next_salary"))
)

**è§£é‡‹ï¼š**åŒéƒ¨é–€å…§ã€æŒ‰è–ªè³‡æ’åºå¾Œï¼Œæ‹¿ã€Œä¸‹ä¸€åˆ—ã€çš„è–ªè³‡ä¾†åšæ¯”è¼ƒï¼ˆæœ€å¾Œä¸€åˆ—æœƒæ˜¯ nullï¼‰ã€‚

â¸»

å°æé†’ï¼ˆè€ƒé»å¸¸å‡ºï¼‰
	â€¢	rowsBetween(-2, 0) æ˜¯ã€Œæœ€è¿‘ 3 åˆ—ã€ï¼šçœ‹çš„æ˜¯åˆ—çš„ä½ç½®ï¼ˆä¾æ’åºï¼‰ï¼Œä¸æ˜¯æ™‚é–“æˆ–æ•¸å€¼ç¯„åœã€‚
	â€¢	rangeBetween(...) æ‰æ˜¯ã€Œå€¼çš„ç¯„åœã€æ¦‚å¿µï¼ˆä¾‹å¦‚ä¾æ™‚é–“æˆ³åšæœ€è¿‘ 10 åˆ†é˜ï¼‰ï¼Œé€™é¡Œ salary æ’åºæ™‚é€šå¸¸ç”¨ rowsBetween æ›´ç›´è¦ºã€‚