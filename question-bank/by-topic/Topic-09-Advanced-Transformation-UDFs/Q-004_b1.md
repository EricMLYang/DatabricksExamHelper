# Question #004

---

## é¡Œç›®è³‡è¨Š

### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-004`

### ä¾†æº
**ä¾†æº:** Sample / Community

### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L1-Basic`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹

Which of the following functions can a data engineer use to return a new DataFrame containing the distinct rows from a given DataFrame based on **multiple columns**?

### é¸é …

- **A.** `pyspark.sql.DataFrame.dropDuplicates`
- **B.** `pyspark.sql.DataFrame.distinct`
- **C.** `pyspark.sql.DataFrame.drop`
- **D.** `pyspark.sql.DataFrame.dropna`

---

## æ¨™ç±¤ç³»çµ±

### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `PySpark`, `DataFrames`, `Data-Quality`

### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Similar-Function`

### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Development

---

## ç­”æ¡ˆèˆ‡ä¾†æº

### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `A`

### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** A
- **ç¤¾ç¾¤å…±è­˜:** A

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥

**æ ¸å¿ƒæŠ€è¡“:** PySpark DataFrame API  
**é—œéµæ¦‚å¿µ:** Deduplication (`dropDuplicates` vs `distinct`)

**é¡Œç›®é—œéµå­—ï¼š**
- **Distinct rows**: å»é™¤é‡è¤‡è¡Œã€‚
- **Based on multiple columns**: æ ¹æ“šç‰¹å®šçš„ä¸€å€‹æˆ–å¤šå€‹æ¬„ä½ä¾†åˆ¤æ–·é‡è¤‡ã€‚

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ A (`dropDuplicates`) æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**æŠ€è¡“åŸç†ï¼š**

åœ¨ PySpark ä¸­ï¼Œè‹¥è¦æ ¹æ“šã€Œç‰¹å®šæ¬„ä½çµ„åˆã€ä¾†ç§»é™¤é‡è¤‡å€¼ï¼Œå¿…é ˆä½¿ç”¨ `dropDuplicates()` (æˆ–å…¶åˆ¥å `drop_duplicates()`)ã€‚å®ƒå¯ä»¥æ¥å—ä¸€å€‹åˆ—è¡¨ä½œç‚ºåƒæ•¸ï¼Œç”¨ä¾†æŒ‡å®šè¦æª¢æŸ¥é‡è¤‡çš„æ¬„ä½ã€‚

**API ç‰¹æ€§ï¼š**

```python
# 1. ä¸å¸¶åƒæ•¸ï¼šè¡Œç‚ºç­‰åŒæ–¼ distinct()ï¼Œæª¢æŸ¥æ‰€æœ‰æ¬„ä½
df.dropDuplicates()

# 2. å¸¶åƒæ•¸ï¼šæª¢æŸ¥ç‰¹å®šæ¬„ä½ (é€™æ˜¯ distinct åšä¸åˆ°çš„)
# é¡Œç›®è¦æ±‚ "based on multiple columns"
df.dropDuplicates(['col1', 'col2'])
```

ç•¶æŒ‡å®šäº† subsets æ™‚ï¼ŒSpark æœƒä¿ç•™è©²çµ„åˆå‡ºç¾çš„ç¬¬ä¸€ç­†è³‡æ–™ï¼Œä¸¦ä¸Ÿæ£„å¾ŒçºŒå‡ºç¾çš„é‡è¤‡åˆ—ã€‚

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### B - `describe` (é¡Œç›®é¸é …ç‚º `distinct`)

*æ³¨æ„ï¼šé¡Œå¹¹é¸é … B ç‚º `pyspark.sql.DataFrame.distinct`*

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **åŠŸèƒ½é™åˆ¶**: `distinct()` æ–¹æ³•**ä¸æ¥å—ä»»ä½•åƒæ•¸**ã€‚
- **è¡Œç‚º**: å®ƒåªèƒ½éæ¿¾æ‰ã€Œæ•´è¡Œå®Œå…¨ç›¸åŒã€çš„é‡è¤‡è³‡æ–™ (all columns)ã€‚
- **ä¸ç¬¦éœ€æ±‚**: ç„¡æ³•åšåˆ°é¡Œç›®è¦æ±‚çš„ "based on multiple columns" (å³åªçœ‹ç‰¹å®šæ¬„ä½ï¼Œå¿½ç•¥å…¶ä»–æ¬„ä½çš„å·®ç•°)ã€‚

**æ¯”è¼ƒï¼š**

| æ–¹æ³• | åƒæ•¸ | æª¢æŸ¥ç¯„åœ | å½ˆæ€§ |
|------|------|---------|------|
| `distinct()` | ç„¡ | æ‰€æœ‰æ¬„ä½ | ä½ |
| `dropDuplicates()` | å¯é¸ (List) | æ‰€æœ‰æ¬„ä½ æˆ– æŒ‡å®šæ¬„ä½ | é«˜ |

### C - `drop`

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **ç”¨é€”**: ç”¨æ–¼**ç§»é™¤æ¬„ä½ (Columns)**ï¼Œè€Œä¸æ˜¯ç§»é™¤è¡Œ (Rows)ã€‚
- **ç¯„ä¾‹**: `df.drop('col_name')` æœƒå›å‚³ä¸€å€‹å°‘äº†è©²æ¬„ä½çš„ DataFrameã€‚

### D - `dropna`

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **ç”¨é€”**: ç”¨æ–¼**ç§»é™¤åŒ…å« Null å€¼çš„è¡Œ** (Handle missing data)ã€‚
- **ç¯„ä¾‹**: `df.dropna()` æœƒç§»é™¤ä»»ä½•åŒ…å« null çš„è¡Œã€‚èˆ‡å»é‡ (Deduplication) ç„¡é—œã€‚

---

## ğŸ§  è¨˜æ†¶æ³•

### å£è¨£

**ã€ŒDistinct å…¨çœ‹ï¼ŒDuplicate å¯é¸ã€**

- **Distinct**: åªèƒ½å…¨çœ‹ (Check all columns)
- **DropDuplicates**: å¯ä»¥é¸ (Choose columns provided)

### ç¨‹å¼ç¢¼è¦–è¦ºåŒ–

```python
# åŸå§‹è³‡æ–™
# id | cat | val
# 1  | A   | 10
# 1  | A   | 20  <-- èˆ‡ç¬¬ä¸€è¡Œæ¯”è¼ƒï¼š
#                distinct() è¦–ç‚ºä¸åŒ (å› ç‚º val ä¸åŒ)
#                dropDuplicates(['id', 'cat']) è¦–ç‚ºé‡è¤‡ (å› ç‚º id, cat ç›¸åŒ)

df.distinct().count() # = 2 (ä¿ç•™å…©è¡Œ)

df.dropDuplicates(['id', 'cat']).count() # = 1 (åªä¿ç•™ç¬¬ä¸€è¡Œ)
```

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶

- [pyspark.sql.DataFrame.dropDuplicates](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.dropDuplicates.html)
- [pyspark.sql.DataFrame.distinct](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.distinct.html)

---

**[è¿”å›é¡Œç›®](#question-004)**
