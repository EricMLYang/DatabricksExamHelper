# Question #013

---

## é¡Œç›®è³‡è¨Š
### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-013`

### ä¾†æº
**ä¾†æº:** Sample / Batch 1

### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹
### é¡Œå¹¹
A data engineer is building a streaming pipeline using Databricks Autoloader to ingest JSON files from an S3 bucket into a target Delta table. The engineer wants the pipeline to automatically handle problematic files and store them separately so they can be inspected later. Specifically, the engineer wants to:

- Exclude files that are badly-formed JSON.
- Exclude files that do not match the expected schema.

Which of the following code blocks meets the specified requirement?

### é¸é …
- **A.** 
```python
df = (spark.readStream
            .format("cloudFiles")
            .option("cloudFiles.format", "json")
            .option("badRecordsPath", "s3://project/quarantine")
            .schema("id int, value double")
            .load("s3://project/source/"))
```

- **B.** 
```python
df = (spark.readStream
            .format("cloudFiles")
            .option("cloudFiles.format", "json")
            .option("cloudFiles.schemaLocation", "s3://project/schema")
            .option("pathGlobFilter", "*.json", "s3://project/quarantine")
            .load("s3://project/source/"))
```

- **C.** 
```python
df = (spark.readStream
            .format("cloudFiles")
            .option("cloudFiles.format", "json")
            .schema("id int, value double")
            .rescue("s3://project/quarantine")
            .load("s3://project/source/"))
```

- **D.** 
```python
df = (spark.readStream
            .format("cloudFiles")
            .option("cloudFiles.format", "json")
            .option("cloudFiles.schemaEvolutionMode", "rescue", "s3://project/quarantine")
            .schema("id int, value double")
            .load("s3://project/source/"))
```

---

## æ¨™ç±¤ç³»çµ±
### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Auto-Loader`, `Streaming`, `Data-Quality`

### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Syntax-Confusion`, `Parameter-Order`

### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Data Ingestion

---

## ç­”æ¡ˆèˆ‡ä¾†æº
### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `A`

### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** A
- **ç¤¾ç¾¤å…±è­˜:** A

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥

**æ ¸å¿ƒæŠ€è¡“:** Auto Loader (cloudFiles) çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶

**é—œéµæ¦‚å¿µ:** 
- Bad Records Path è¨­å®š
- Auto Loader çš„è³‡æ–™å“è³ªç®¡ç†
- Streaming ä¸²æµè®€å–ä¸­çš„éŒ¯èª¤éš”é›¢

**é¡Œç›®é—œéµå­—ï¼š**
- **badly-formed JSON**: æ ¼å¼éŒ¯èª¤çš„ JSON æª”æ¡ˆï¼ˆèªæ³•éŒ¯èª¤ã€ä¸å®Œæ•´çµæ§‹ï¼‰
- **does not match the expected schema**: Schema ä¸ç¬¦åˆçš„è¨˜éŒ„ï¼ˆå‹åˆ¥éŒ¯èª¤ã€ç¼ºå°‘æ¬„ä½ï¼‰
- **store them separately**: å°‡å•é¡Œæª”æ¡ˆéš”é›¢å„²å­˜ä»¥ä¾¿å¾ŒçºŒæª¢æŸ¥
- **badRecordsPath**: Spark æ¨™æº–é¸é …ï¼Œç”¨æ–¼æŒ‡å®šéŒ¯èª¤è¨˜éŒ„çš„å„²å­˜è·¯å¾‘

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ A æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**æŠ€è¡“åŸç†ï¼š**

`badRecordsPath` æ˜¯ Spark åœ¨è™•ç†çµæ§‹åŒ–è³‡æ–™ï¼ˆJSONã€CSV ç­‰ï¼‰æ™‚çš„æ¨™æº–éŒ¯èª¤è™•ç†é¸é …ï¼Œåœ¨ Auto Loader ä¸­å®Œå…¨æ”¯æ´ã€‚é€™å€‹é¸é …å¯ä»¥åŒæ™‚è™•ç†å…©ç¨®é¡å‹çš„éŒ¯èª¤ï¼š

#### 1. è™•ç†æ ¼å¼éŒ¯èª¤çš„ JSON æª”æ¡ˆ

ç•¶ JSON æª”æ¡ˆæœ¬èº«ç„¡æ³•è¢«è§£ææ™‚ï¼ˆä¾‹å¦‚ï¼šç¼ºå°‘æ‹¬è™Ÿã€å¤šé¤˜é€—è™Ÿã€é JSON å…§å®¹ï¼‰ï¼Œ`badRecordsPath` æœƒå°‡æ•´å€‹éŒ¯èª¤è¨˜éŒ„å¯«å…¥æŒ‡å®šè·¯å¾‘ï¼Œè€Œä¸æ˜¯è®“æ•´å€‹ä¸²æµå¤±æ•—ã€‚

**ç¯„ä¾‹éŒ¯èª¤æƒ…å¢ƒï¼š**
```json
{
  "id": 1,
  "value": 123.45
  // ç¼ºå°‘çµæŸæ‹¬è™Ÿ

// æˆ–

{id: 1, value: 123.45}  // éµæ²’æœ‰å¼•è™Ÿ
```

#### 2. è™•ç† Schema ä¸ç¬¦åˆçš„è¨˜éŒ„

ç•¶è³‡æ–™å¯ä»¥è¢«è§£æç‚º JSONï¼Œä½†ç„¡æ³•ç¬¦åˆæŒ‡å®šçš„ schema æ™‚ï¼ˆä¾‹å¦‚ï¼šå‹åˆ¥è½‰æ›å¤±æ•—ã€å¿…è¦æ¬„ä½ç¼ºå¤±ï¼‰ï¼Œ`badRecordsPath` ä¹Ÿæœƒæ•ç²é€™äº›è¨˜éŒ„ã€‚

**ç¯„ä¾‹ Schema éŒ¯èª¤ï¼š**
```python
# æŒ‡å®š schema: id int, value double
# ä½†å¯¦éš›è³‡æ–™ï¼š
{"id": "abc", "value": 123.45}  # id æ‡‰ç‚º intï¼Œå¯¦éš›ç‚º string
{"id": 1, "value": "not_a_number"}  # value æ‡‰ç‚º doubleï¼Œå¯¦éš›ç‚º string
{"id": 1}  # ç¼ºå°‘ value æ¬„ä½
```

**æ­£ç¢ºç¨‹å¼ç¢¼è§£æï¼š**
```python
df = (spark.readStream
            .format("cloudFiles")  # ä½¿ç”¨ Auto Loader
            .option("cloudFiles.format", "json")  # æŒ‡å®šä¾†æºæ ¼å¼
            .option("badRecordsPath", "s3://project/quarantine")  # âœ… é—œéµè¨­å®š
            .schema("id int, value double")  # æŒ‡å®šé æœŸ schema
            .load("s3://project/source/"))
```

**åŸ·è¡Œè¡Œç‚ºï¼š**
1. æ­£å¸¸è¨˜éŒ„ â†’ é€²å…¥ DataFrameï¼Œç¹¼çºŒè™•ç†æµç¨‹
2. æ ¼å¼éŒ¯èª¤è¨˜éŒ„ â†’ å¯«å…¥ `s3://project/quarantine`ï¼ŒåŒ…å«åŸå§‹å…§å®¹èˆ‡éŒ¯èª¤è³‡è¨Š
3. Schema éŒ¯èª¤è¨˜éŒ„ â†’ åŒæ¨£å¯«å…¥éš”é›¢å€ï¼Œä¸²æµä¸æœƒä¸­æ–·

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### é¸é … B
```python
.option("cloudFiles.schemaLocation", "s3://project/schema")
.option("pathGlobFilter", "*.json", "s3://project/quarantine")
```

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

1. **`pathGlobFilter` ç”¨é€”éŒ¯èª¤**: 
   - `pathGlobFilter` æ˜¯ç”¨ä¾†**ç¯©é¸è¦è®€å–çš„æª”æ¡ˆ**ï¼ˆä¾‹å¦‚åªè®€å– `*.json` æª”æ¡ˆï¼‰ï¼Œä¸æ˜¯ç”¨ä¾†æŒ‡å®šéš”é›¢è·¯å¾‘ã€‚
   - æ­£ç¢ºç”¨æ³•ï¼š`.option("pathGlobFilter", "*.json")`ï¼ˆåªæœ‰ä¸€å€‹åƒæ•¸ï¼‰

2. **ç„¡æ³•è™•ç†éŒ¯èª¤è¨˜éŒ„**: 
   - æ²’æœ‰ `badRecordsPath`ï¼Œç•¶é‡åˆ°æ ¼å¼éŒ¯èª¤æˆ– Schema éŒ¯èª¤æ™‚ï¼Œä¸²æµæœƒç›´æ¥å¤±æ•—æˆ–è·³éè¨˜éŒ„ï¼Œç„¡æ³•å„²å­˜åˆ°éš”é›¢å€ã€‚

3. **`cloudFiles.schemaLocation` çš„èª¤ç”¨**:
   - `schemaLocation` æ˜¯ç”¨ä¾†å„²å­˜ Auto Loader è‡ªå‹•æ¨æ–·çš„ schemaï¼Œä¸æ˜¯ç”¨ä¾†å®šç¾©éŒ¯èª¤è™•ç†è¡Œç‚ºã€‚

---

### é¸é … C
```python
.rescue("s3://project/quarantine")
```

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

1. **æ–¹æ³•ä¸å­˜åœ¨**: 
   - Spark DataStreamReader æ²’æœ‰ `.rescue()` æ–¹æ³•ï¼Œé€™æ˜¯è™›æ§‹çš„ APIã€‚

2. **æ··æ·† `_rescued_data` column**:
   - Auto Loader æœ‰ `_rescued_data` æ¬„ä½ï¼ˆç”¨æ–¼å„²å­˜ç„¡æ³•è§£æçš„è³‡æ–™ç‰‡æ®µï¼‰ï¼Œä½†ä¸æ˜¯é€é `.rescue()` æ–¹æ³•è¨­å®šã€‚
   - `_rescued_data` æ˜¯ schema çš„ä¸€éƒ¨åˆ†ï¼Œèˆ‡éŒ¯èª¤éš”é›¢è·¯å¾‘ç„¡é—œã€‚

3. **èªæ³•éŒ¯èª¤**:
   - å³ä½¿è¦ä½¿ç”¨é¡ä¼¼åŠŸèƒ½ï¼Œä¹Ÿæ‡‰è©²æ˜¯ `.option("rescuedDataColumn", "_rescued_data")`ï¼Œè€Œé `.rescue()` æ–¹æ³•ã€‚

---

### é¸é … D
```python
.option("cloudFiles.schemaEvolutionMode", "rescue", "s3://project/quarantine")
```

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

1. **åƒæ•¸æ•¸é‡éŒ¯èª¤**: 
   - `.option()` æ–¹æ³•åªæ¥å—å…©å€‹åƒæ•¸ï¼š`(key, value)`
   - é€™è£¡æä¾›äº†ä¸‰å€‹åƒæ•¸ï¼š`("cloudFiles.schemaEvolutionMode", "rescue", "s3://project/quarantine")`ï¼Œèªæ³•éŒ¯èª¤ã€‚

2. **`schemaEvolutionMode` ç”¨é€”éŒ¯èª¤**:
   - `schemaEvolutionMode` çš„åˆæ³•å€¼æ˜¯ï¼š`addNewColumns`, `failOnNewColumns`, `rescue`
   - é€™å€‹é¸é …æ§åˆ¶çš„æ˜¯ã€Œæ–°æ¬„ä½å‡ºç¾æ™‚çš„è¡Œç‚ºã€ï¼Œä¸æ˜¯ã€ŒéŒ¯èª¤è¨˜éŒ„çš„å„²å­˜è·¯å¾‘ã€

3. **æ··æ·†å…©ç¨®æ©Ÿåˆ¶**:
   - Schema Evolutionï¼ˆschema æ¼”åŒ–ï¼‰: è™•ç†æ¬„ä½æ–°å¢/è®Šæ›´
   - Bad Records Handlingï¼ˆéŒ¯èª¤è¨˜éŒ„è™•ç†ï¼‰: è™•ç†è§£æå¤±æ•—/å‹åˆ¥éŒ¯èª¤
   - é€™å…©è€…æ˜¯ä¸åŒçš„æ©Ÿåˆ¶ï¼Œä¸æ‡‰æ··ç”¨

---

## ğŸ§  è¨˜æ†¶æ³•

### å£è¨£
**ã€Œå£è¨˜éŒ„æ‰¾å£è·¯å¾‘ã€**  
â†’ **Bad Records** è¦è¨­å®š **Bad Records Path**

### å°æ¯”è¡¨ï¼šAuto Loader éŒ¯èª¤è™•ç† vs Schema æ¼”åŒ–

| åŠŸèƒ½ | åƒæ•¸åç¨± | ç”¨é€” | ç¯„ä¾‹å€¼ |
|------|---------|------|--------|
| **éŒ¯èª¤è¨˜éŒ„éš”é›¢** | `badRecordsPath` | å„²å­˜**æ ¼å¼éŒ¯èª¤**æˆ–**å‹åˆ¥éŒ¯èª¤**çš„è¨˜éŒ„ | `s3://bucket/quarantine` |
| **Schema æ¼”åŒ–** | `cloudFiles.schemaEvolutionMode` | æ§åˆ¶**æ–°æ¬„ä½å‡ºç¾**æ™‚çš„è¡Œç‚º | `addNewColumns`, `rescue` |
| **Rescued Data** | `cloudFiles.rescuedDataColumn` | åœ¨åŸå§‹ DataFrame ä¸­æ–°å¢æ¬„ä½ï¼Œå„²å­˜**éƒ¨åˆ†å¯æ•‘å›çš„è³‡æ–™** | `_rescued_data` (é è¨­) |
| **æª”æ¡ˆç¯©é¸** | `pathGlobFilter` | **ç¯©é¸è¦è®€å–**çš„æª”æ¡ˆ | `*.json`, `part-*.parquet` |

### å¯¦ä¾‹è¨˜æ†¶

**æƒ…å¢ƒï¼šé†«é™¢æ€¥è¨ºå®¤çš„ç—…æ‚£åˆ†æµ**
- **æ­£å¸¸ç—…æ‚£** â†’ é€²å…¥ä¸€èˆ¬è¨ºç™‚æµç¨‹ï¼ˆæ­£å¸¸è¨˜éŒ„é€²å…¥ DataFrameï¼‰
- **é‡ç—‡ç—…æ‚£** â†’ é€åˆ°ç‰¹æ®Šéš”é›¢ç—…æˆ¿ï¼ˆ`badRecordsPath` éš”é›¢å€ï¼‰
- **æ–°å¢æª¢æŸ¥é …ç›®** â†’ æ›´æ–°ç—…æ­·æ ¼å¼ï¼ˆ`schemaEvolutionMode` è™•ç†æ–°æ¬„ä½ï¼‰

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶

- [Auto Loader - Databricks Documentation](https://docs.databricks.com/ingestion/auto-loader/index.html)
- [Bad Records Handling in Spark](https://docs.databricks.com/ingestion/auto-loader/options.html#bad-records-handling)
- [Schema Evolution with Auto Loader](https://docs.databricks.com/ingestion/auto-loader/schema.html)
- [cloudFiles Options Reference](https://docs.databricks.com/ingestion/auto-loader/options.html)

---

**[è¿”å›é¡Œç›®](#question-013)**
