# Question #32

---

## 題目資訊

### 題目編號
**ID:** `Q-032`

### 來源
**來源:** Real Exam Recall

### 難度等級
**難度:** `L2-Intermediate`

---

## 題目內容

### 題幹

The data engineering team maintains the following code:

```python
accountDF = spark.table("accounts")
orderDF = spark.table("orders")
itemDF = spark.table("items")

orderWithItemDF = (orderDF.join(
    itemDF,
    orderDF.itemID == itemDF.itemID)
    .select(
        orderDF.accountID,
        orderDF.itemID,
        itemDF.itemName))

finalDF = (accountDF.join(
    orderWithItemDF,
    accountDF.accountID == orderWithItemDF.accountID)
    .select(
        orderWithItemDF["*"],
        accountDF.city))

(finalDF.write
 .mode("overwrite")
 .table("enriched_itemized_orders_by_account"))
```

Assuming that this code produces logically correct results and the data in the source tables has been de-duplicated and validated, which statement describes what will occur when this code is executed?

### 選項

- **A.** A batch job will update the enriched_itemized_orders_by_account table, replacing only those rows that have different values than the current version of the table, using accountID as the primary key.
- **B.** The enriched_itemized_orders_by_account table will be overwritten using the current valid version of data in each of the three tables referenced in the join logic.
- **C.** An incremental job will leverage information in the state store to identify unjoined rows in the source tables and write these rows to the enriched_itemized_orders_by_account table.
- **D.** An incremental job will detect if new rows have been written to any of the source tables; if new rows are detected, all results will be recalculated and used to overwrite the enriched_itemized_orders_by_account table.
- **E.** No computation will occur until enriched_itemized_orders_by_account is queried; upon query materialization, results will be calculated using the current valid version of data in each of the three tables referenced in the join logic.

---

## 標籤系統

### Topic Tags (技術主題標籤)
**Topics:** `Batch-Processing`, `Joins`, `Write-Modes`, `DataFrames`

### Trap Tags (陷阱類型標籤)
**Traps:** `Batch-vs-Stream`, `Overwrite-Behavior`

### Knowledge Domain (知識領域)
**Domain:** `Data Engineering`

---

## 答案與解析連結

### 正確答案
**正解:** `B`

### 解析檔案
**詳細解析:** [點此查看解析](../analysis/Q-032-analysis.md)

---

## 相關資源

### 官方文件
- [DataFrame Write Operations](https://docs.databricks.com/spark/latest/spark-sql/dataframes-datasets.html)
- [Save Modes](https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html)
