# Q-088

## é¡Œç›®è³‡è¨Š

**ID:** `Q-088`

**ä¾†æº:** Mock Exam (Source labeled as #388)

**é›£åº¦:** `L1-Basic`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹

You are testing a collection of mathematical functions, one of which calculates the area under a curve as described by another function.

```python
assert(myIntegrate(lambda x: x*x, 0, 3) == 9)
```

Which kind of test would the above line exemplify?

### é¸é …

- **A.** Unit
- **B.** Manual
- **C.** Functional
- **D.** Integration
- **E.** End-to-end

---

## æ¨™ç±¤ç³»çµ±

**Topics:** `Testing`, `Python`, `Software-Engineering`

**Traps:** `Test-Type-Confusion`

**Domain:** `é–‹ç™¼èˆ‡è½‰æ› (Development & Transformation)`

---

## ç­”æ¡ˆèˆ‡åˆ†æ

### æ­£ç¢ºç­”æ¡ˆ

**æ­£è§£:** `A`

---

## ğŸ“ è€ƒé»è­˜åˆ¥

### ä¸»è¦è€ƒé»
**æ ¸å¿ƒæŠ€è¡“:** Unit Testing (å–®å…ƒæ¸¬è©¦)
**çŸ¥è­˜é ˜åŸŸ:** é–‹ç™¼èˆ‡è½‰æ› - è»Ÿé«”æ¸¬è©¦æœ€ä½³å¯¦è¸
**é—œéµæ¦‚å¿µ:** 
- å–®å…ƒæ¸¬è©¦çš„å®šç¾©èˆ‡ç‰¹å¾µ
- æ¸¬è©¦é¡å‹çš„å€åˆ†ï¼ˆUnit vs Integration vs E2Eï¼‰
- Python assert èªå¥åœ¨æ¸¬è©¦ä¸­çš„æ‡‰ç”¨

### æ¬¡è¦è€ƒé»
- ç†è§£ä¸åŒæ¸¬è©¦å±¤ç´šçš„ç”¨é€”
- æ•¸å­¸å‡½æ•¸æ¸¬è©¦ç¯„ä¾‹ï¼ˆç©åˆ†è¨ˆç®—é©—è­‰ï¼‰

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ A (Unit) æ˜¯æ­£ç¢ºçš„ï¼Ÿ

**æŠ€è¡“åŸç†:**

**Unit Test (å–®å…ƒæ¸¬è©¦)** æ˜¯è»Ÿé«”æ¸¬è©¦çš„æœ€å°å–®ä½ï¼Œç‰¹å¾µåŒ…æ‹¬ï¼š

1. **æ¸¬è©¦å–®ä¸€åŠŸèƒ½/å‡½æ•¸** - å°ˆæ³¨æ–¼æ¸¬è©¦ä¸€å€‹ç¨ç«‹çš„ç¨‹å¼ç¢¼å–®å…ƒ
2. **éš”é›¢æ€§** - ä¸ä¾è³´å¤–éƒ¨ç³»çµ±ï¼ˆè³‡æ–™åº«ã€APIã€æª”æ¡ˆç³»çµ±ï¼‰
3. **å¿«é€ŸåŸ·è¡Œ** - é€šå¸¸åœ¨æ¯«ç§’å…§å®Œæˆ
4. **å¯é æ¸¬æ€§** - çµ¦å®šç›¸åŒè¼¸å…¥ï¼Œç¸½æ˜¯å¾—åˆ°ç›¸åŒè¼¸å‡º
5. **è‡ªå‹•åŒ–é©—è­‰** - ä½¿ç”¨ assert èªå¥è‡ªå‹•é©—è­‰çµæœ

**ç¬¦åˆéœ€æ±‚:**

æ­¤é¡Œç›®ä¸­çš„ç¨‹å¼ç¢¼å±•ç¾å…¸å‹çš„ Unit Test ç‰¹å¾µï¼š

```python
assert(myIntegrate(lambda x: x*x, 0, 3) == 9)
```

åˆ†æï¼š
- **æ¸¬è©¦ç›®æ¨™ï¼š** å–®ä¸€å‡½æ•¸ `myIntegrate`
- **æ¸¬è©¦è¼¸å…¥ï¼š** 
  - å‡½æ•¸ï¼š`lambda x: x*x`ï¼ˆxÂ²ï¼‰
  - ç©åˆ†ç¯„åœï¼š0 åˆ° 3
- **é æœŸè¼¸å‡ºï¼š** 9
  - æ•¸å­¸é©—è­‰ï¼šâˆ«â‚€Â³ xÂ² dx = [xÂ³/3]â‚€Â³ = 27/3 = 9 âœ“
- **é©—è­‰æ–¹å¼ï¼š** assert èªå¥ï¼ˆè‡ªå‹•åŒ–ï¼‰
- **éš”é›¢æ€§ï¼š** ç´”å‡½æ•¸é‹ç®—ï¼Œç„¡å¤–éƒ¨ä¾è³´

**å¯¦å‹™æ‡‰ç”¨:**

åœ¨ Databricks/PySpark é–‹ç™¼ä¸­çš„å–®å…ƒæ¸¬è©¦ç¯„ä¾‹ï¼š

```python
# æ¸¬è©¦è‡ªè¨‚è½‰æ›å‡½æ•¸
def clean_name(name):
    """ç§»é™¤åç¨±ä¸­çš„ç‰¹æ®Šå­—å…ƒ"""
    return name.strip().lower().replace(" ", "_")

# Unit Test
def test_clean_name():
    assert clean_name("  John Doe  ") == "john_doe"
    assert clean_name("Mary-Jane") == "mary-jane"
    assert clean_name("Bob123") == "bob123"
    print("All tests passed!")

test_clean_name()
```

```python
# æ¸¬è©¦è³‡æ–™è½‰æ›é‚è¼¯
def calculate_discount(price, discount_rate):
    """è¨ˆç®—æŠ˜æ‰£å¾Œåƒ¹æ ¼"""
    return price * (1 - discount_rate)

# Unit Test
def test_calculate_discount():
    assert calculate_discount(100, 0.1) == 90.0
    assert calculate_discount(200, 0.25) == 150.0
    assert calculate_discount(50, 0) == 50.0
    print("Discount calculation tests passed!")

test_calculate_discount()
```

**æ¸¬è©¦é‡‘å­—å¡” (Testing Pyramid):**

```
        â•±â•²
       â•±E2Eâ•²          å°‘é‡ E2E æ¸¬è©¦ï¼ˆæœ€æ…¢ã€æœ€è²´ï¼‰
      â•±â”€â”€â”€â”€â”€â”€â•²
     â•±Integrationâ•²    é©é‡æ•´åˆæ¸¬è©¦ï¼ˆä¸­é€Ÿã€ä¸­æˆæœ¬ï¼‰
    â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
   â•±  Unit Tests  â•²   å¤§é‡å–®å…ƒæ¸¬è©¦ï¼ˆæœ€å¿«ã€æœ€ä¾¿å®œï¼‰âœ… æ­¤é¡Œå±¬æ–¼é€™å±¤
  â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### é¸é … B - Manual

**éŒ¯èª¤åŸå› :** é€™æ˜¯**è‡ªå‹•åŒ–æ¸¬è©¦**ï¼Œè€Œéæ‰‹å‹•æ¸¬è©¦

**è©³ç´°åˆ†æ:**
- **Manual Test (æ‰‹å‹•æ¸¬è©¦)** éœ€è¦äººå·¥ä»‹å…¥ï¼š
  - æ‰‹å‹•åŸ·è¡Œç¨‹å¼
  - æ‰‹å‹•æª¢æŸ¥è¼¸å‡º
  - æ‰‹å‹•åˆ¤æ–·æ­£ç¢ºæ€§
- é¡Œç›®ä¸­çš„ `assert` èªå¥æ˜¯**è‡ªå‹•åŒ–é©—è­‰**ï¼š
  - è‡ªå‹•æ¯”è¼ƒçµæœ
  - å¦‚æœä¸ç¬¦åˆé æœŸè‡ªå‹•æ‹‹å‡ºéŒ¯èª¤
  - å¯æ•´åˆåˆ° CI/CD æµç¨‹
  
```python
# Manual Testing (éŒ¯èª¤ç¤ºç¯„)
result = myIntegrate(lambda x: x*x, 0, 3)
print(f"Result: {result}")  # æ‰‹å‹•çœ‹çµæœæ˜¯ä¸æ˜¯ 9

# Automated Unit Testing (æ­£ç¢ºç¤ºç¯„)
assert myIntegrate(lambda x: x*x, 0, 3) == 9  # è‡ªå‹•é©—è­‰
```

**æ˜“æ··æ·†é»:**
æœ‰äº›äººå¯èƒ½èªç‚ºã€Œéœ€è¦äººå¯«æ¸¬è©¦ç¨‹å¼ç¢¼ã€å°±æ˜¯æ‰‹å‹•æ¸¬è©¦ï¼Œä½†å¯¦éš›ä¸Šæ‰‹å‹•æ¸¬è©¦æŒ‡çš„æ˜¯ã€ŒåŸ·è¡Œèˆ‡é©—è­‰éç¨‹ã€éœ€è¦äººå·¥ä»‹å…¥

---

### é¸é … C - Functional

**éŒ¯èª¤åŸå› :** Functional Test æ¸¬è©¦çš„æ˜¯**æ¥­å‹™åŠŸèƒ½**ï¼Œè€Œéå–®ä¸€ç¨‹å¼å‡½æ•¸

**è©³ç´°åˆ†æ:**
- **Functional Test (åŠŸèƒ½æ¸¬è©¦)** ç‰¹å¾µï¼š
  - å¾**ä½¿ç”¨è€…è§’åº¦**æ¸¬è©¦ç³»çµ±åŠŸèƒ½
  - é©—è­‰ç³»çµ±æ˜¯å¦ç¬¦åˆ**æ¥­å‹™éœ€æ±‚**
  - é€šå¸¸æ¶‰åŠå¤šå€‹å…ƒä»¶å”ä½œ
  - ç¯„ä¾‹ï¼šã€Œä½¿ç”¨è€…èƒ½å¦æˆåŠŸç™»å…¥ã€ã€ã€Œè¨‚å–®èƒ½å¦æ­£ç¢ºè¨ˆç®—ç¸½é‡‘é¡ã€

- **Unit Test** ç‰¹å¾µï¼š
  - å¾**é–‹ç™¼è€…è§’åº¦**æ¸¬è©¦ç¨‹å¼ç¢¼å–®å…ƒ
  - é©—è­‰**å‡½æ•¸é‚è¼¯**æ˜¯å¦æ­£ç¢º
  - æ¸¬è©¦å–®ä¸€å‡½æ•¸ï¼Œä¸æ¶‰åŠå…¶ä»–å…ƒä»¶
  - ç¯„ä¾‹ï¼šã€ŒmyIntegrate å‡½æ•¸èƒ½å¦æ­£ç¢ºè¨ˆç®—ç©åˆ†ã€

**å°æ¯”ç¯„ä¾‹ï¼š**

```python
# Unit Test - æ¸¬è©¦å–®ä¸€å‡½æ•¸
assert calculate_total_price([10, 20, 30]) == 60

# Functional Test - æ¸¬è©¦æ¥­å‹™åŠŸèƒ½
"""
1. ä½¿ç”¨è€…å°‡å•†å“åŠ å…¥è³¼ç‰©è»Š
2. ä½¿ç”¨è€…è¼¸å…¥å„ªæƒ ç¢¼
3. ç³»çµ±è¨ˆç®—æŠ˜æ‰£å¾Œç¸½é‡‘é¡
4. ä½¿ç”¨è€…ç¢ºèªè¨‚å–®
5. é©—è­‰è¨‚å–®é‡‘é¡æ˜¯å¦æ­£ç¢º
"""
```

**æ˜“æ··æ·†é»:**
ã€ŒFunctionalã€é€™å€‹è©å®¹æ˜“èˆ‡ã€ŒFunction (å‡½æ•¸)ã€æ··æ·†ï¼Œä½† Functional Testing æŒ‡çš„æ˜¯ã€ŒåŠŸèƒ½æ¸¬è©¦ã€è€Œéã€Œå‡½æ•¸æ¸¬è©¦ã€

---

### é¸é … D - Integration

**éŒ¯èª¤åŸå› :** Integration Test æ¸¬è©¦**å¤šå€‹å…ƒä»¶çš„æ•´åˆ**ï¼Œè€Œæ­¤é¡Œåªæ¸¬è©¦å–®ä¸€å‡½æ•¸

**è©³ç´°åˆ†æ:**
- **Integration Test (æ•´åˆæ¸¬è©¦)** ç‰¹å¾µï¼š
  - æ¸¬è©¦**å¤šå€‹å…ƒä»¶ä¹‹é–“çš„äº’å‹•**
  - é©—è­‰ä»‹é¢/API æ˜¯å¦æ­£ç¢ºä¸²æ¥
  - å¯èƒ½æ¶‰åŠè³‡æ–™åº«ã€å¤–éƒ¨æœå‹™ã€æª”æ¡ˆç³»çµ±
  - ç¯„ä¾‹ï¼šã€Œè³‡æ–™è®€å– â†’ è½‰æ› â†’ å¯«å…¥ Delta Lakeã€æµç¨‹

- **Unit Test** ç‰¹å¾µï¼š
  - æ¸¬è©¦**å–®ä¸€å…ƒä»¶**çš„é‚è¼¯
  - **éš”é›¢**å…¶ä»–å…ƒä»¶ï¼ˆä½¿ç”¨ mock/stubï¼‰
  - ä¸æ¶‰åŠå¤–éƒ¨ä¾è³´
  - ç¯„ä¾‹ï¼šã€ŒmyIntegrate å‡½æ•¸æœ¬èº«çš„è¨ˆç®—é‚è¼¯ã€

**å°æ¯”ç¯„ä¾‹ï¼š**

```python
# Unit Test - åªæ¸¬è©¦è½‰æ›é‚è¼¯
def transform_data(data):
    return [x * 2 for x in data]

assert transform_data([1, 2, 3]) == [2, 4, 6]  âœ… Unit Test

# Integration Test - æ¸¬è©¦å®Œæ•´æµç¨‹
def test_etl_pipeline():
    # 1. å¾è³‡æ–™åº«è®€å–
    data = read_from_database()
    
    # 2. è½‰æ›è³‡æ–™
    transformed = transform_data(data)
    
    # 3. å¯«å…¥ Delta Lake
    write_to_delta(transformed)
    
    # 4. é©—è­‰å¯«å…¥çµæœ
    result = spark.read.format("delta").load("/path/to/table")
    assert result.count() > 0  âœ… Integration Test
```

**æ˜“æ··æ·†é»:**
`myIntegrate` é›–ç„¶æ¥å—å¦ä¸€å€‹å‡½æ•¸ (`lambda`) ä½œç‚ºåƒæ•¸ï¼Œä½†é€™ä¸æ˜¯ã€Œæ•´åˆæ¸¬è©¦ã€ï¼Œå› ç‚º lambda åªæ˜¯**è¼¸å…¥è³‡æ–™**ï¼Œä¸æ˜¯ç¨ç«‹çš„å¤–éƒ¨å…ƒä»¶

---

### é¸é … E - End-to-end

**éŒ¯èª¤åŸå› :** E2E Test æ¸¬è©¦**æ•´å€‹ç³»çµ±æµç¨‹**ï¼Œè€Œæ­¤é¡Œåªæ¸¬è©¦å–®ä¸€å‡½æ•¸

**è©³ç´°åˆ†æ:**
- **End-to-End Test (ç«¯åˆ°ç«¯æ¸¬è©¦)** ç‰¹å¾µï¼š
  - æ¸¬è©¦**å®Œæ•´çš„ä½¿ç”¨è€…å ´æ™¯**
  - å¾é ­åˆ°å°¾æ¶µè“‹æ‰€æœ‰å±¤ç´šï¼ˆUI â†’ API â†’ Databaseï¼‰
  - é€šå¸¸æœ€æ…¢ã€æœ€è¤‡é›œã€ç¶­è­·æˆæœ¬æœ€é«˜
  - ç¯„ä¾‹ï¼šã€Œä½¿ç”¨è€…ç™»å…¥ â†’ ç€è¦½å•†å“ â†’ åŠ å…¥è³¼ç‰©è»Š â†’ çµå¸³ â†’ ç¢ºèªè¨‚å–®ã€

- **Unit Test** ç‰¹å¾µï¼š
  - æ¸¬è©¦**æœ€å°ç¨‹å¼ç¢¼å–®å…ƒ**
  - åªé—œæ³¨å–®ä¸€å‡½æ•¸/æ–¹æ³•
  - æœ€å¿«ã€æœ€ç°¡å–®ã€ç¶­è­·æˆæœ¬æœ€ä½
  - ç¯„ä¾‹ï¼šã€ŒmyIntegrate å‡½æ•¸çš„è¨ˆç®—é‚è¼¯ã€

**å°æ¯”ç¯„ä¾‹ (Databricks æƒ…å¢ƒ):**

```python
# Unit Test - æ¸¬è©¦è½‰æ›å‡½æ•¸
def add_timestamp(df):
    from pyspark.sql.functions import current_timestamp
    return df.withColumn("processed_at", current_timestamp())

# åªæ¸¬è©¦å‡½æ•¸æœ¬èº«
test_df = spark.createDataFrame([(1,)], ["id"])
result = add_timestamp(test_df)
assert "processed_at" in result.columns  âœ… Unit Test

# End-to-End Test - æ¸¬è©¦å®Œæ•´è³‡æ–™ç®¡ç·š
"""
1. å¾ S3 è®€å–åŸå§‹ CSV æª”æ¡ˆ
2. ä½¿ç”¨ Auto Loader ä¸²æµè®€å–
3. å¥—ç”¨è½‰æ›é‚è¼¯ï¼ˆåŒ…å« add_timestampï¼‰
4. å¯«å…¥ Delta Lake Bronze å±¤
5. è§¸ç™¼ Delta Live Tables ç®¡ç·š
6. é©—è­‰ Gold å±¤è³‡æ–™æ­£ç¢ºæ€§
7. æª¢æŸ¥ Databricks SQL å„€è¡¨æ¿é¡¯ç¤º
"""  âœ… End-to-End Test
```

**æ˜“æ··æ·†é»:**
ä¸è¦å› ç‚ºæ¸¬è©¦ã€Œæ•¸å­¸è¨ˆç®—çš„å®Œæ•´éç¨‹ã€å°±èªç‚ºæ˜¯ E2Eï¼ŒE2E æŒ‡çš„æ˜¯ã€Œç³»çµ±å±¤ç´šçš„å®Œæ•´æµç¨‹ã€

---

## ğŸ§  è¨˜æ†¶æ³•èˆ‡æŠ€å·§

### å£è¨£
**ã€Œæ¸¬ä¸€å€‹å‡½æ•¸å°±æ˜¯ Unitï¼Œå¤šå€‹å…ƒä»¶å« Integrationã€**

### é—œéµå°æ¯”è¡¨

| æ¸¬è©¦é¡å‹ | æ¸¬è©¦ç¯„åœ | é€Ÿåº¦ | å¤–éƒ¨ä¾è³´ | æ­¤é¡Œæ˜¯å¦ç¬¦åˆ |
|---------|---------|------|---------|------------|
| **Unit** | å–®ä¸€å‡½æ•¸/æ–¹æ³• | æœ€å¿«ï¼ˆæ¯«ç§’ç´šï¼‰ | ç„¡ | âœ… æ˜¯ |
| Manual | ä»»ä½•ç¯„åœ | æ…¢ | å¯èƒ½æœ‰ | âŒ å¦ï¼ˆæœ‰ assert è‡ªå‹•åŒ–ï¼‰ |
| Functional | æ¥­å‹™åŠŸèƒ½ | ä¸­ç­‰ | å¯èƒ½æœ‰ | âŒ å¦ï¼ˆéæ¥­å‹™åŠŸèƒ½ï¼‰ |
| Integration | å¤šå€‹å…ƒä»¶æ•´åˆ | è¼ƒæ…¢ | æœ‰ | âŒ å¦ï¼ˆå–®ä¸€å‡½æ•¸ï¼‰ |
| End-to-end | å®Œæ•´ç³»çµ±æµç¨‹ | æœ€æ…¢ï¼ˆç§’/åˆ†é˜ç´šï¼‰ | æœ‰ | âŒ å¦ï¼ˆéç³»çµ±ç´šï¼‰ |

### åˆ¤æ–·æµç¨‹åœ–

```
é¡Œç›®ï¼šassert(myIntegrate(lambda x: x*x, 0, 3) == 9)

åˆ¤æ–·æ­¥é©Ÿï¼š
1. æ˜¯å¦è‡ªå‹•åŒ–é©—è­‰ï¼Ÿ
   assert èªå¥ â†’ æ˜¯ âœ“ (æ’é™¤ Manual)

2. æ¸¬è©¦å¹¾å€‹å…ƒä»¶ï¼Ÿ
   åªæœ‰ myIntegrate ä¸€å€‹å‡½æ•¸ â†’ å–®ä¸€å…ƒä»¶ âœ“ (æ’é™¤ Integration, E2E)

3. æ¸¬è©¦ç¨‹å¼é‚è¼¯é‚„æ˜¯æ¥­å‹™åŠŸèƒ½ï¼Ÿ
   æ¸¬è©¦å‡½æ•¸è¨ˆç®—é‚è¼¯ â†’ ç¨‹å¼é‚è¼¯ âœ“ (æ’é™¤ Functional)

çµè«–ï¼šUnit Test âœ…
```

### è¨˜æ†¶æŠ€å·§

**æ¸¬è©¦é‡‘å­—å¡”è¨˜æ†¶æ³•ï¼š**

```
æ•¸é‡ï¼šUnit > Integration > E2E
é€Ÿåº¦ï¼šUnit > Integration > E2E
æˆæœ¬ï¼šUnit < Integration < E2E
éš”é›¢ï¼šUnit (æœ€éš”é›¢) > Integration > E2E (æœ€æ•´åˆ)

æ­¤é¡Œç‰¹å¾µï¼š
- å–®ä¸€å‡½æ•¸ âœ“
- ç„¡å¤–éƒ¨ä¾è³´ âœ“
- å¿«é€ŸåŸ·è¡Œ âœ“
- è‡ªå‹•é©—è­‰ âœ“
â†’ Unit Test
```

### å¯¦å‹™è­˜åˆ¥è¦é»

**Unit Test çš„æ˜ç¢ºç‰¹å¾µï¼ˆå¿…é ˆå…¨éƒ¨ç¬¦åˆï¼‰ï¼š**
1. âœ… æ¸¬è©¦å–®ä¸€å‡½æ•¸/æ–¹æ³•ï¼ˆ`myIntegrate`ï¼‰
2. âœ… æœ‰æ˜ç¢ºè¼¸å…¥ï¼ˆ`lambda x: x*x, 0, 3`ï¼‰
3. âœ… æœ‰é æœŸè¼¸å‡ºï¼ˆ`9`ï¼‰
4. âœ… è‡ªå‹•åŒ–é©—è­‰ï¼ˆ`assert`ï¼‰
5. âœ… ä¸ä¾è³´å¤–éƒ¨ç³»çµ±ï¼ˆç´”æ•¸å­¸è¨ˆç®—ï¼‰
6. âœ… å¯ç¨ç«‹åŸ·è¡Œï¼ˆä¸éœ€è¦å…¶ä»–å…ƒä»¶ï¼‰

**æ­¤é¡Œå®Œå…¨ç¬¦åˆä»¥ä¸Šæ‰€æœ‰ç‰¹å¾µ â†’ 100% ç¢ºå®šæ˜¯ Unit Test**

---

## ğŸ“š å»¶ä¼¸é–±è®€

### å®˜æ–¹æ–‡ä»¶
- [Databricks - Testing best practices](https://docs.databricks.com/dev-tools/testing.html)
- [Python unittest module](https://docs.python.org/3/library/unittest.html)
- [pytest documentation](https://docs.pytest.org/)

### ç›¸é—œæ¦‚å¿µ
- æ¸¬è©¦é‡‘å­—å¡”ï¼ˆTest Pyramidï¼‰
- TDD (Test-Driven Development)
- Mocking and Stubbing in Unit Tests
- PySpark Unit Testing æœ€ä½³å¯¦è¸

### å¯¦å‹™ç¯„ä¾‹ (Databricks å–®å…ƒæ¸¬è©¦)

```python
# ç¯„ä¾‹ 1: æ¸¬è©¦è‡ªè¨‚ UDF
from pyspark.sql.types import IntegerType
from pyspark.sql.functions import udf

def square(x):
    return x * x

square_udf = udf(square, IntegerType())

# Unit Test
def test_square_udf():
    assert square(3) == 9
    assert square(0) == 0
    assert square(-2) == 4
    print("UDF tests passed!")

test_square_udf()
```

```python
# ç¯„ä¾‹ 2: æ¸¬è©¦è³‡æ–™è½‰æ›å‡½æ•¸
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

def add_age_category(df):
    """æ–°å¢å¹´é½¡åˆ†é¡æ¬„ä½"""
    return df.withColumn(
        "age_category",
        when(col("age") < 18, "Minor")
        .when(col("age") < 65, "Adult")
        .otherwise("Senior")
    )

# Unit Test
def test_add_age_category():
    spark = SparkSession.builder.getOrCreate()
    test_data = [(10,), (30,), (70,)]
    test_df = spark.createDataFrame(test_data, ["age"])
    
    result = add_age_category(test_df)
    categories = [row.age_category for row in result.collect()]
    
    assert categories == ["Minor", "Adult", "Senior"]
    print("Age category test passed!")

test_add_age_category()
```

### pytest æ¡†æ¶ç¯„ä¾‹

```python
# test_integration.py
import pytest

def myIntegrate(func, a, b):
    """ç°¡å–®çš„æ•¸å€¼ç©åˆ†ï¼ˆæ¢¯å½¢æ³•ï¼‰"""
    n = 1000
    h = (b - a) / n
    result = 0.5 * (func(a) + func(b))
    for i in range(1, n):
        result += func(a + i * h)
    return result * h

# Unit Tests
def test_integrate_square():
    """æ¸¬è©¦ xÂ² çš„ç©åˆ†"""
    result = myIntegrate(lambda x: x*x, 0, 3)
    assert abs(result - 9) < 0.01  # å…è¨±æ•¸å€¼èª¤å·®

def test_integrate_linear():
    """æ¸¬è©¦ x çš„ç©åˆ†"""
    result = myIntegrate(lambda x: x, 0, 2)
    assert abs(result - 2) < 0.01  # âˆ«â‚€Â² x dx = 2

def test_integrate_constant():
    """æ¸¬è©¦å¸¸æ•¸çš„ç©åˆ†"""
    result = myIntegrate(lambda x: 5, 0, 10)
    assert abs(result - 50) < 0.01  # âˆ«â‚€Â¹â° 5 dx = 50

# åŸ·è¡Œæ¸¬è©¦ï¼špytest test_integration.py
```

---

## ğŸ”— ç›¸é—œé¡Œç›®
- Q-XXX: PySpark DataFrame å–®å…ƒæ¸¬è©¦æœ€ä½³å¯¦è¸
- Q-XXX: CI/CD æ•´åˆæ¸¬è©¦ç­–ç•¥
- Q-XXX: Delta Lake è³‡æ–™å“è³ªæ¸¬è©¦
