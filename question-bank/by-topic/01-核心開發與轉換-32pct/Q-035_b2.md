# Question #035

---

## é¡Œç›®è³‡è¨Š

### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-035`

### ä¾†æº
**ä¾†æº:** Community

### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L3-Advanced`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹

Given the following query on the Delta table 'customers' on which Change Data Feed is enabled:

```python
spark.read
    .option("readChangeFeed", "true")
    .option("startingVersion", 0)
    .table("customers")
    .filter(col("_change_type").isin(["update_postimage"]))
.write
    .mode("append")
    .table("customers_updates")
```

Which statement describes the result of this query each time it is executed?

### é¸é …

- **A.** The entire history of updated records will overwrite the target table at each execution.
- **B.** Newly updated records will overwrite the target table.
- **C.** The entire history of updated records will be appended to the target table at each execution, which leads to duplicate entries.
- **D.** Newly updated records will be appended to the target table.

---

## æ¨™ç±¤ç³»çµ±

### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Change-Data-Feed`, `Batch-Processing`, `Delta-Lake`

### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Execution-Behavior`, `Batch-vs-Streaming`

### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Development

---

## ç­”æ¡ˆèˆ‡ä¾†æº

### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `C`

### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** C
- **ç¤¾ç¾¤å…±è­˜:** C

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥

**æ ¸å¿ƒæŠ€è¡“:** Change Data Feed / Batch Read
**é—œéµæ¦‚å¿µ:** spark.read vs spark.readStream, Batch semantics, Append mode

**é¡Œç›®é—œéµå­—ï¼š**
- **spark.read**: æ‰¹æ¬¡è®€å–ï¼ˆéä¸²æµï¼‰ã€‚
- **startingVersion: 0**: å¾ç‰ˆæœ¬ 0 é–‹å§‹è®€å–ã€‚
- **mode("append")**: é™„åŠ æ¨¡å¼å¯«å…¥ã€‚
- **each time it is executed**: æ¯æ¬¡åŸ·è¡Œæ™‚ã€‚

---

## âœ… æ­£è§£èªªæ˜

### ç‚ºä»€éº¼ C æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**æŠ€è¡“åŸç†ï¼š**

1. **spark.read æ˜¯æ‰¹æ¬¡è®€å–**:
   - æ¯æ¬¡åŸ·è¡Œéƒ½æ˜¯**ç¨ç«‹çš„è®€å–**
   - æ²’æœ‰è¨˜éŒ„ã€Œä¸Šæ¬¡è®€åˆ°å“ªè£¡ã€
   - ç¸½æ˜¯å¾ startingVersion é–‹å§‹è®€å–**å…¨éƒ¨**

2. **åŸ·è¡Œæµç¨‹åˆ†æ**:
   ```
   ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼š
   è®€å– version 0 åˆ°æœ€æ–°çš„æ‰€æœ‰ update_postimage
   â†’ append åˆ° customers_updates

   ç¬¬äºŒæ¬¡åŸ·è¡Œï¼š
   å†æ¬¡è®€å– version 0 åˆ°æœ€æ–°çš„æ‰€æœ‰ update_postimage
   â†’ append åˆ° customers_updatesï¼ˆé‡è¤‡ï¼ï¼‰

   ç¬¬ä¸‰æ¬¡åŸ·è¡Œï¼š
   åŒä¸Š... ç¹¼çºŒé‡è¤‡
   ```

3. **çµæœ**:
   - æ¯æ¬¡åŸ·è¡Œéƒ½è®€å–å®Œæ•´æ­·å²
   - append æ¨¡å¼ä¸æœƒè¦†è“‹ï¼Œåªæœƒæ–°å¢
   - å°è‡´ç›®æ¨™è¡¨ä¸­æœ‰**å¤§é‡é‡è¤‡è³‡æ–™**

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### A - æ¯æ¬¡è¦†è“‹æ•´å€‹æ­·å²

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

- **ä½¿ç”¨çš„æ˜¯ append æ¨¡å¼**: ä¸æ˜¯ overwrite æ¨¡å¼ã€‚
- **append ä¸æœƒè¦†è“‹**: åªæœƒæ–°å¢è³‡æ–™ã€‚

### B - æ–°è¨˜éŒ„è¦†è“‹

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

- **ä¸æ˜¯ overwrite æ¨¡å¼**: ä½¿ç”¨ appendï¼Œä¸æœƒè¦†è“‹ã€‚
- **ä¸æ˜¯åªè®€æ–°è¨˜éŒ„**: spark.read æ¯æ¬¡éƒ½è®€å…¨éƒ¨ã€‚

### D - åªé™„åŠ æ–°è¨˜éŒ„

**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**

- **spark.read æ²’æœ‰å¢é‡èªæ„**: æ¯æ¬¡éƒ½å¾ version 0 é–‹å§‹ã€‚
- **æ²’æœ‰ checkpoint**: æ‰¹æ¬¡è®€å–ä¸è¿½è¹¤è®€å–é€²åº¦ã€‚
- **æ··æ·†èˆ‡ spark.readStream**: ä¸²æµæ‰æœ‰å¢é‡è™•ç†èƒ½åŠ›ã€‚

---

## ğŸ§  è¨˜æ†¶æ³•

### å£è¨£

**ã€Œbatch read æ²’è¨˜æ†¶ï¼Œæ¯æ¬¡é‡é ­è®€ä¸€éã€**

### spark.read vs spark.readStream æ¯”è¼ƒ

| ç‰¹æ€§ | spark.read | spark.readStream |
|------|------------|------------------|
| è™•ç†æ¨¡å¼ | æ‰¹æ¬¡ | ä¸²æµ |
| é€²åº¦è¿½è¹¤ | âŒ ç„¡ | âœ… Checkpoint |
| å¢é‡è™•ç† | âŒ | âœ… |
| æ¯æ¬¡åŸ·è¡Œ | è®€å…¨éƒ¨ | åªè®€æ–°è³‡æ–™ |
| é©ç”¨å ´æ™¯ | ä¸€æ¬¡æ€§è™•ç† | æŒçºŒè™•ç† |

### æ­£ç¢ºçš„å¢é‡è™•ç†æ–¹å¼

```python
# æ–¹æ³•ä¸€ï¼šä½¿ç”¨ä¸²æµ
spark.readStream
    .option("readChangeFeed", "true")
    .option("startingVersion", 0)
    .table("customers")
    .writeStream
    .option("checkpointLocation", "/checkpoint/path")
    .table("customers_updates")

# æ–¹æ³•äºŒï¼šæ‰‹å‹•è¿½è¹¤ç‰ˆæœ¬
last_version = get_last_processed_version()
spark.read
    .option("readChangeFeed", "true")
    .option("startingVersion", last_version + 1)
    .table("customers")
    ...
```

### CDF è®€å–æ¨¡å¼é¸æ“‡

| å ´æ™¯ | å»ºè­°æ–¹å¼ |
|------|----------|
| ä¸€æ¬¡æ€§åˆ†ææ­·å²è®Šæ›´ | spark.read |
| æŒçºŒå¢é‡è™•ç† | spark.readStream |
| æ‰‹å‹•æ§åˆ¶æ‰¹æ¬¡ | spark.read + ç‰ˆæœ¬è¿½è¹¤ |

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶

- [Read CDF in Batch Queries](https://docs.databricks.com/delta/delta-change-data-feed.html#read-changes-in-batch-queries)
- [Read CDF in Streaming Queries](https://docs.databricks.com/delta/delta-change-data-feed.html#read-changes-in-streaming-queries)

---

**[è¿”å›é¡Œç›®](#question-035)**
