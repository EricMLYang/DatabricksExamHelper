# Question #049

---

## é¡Œç›®è³‡è¨Š
### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-049`
### ä¾†æº
**ä¾†æº:** Community
### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L1-Basic`

---

## é¡Œç›®å…§å®¹
### é¡Œå¹¹
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
A data engineer has a PySpark DataFrame with the following columns: employee_name, department, and salary. They want to assign a tier to each employee within their department based on salary, where each employee has a unique tier number, even if they have the same salary. The expected output is as follows:

*(é¡Œç›®é™„æœ‰é æœŸè¼¸å‡ºè¡¨æ ¼ï¼Œé¡¯ç¤ºæ¯ä½å“¡å·¥æœ‰å”¯ä¸€çš„ tier ç·¨è™Ÿ)*

To achieve this, they define a window by department and order by salary in descending order:

```python
window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())
```

Which of the following functions correctly use this window to calculate the tier column?

### é¸é …
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
- **A.** `df.withColumn("tier", rank().over(window_spec))`
- **B.** `df.withColumn("tier", row_number().over(window_spec))`
- **C.** `df.withColumn("tier", dense_rank().over(window_spec))`
- **D.** `df.withColumn("tier", percent_rank().over(window_spec))`

---

## æ¨™ç±¤ç³»çµ±
### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Spark-Core`, `Databricks-SQL`
### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** (ç„¡)
### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Data Transformation

---

## ç­”æ¡ˆèˆ‡ä¾†æº
### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `B`
### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** B
- **ç¤¾ç¾¤å…±è­˜:** B

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥
**æ ¸å¿ƒæŠ€è¡“:** Window Functionsï¼ˆè¦–çª—å‡½æ•¸ï¼‰
**é—œéµæ¦‚å¿µ:** row_number vs rank vs dense_rank
**é¡Œç›®é—œéµå­—ï¼š**
- **unique tier number**: å”¯ä¸€çš„å±¤ç´šç·¨è™Ÿ
- **even if they have the same salary**: å³ä½¿è–ªè³‡ç›¸åŒ
- **row_number**: å”¯ä¸€åºè™Ÿå‡½æ•¸

---

## âœ… æ­£è§£èªªæ˜
### ç‚ºä»€éº¼ B æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

**`row_number()`** æœƒç‚ºæ¯ä¸€è¡Œåˆ†é…**å”¯ä¸€çš„åºè™Ÿ**ï¼Œå³ä½¿å€¼ç›¸åŒä¹Ÿä¸æœƒé‡è¤‡ã€‚

#### row_number() çš„ç‰¹æ€§
| ç‰¹æ€§ | èªªæ˜ |
|------|------|
| **å”¯ä¸€æ€§** | æ¯è¡Œéƒ½æœ‰å”¯ä¸€çš„ç·¨è™Ÿ |
| **é€£çºŒæ€§** | ç·¨è™Ÿé€£çºŒï¼Œç„¡é–“éš” |
| **è™•ç†ç›¸åŒå€¼** | ç›¸åŒå€¼ä¹Ÿæœƒæœ‰ä¸åŒç·¨è™Ÿ |

#### ç¯„ä¾‹èªªæ˜
```python
from pyspark.sql.window import Window
from pyspark.sql.functions import row_number

window_spec = Window.partitionBy("department").orderBy(df["salary"].desc())
df.withColumn("tier", row_number().over(window_spec))

# çµæœï¼ˆå³ä½¿è–ªè³‡ç›¸åŒï¼Œtier ä¹Ÿä¸åŒï¼‰ï¼š
# department | employee | salary | tier
# -----------------------------------------
# Sales      | Alice    | 100000 | 1
# Sales      | Bob      | 100000 | 2  â† è–ªè³‡ç›¸åŒä½† tier ä¸åŒ
# Sales      | Carol    | 90000  | 3
# HR         | Dave     | 80000  | 1
# HR         | Eve      | 70000  | 2
```

#### ç‚ºä»€éº¼éœ€è¦ row_number()ï¼Ÿ
```
é¡Œç›®éœ€æ±‚ï¼šã€Œeach employee has a unique tier numberã€
             â†“
éœ€è¦å”¯ä¸€ç·¨è™Ÿ â†’ row_number() æ˜¯å”¯ä¸€é¸æ“‡
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### A. rank()
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- `rank()` å°ç›¸åŒå€¼çµ¦äºˆ**ç›¸åŒæ’å**
- ä¹‹å¾Œæœƒ**è·³é**ç·¨è™Ÿï¼Œç”¢ç”Ÿé–“éš”
- ä¸ç¬¦åˆã€Œå”¯ä¸€ç·¨è™Ÿã€éœ€æ±‚

```python
# rank() è¡Œç‚ºç¤ºä¾‹ï¼š
# salary | rank
# 100000 | 1
# 100000 | 1  â† ç›¸åŒï¼
# 90000  | 3  â† è·³é 2
```

### C. dense_rank()
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- `dense_rank()` å°ç›¸åŒå€¼çµ¦äºˆ**ç›¸åŒæ’å**
- é›–ç„¶ä¸æœƒè·³è™Ÿï¼Œä½†ä»æœƒé‡è¤‡
- ä¸ç¬¦åˆã€Œå”¯ä¸€ç·¨è™Ÿã€éœ€æ±‚

```python
# dense_rank() è¡Œç‚ºç¤ºä¾‹ï¼š
# salary | dense_rank
# 100000 | 1
# 100000 | 1  â† ç›¸åŒï¼
# 90000  | 2  â† é€£çºŒï¼Œä¸è·³è™Ÿ
```

### D. percent_rank()
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- `percent_rank()` ç”¢ç”Ÿ**0 åˆ° 1 ä¹‹é–“çš„ç™¾åˆ†æ¯”**
- ä¸æ˜¯æ•´æ•¸ï¼Œä¸é©åˆä½œç‚ºã€Œtierã€
- è¨ˆç®—å…¬å¼ï¼š(rank - 1) / (total rows - 1)

```python
# percent_rank() è¡Œç‚ºç¤ºä¾‹ï¼š
# salary | percent_rank
# 100000 | 0.0
# 100000 | 0.0
# 90000  | 0.5
```

---

## ğŸ§  è¨˜æ†¶æ³•
### å£è¨£
**ã€Œrow_number ç¨ä¸€ç„¡äºŒï¼Œrank ç›¸åŒæœƒè·³ï¼Œdense_rank ç›¸åŒä¸è·³ã€**

### æ’åå‡½æ•¸æ¯”è¼ƒè¡¨
| å‡½æ•¸ | ç›¸åŒå€¼è™•ç† | è·³è™Ÿ | è¼¸å‡ºç¯„ä¾‹ |
|------|-----------|------|---------|
| **row_number()** | ä¸åŒç·¨è™Ÿ | N/A | 1, 2, 3, 4 |
| **rank()** | ç›¸åŒç·¨è™Ÿ | æœ‰ | 1, 1, 3, 4 |
| **dense_rank()** | ç›¸åŒç·¨è™Ÿ | ç„¡ | 1, 1, 2, 3 |
| **percent_rank()** | ç™¾åˆ†æ¯” | N/A | 0.0, 0.0, 0.5, 1.0 |

### è¦–è¦ºåŒ–æ¯”è¼ƒ
```
è³‡æ–™ï¼š[100, 100, 90, 80]

row_number(): 1, 2, 3, 4  â† å”¯ä¸€ç·¨è™Ÿ
rank():       1, 1, 3, 4  â† ç›¸åŒå€¼åŒç·¨è™Ÿï¼Œè·³è™Ÿ
dense_rank(): 1, 1, 2, 3  â† ç›¸åŒå€¼åŒç·¨è™Ÿï¼Œä¸è·³è™Ÿ
```

### é¸æ“‡æ±ºç­–æ¨¹
```
éœ€è¦ä»€éº¼é¡å‹çš„æ’åï¼Ÿ
â”‚
â”œâ”€â”€ å”¯ä¸€ç·¨è™Ÿï¼ˆå³ä½¿ç›¸åŒå€¼ï¼‰
â”‚   â””â”€â”€ row_number() â† æœ¬é¡Œç­”æ¡ˆ
â”‚
â”œâ”€â”€ ç›¸åŒå€¼ç›¸åŒæ’å
â”‚   â”œâ”€â”€ éœ€è¦è·³è™Ÿ â†’ rank()
â”‚   â””â”€â”€ ä¸éœ€è·³è™Ÿ â†’ dense_rank()
â”‚
â””â”€â”€ ç™¾åˆ†æ¯”æ’å
    â””â”€â”€ percent_rank()
```

### è¨˜æ†¶æŠ€å·§
- **row_number** = ã€Œè¡Œè™Ÿã€= æ¯è¡Œä¸€å€‹è™Ÿç¢¼
- **rank** = ã€Œæ’åã€= ä¸¦åˆ—ç¬¬ä¸€å
- **dense** = ã€Œå¯†é›†ã€= ä¸è·³è™Ÿ
- **percent** = ã€Œç™¾åˆ†æ¯”ã€= 0~1 ä¹‹é–“

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶
- [Window functions](https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#window-functions)
- [PySpark Window functions](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html#window-functions)

---

**[è¿”å›é¡Œç›®](#question-049)**
