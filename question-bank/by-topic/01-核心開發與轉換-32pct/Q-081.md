# Q-081

## é¡Œç›®è³‡è¨Š

**ID:** `Q-081`  
**ä¾†æº:** Official Practice Exam  
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹

### é¡Œå¹¹

A CHECK constraint has been successfully added to the Delta table named `activity_details` using the following logic:

```sql
ALTER TABLE activity_details
ADD CONSTRAINT valid_coordinates
CHECK (
  latitude >= -90 AND
  latitude <= 90 AND
  longitude >= -180 AND
  longitude <= 180);
```

A batch job is attempting to insert new records to the table, including a record where `latitude = 45.50` and `longitude = 212.67`.

Which statement describes the outcome of this batch insert?

### é¸é …

**A.** The write will fail when the violating record is reached; any records previously processed will be recorded to the target table.

**B.** The write will fail completely because of the constraint violation and no records will be inserted into the target table.

**C.** The write will insert all records except those that violate the table constraints; the violating records will be recorded to a quarantine table.

**D.** The write will include all records in the target table; any violations will be indicated in the boolean column named `valid_coordinates`.

**E.** The write will insert all records except those that violate the table constraints; the violating records will be reported in a warning log.

---

## æ¨™ç±¤ (Tags)

### Topic Tags
- `Delta-Constraints`
- `Delta-Lake`
- `Data-Quality`

### Trap Tags
- `Concept-Confusion`

### Level Tag
- `L2-Intermediate`

---

---

# é¡Œç›®è§£æž

## é¡Œç›®å›žé¡§

**é¡Œç›® ID:** `Q-081`  
**é¡Œç›®é€£çµ:** [é»žæ­¤è¿”å›žé¡Œç›®](#q-081)  
**æ­£è§£:** `B`

---

## ðŸ“ è€ƒé»žè­˜åˆ¥

### ä¸»è¦è€ƒé»ž
**æ ¸å¿ƒæŠ€è¡“:** Delta Lake CHECK Constraints  
**çŸ¥è­˜é ˜åŸŸ:** è³‡æ–™å“è³ªèˆ‡ç´„æŸæ¢ä»¶ / Delta Lake æ ¸å¿ƒåŠŸèƒ½  
**é—œéµæ¦‚å¿µ:**
- CHECK ç´„æŸçš„åŽŸå­æ€§ï¼ˆAtomicityï¼‰
- ç´„æŸé•åæ™‚çš„äº‹å‹™è¡Œç‚º
- Delta Lake çš„ ACID ç‰¹æ€§

### æ¬¡è¦è€ƒé»ž
- è³‡æ–™é©—è­‰æ©Ÿåˆ¶
- æ‰¹æ¬¡å¯«å…¥çš„å¤±æ•—è™•ç†
- åæ¨™ç¯„åœé©—è­‰ï¼ˆåœ°ç†è³‡æ–™ï¼‰

---

## âœ… æ­£è§£èªªæ˜Ž

### ç‚ºä»€éº¼ B æ˜¯æ­£ç¢ºçš„ï¼Ÿ

**æŠ€è¡“åŽŸç†:**

Delta Lake çš„ CHECK ç´„æŸæ˜¯**äº‹å‹™å±¤ç´šçš„ç´„æŸæ¢ä»¶**ï¼Œéµå¾ª ACID åŽŸå‰‡ä¸­çš„åŽŸå­æ€§ï¼ˆAtomicityï¼‰ã€‚ç•¶æ‰¹æ¬¡å¯«å…¥ä¸­ä»»ä½•ä¸€ç­†è¨˜éŒ„é•åç´„æŸæ¢ä»¶æ™‚ï¼Œæ•´å€‹äº‹å‹™æœƒè¢«å›žæ»¾ï¼ˆRollbackï¼‰ï¼Œ**æ²’æœ‰ä»»ä½•è¨˜éŒ„æœƒè¢«æ’å…¥åˆ°ç›®æ¨™è¡¨**ã€‚

**ç¬¦åˆéœ€æ±‚:**

1. **åŽŸå­æ€§ä¿è­‰**ï¼šDelta Lake ç¢ºä¿å¯«å…¥æ“ä½œçš„åŽŸå­æ€§ï¼Œè¦éº¼å…¨éƒ¨æˆåŠŸï¼Œè¦éº¼å…¨éƒ¨å¤±æ•—ï¼Œä¸å­˜åœ¨éƒ¨åˆ†æˆåŠŸçš„æƒ…æ³ã€‚

2. **ç´„æŸé•ååµæ¸¬**ï¼šåœ¨é¡Œç›®ä¸­ï¼Œ`longitude = 212.67` è¶…å‡ºäº†æœ‰æ•ˆç¯„åœï¼ˆ-180 åˆ° 180ï¼‰ï¼Œé•åäº† `valid_coordinates` ç´„æŸæ¢ä»¶ã€‚

3. **äº‹å‹™å›žæ»¾**ï¼šä¸€æ—¦åµæ¸¬åˆ°ç´„æŸé•åï¼Œæ•´å€‹æ‰¹æ¬¡å¯«å…¥æ“ä½œæœƒç«‹å³å¤±æ•—ï¼Œå·²è™•ç†çš„è¨˜éŒ„ä¹Ÿä¸æœƒè¢«æäº¤ã€‚

4. **è³‡æ–™å®Œæ•´æ€§**ï¼šé€™ç¨®è¡Œç‚ºç¢ºä¿è¡¨ä¸­çš„æ‰€æœ‰è³‡æ–™éƒ½ç¬¦åˆå®šç¾©çš„ç´„æŸæ¢ä»¶ï¼Œç¶­è­·è³‡æ–™å®Œæ•´æ€§ã€‚

**å¯¦å‹™æ‡‰ç”¨:**

```python
# ç¯„ä¾‹ï¼šé•åç´„æŸçš„æ‰¹æ¬¡å¯«å…¥
from pyspark.sql import Row

# å»ºç«‹åŒ…å«é•åç´„æŸè¨˜éŒ„çš„è³‡æ–™é›†
data = [
    Row(id=1, latitude=45.50, longitude=120.30),   # æœ‰æ•ˆè¨˜éŒ„
    Row(id=2, latitude=30.25, longitude=-75.50),   # æœ‰æ•ˆè¨˜éŒ„
    Row(id=3, latitude=45.50, longitude=212.67),   # é•åç´„æŸï¼šlongitude > 180
    Row(id=4, latitude=60.00, longitude=100.00)    # æœ‰æ•ˆè¨˜éŒ„
]

df = spark.createDataFrame(data)

# å˜—è©¦å¯«å…¥ - æ•´å€‹æ“ä½œæœƒå¤±æ•—
try:
    df.write.mode("append").saveAsTable("activity_details")
except Exception as e:
    print(f"å¯«å…¥å¤±æ•—: {e}")
    # è¼¸å‡ºé¡žä¼¼ï¼šCHECK constraint valid_coordinates violated by row with values: [45.50, 212.67]
    
# æª¢æŸ¥è¡¨ä¸­çš„è¨˜éŒ„æ•¸ - æ²’æœ‰æ–°è¨˜éŒ„è¢«æ’å…¥
spark.table("activity_details").count()  # èˆ‡å¯«å…¥å‰ç›¸åŒ
```

**ç´„æŸé©—è­‰æ™‚æ©Ÿï¼š**

```sql
-- æŸ¥çœ‹è¡¨çš„ç´„æŸæ¢ä»¶
DESCRIBE DETAIL activity_details;

-- æŸ¥çœ‹ç´„æŸå®šç¾©
SHOW TBLPROPERTIES activity_details;

-- ç´„æŸåœ¨ä»¥ä¸‹æ™‚æ©Ÿé©—è­‰ï¼š
-- 1. INSERT æ“ä½œ
-- 2. UPDATE æ“ä½œ
-- 3. MERGE æ“ä½œ
-- 4. DataFrame å¯«å…¥æ“ä½œ

-- é©—è­‰å¤±æ•—æœƒæ‹‹å‡ºç•°å¸¸
-- Delta Lake ä¸æœƒè‡ªå‹•éŽæ¿¾æˆ–éš”é›¢é•åç´„æŸçš„è¨˜éŒ„
```

---

## âŒ éŒ¯èª¤é¸é …æŽ’é™¤

### é¸é … Aï¼šéƒ¨åˆ†è¨˜éŒ„æˆåŠŸå¯«å…¥

**ç‚ºä»€éº¼éŒ¯èª¤ï¼š**

1. **é•ååŽŸå­æ€§åŽŸå‰‡**ï¼šDelta Lake ä¿è­‰äº‹å‹™çš„åŽŸå­æ€§ï¼Œä¸æœƒå‡ºç¾ã€Œéƒ¨åˆ†æˆåŠŸã€çš„æƒ…æ³ã€‚

2. **èª¤è§£ç´„æŸåŸ·è¡Œæ©Ÿåˆ¶**ï¼šç´„æŸä¸æ˜¯é€ç­†è¨˜éŒ„é©—è­‰ä¸¦æ±ºå®šæ˜¯å¦å¯«å…¥ï¼Œè€Œæ˜¯åœ¨æ•´å€‹æ‰¹æ¬¡æ“ä½œä¸­é©—è­‰æ‰€æœ‰è¨˜éŒ„ã€‚

3. **è³‡æ–™ä¸ä¸€è‡´é¢¨éšª**ï¼šå¦‚æžœå…è¨±éƒ¨åˆ†è¨˜éŒ„å¯«å…¥ï¼Œæœƒå°Žè‡´è³‡æ–™ä¸ä¸€è‡´ï¼Œé•å ACID åŽŸå‰‡ã€‚

**é™·é˜±è¨­è¨ˆï¼š**  
é€™å€‹é¸é …èª¤å°Žè€ƒç”Ÿä»¥ç‚ºç´„æŸæ˜¯ã€Œé€ç­†è™•ç†ã€çš„æ©Ÿåˆ¶ï¼Œé¡žä¼¼ä¸²æµè™•ç†ä¸­çš„éŒ¯èª¤è™•ç†æ¨¡å¼ã€‚

```python
# éŒ¯èª¤ç†è§£ç¤ºä¾‹ï¼ˆDelta Lake ä¸æœƒé€™æ¨£é‹ä½œï¼‰
# for record in batch:
#     if validate(record):
#         insert(record)  # âŒ Delta Lake ä¸æœƒéƒ¨åˆ†æ’å…¥
#     else:
#         break
```

---

### é¸é … Cï¼šé•åè¨˜éŒ„å¯«å…¥éš”é›¢è¡¨

**ç‚ºä»€éº¼éŒ¯èª¤ï¼š**

1. **æ²’æœ‰è‡ªå‹•éš”é›¢æ©Ÿåˆ¶**ï¼šDelta Lake çš„ CHECK ç´„æŸä¸æœƒè‡ªå‹•å»ºç«‹éš”é›¢è¡¨ï¼ˆQuarantine Tableï¼‰ä¾†å­˜æ”¾é•åç´„æŸçš„è¨˜éŒ„ã€‚

2. **æ··æ·†è³‡æ–™å“è³ªå·¥å…·**ï¼šéš”é›¢è¡¨æ˜¯æŸäº›è³‡æ–™å“è³ªæ¡†æž¶ï¼ˆå¦‚ Great Expectationsã€Deequï¼‰çš„åŠŸèƒ½ï¼Œä¸æ˜¯ CHECK ç´„æŸçš„å…§å»ºè¡Œç‚ºã€‚

3. **éœ€è¦é¡å¤–å¯¦ä½œ**ï¼šå¦‚æžœéœ€è¦éš”é›¢é•åç´„æŸçš„è¨˜éŒ„ï¼Œå¿…é ˆåœ¨æ‡‰ç”¨å±¤å¯¦ä½œé¡å¤–çš„éŒ¯èª¤è™•ç†é‚è¼¯ã€‚

**é™·é˜±è¨­è¨ˆï¼š**  
é€™å€‹é¸é …æ··æ·†äº† CHECK ç´„æŸèˆ‡è³‡æ–™å“è³ªæ¡†æž¶çš„åŠŸèƒ½ï¼Œèª¤å°Žè€ƒç”Ÿä»¥ç‚º Delta Lake æœ‰è‡ªå‹•éš”é›¢æ©Ÿåˆ¶ã€‚

```python
# å¦‚æžœéœ€è¦éš”é›¢é•åç´„æŸçš„è¨˜éŒ„ï¼Œéœ€è¦æ‰‹å‹•å¯¦ä½œ
from pyspark.sql.functions import col

# åœ¨å¯«å…¥å‰æ‰‹å‹•é©—è­‰
valid_df = df.filter(
    (col("latitude") >= -90) & (col("latitude") <= 90) &
    (col("longitude") >= -180) & (col("longitude") <= 180)
)

invalid_df = df.filter(
    ~((col("latitude") >= -90) & (col("latitude") <= 90) &
      (col("longitude") >= -180) & (col("longitude") <= 180))
)

# åˆ†åˆ¥å¯«å…¥
valid_df.write.mode("append").saveAsTable("activity_details")
invalid_df.write.mode("append").saveAsTable("activity_details_quarantine")
```

---

### é¸é … Dï¼šå»ºç«‹å¸ƒæž—æ¬„ä½æ¨™è¨˜é•åè¨˜éŒ„

**ç‚ºä»€éº¼éŒ¯èª¤ï¼š**

1. **ç´„æŸä¸æœƒå»ºç«‹é¡å¤–æ¬„ä½**ï¼šCHECK ç´„æŸä¸æœƒè‡ªå‹•å»ºç«‹åç‚º `valid_coordinates` çš„å¸ƒæž—æ¬„ä½ä¾†æ¨™è¨˜é•åè¨˜éŒ„ã€‚

2. **ç´„æŸåç¨± â‰  æ¬„ä½åç¨±**ï¼š`valid_coordinates` æ˜¯ç´„æŸçš„**åç¨±**ï¼Œä¸æ˜¯è¡¨ä¸­çš„æ¬„ä½ã€‚

3. **é•åç´„æŸå³æ‹’çµ•**ï¼šCHECK ç´„æŸçš„è¨­è¨ˆæ˜¯ã€Œæ‹’çµ•é•åçš„è¨˜éŒ„ã€ï¼Œè€Œä¸æ˜¯ã€Œæ¨™è¨˜ä¸¦æŽ¥å—ã€ã€‚

**é™·é˜±è¨­è¨ˆï¼š**  
é€™å€‹é¸é …æ··æ·†äº†ç´„æŸåç¨±èˆ‡æ¬„ä½åç¨±ï¼Œèª¤å°Žè€ƒç”Ÿä»¥ç‚ºç´„æŸæœƒå»ºç«‹å°æ‡‰çš„å¸ƒæž—æ¬„ä½ã€‚

```sql
-- ç´„æŸåç¨±ä¸æ˜¯æ¬„ä½
-- valid_coordinates æ˜¯ç´„æŸçš„è­˜åˆ¥ç¬¦ï¼Œä¸æ˜¯è¡¨çš„æ¬„ä½

-- æŸ¥çœ‹è¡¨çµæ§‹ - ä¸æœƒæœ‰ valid_coordinates æ¬„ä½
DESCRIBE activity_details;
-- è¼¸å‡ºï¼š
-- | id         | bigint  |
-- | latitude   | double  |
-- | longitude  | double  |
-- (æ²’æœ‰ valid_coordinates æ¬„ä½)

-- æŸ¥çœ‹ç´„æŸå®šç¾©
SHOW TBLPROPERTIES activity_details('delta.constraints.valid_coordinates');
-- è¼¸å‡ºï¼šlatitude >= -90 AND latitude <= 90 AND longitude >= -180 AND longitude <= 180
```

---

### é¸é … Eï¼šé•åè¨˜éŒ„è¨˜éŒ„åœ¨è­¦å‘Šæ—¥èªŒ

**ç‚ºä»€éº¼éŒ¯èª¤ï¼š**

1. **ç´„æŸé•åæ˜¯éŒ¯èª¤ï¼Œä¸æ˜¯è­¦å‘Š**ï¼šCHECK ç´„æŸé•åæœƒæ‹‹å‡ºç•°å¸¸ï¼ˆExceptionï¼‰ï¼Œè€Œä¸æ˜¯è¨˜éŒ„è­¦å‘Šï¼ˆWarningï¼‰ã€‚

2. **å¯«å…¥æ“ä½œæœƒå¤±æ•—**ï¼šé•åç´„æŸæ™‚ï¼Œå¯«å…¥æ“ä½œæœƒå®Œå…¨å¤±æ•—ï¼Œä¸æœƒç¹¼çºŒè™•ç†å…¶ä»–è¨˜éŒ„ã€‚

3. **æ²’æœ‰è‡ªå‹•æ—¥èªŒè¨˜éŒ„**ï¼šDelta Lake ä¸æœƒè‡ªå‹•å°‡é•åç´„æŸçš„è¨˜éŒ„è¨˜éŒ„åˆ°ç‰¹æ®Šçš„æ—¥èªŒæª”æ¡ˆã€‚

**é™·é˜±è¨­è¨ˆï¼š**  
é€™å€‹é¸é …èª¤å°Žè€ƒç”Ÿä»¥ç‚ºç´„æŸé•åæ˜¯ã€Œè»Ÿæ€§é©—è­‰ã€ï¼ˆSoft Validationï¼‰ï¼Œé¡žä¼¼è­¦å‘Šæç¤ºï¼Œè€Œä¸æ˜¯ã€Œç¡¬æ€§ç´„æŸã€ï¼ˆHard Constraintï¼‰ã€‚

```python
# ç´„æŸé•åæœƒæ‹‹å‡ºç•°å¸¸ï¼Œä¸æ˜¯è­¦å‘Š
try:
    df.write.mode("append").saveAsTable("activity_details")
except Exception as e:
    # é€™æ˜¯ä¸€å€‹ç•°å¸¸ï¼ˆExceptionï¼‰ï¼Œä¸æ˜¯è­¦å‘Šï¼ˆWarningï¼‰
    print(f"ç•°å¸¸: {type(e).__name__}")
    print(f"è¨Šæ¯: {str(e)}")
    # è¼¸å‡ºé¡žä¼¼ï¼š
    # ç•°å¸¸: AnalysisException
    # è¨Šæ¯: CHECK constraint valid_coordinates (latitude >= -90 AND ...) violated
```

---

## ðŸ§  è¨˜æ†¶æ³•

### å£è¨£

**ã€Œç´„æŸé•åå…¨å¤±æ•—ï¼ŒåŽŸå­ä¿è­‰ä¸éƒ¨åˆ†ã€**

- **ç´„æŸé•å** - CHECK ç´„æŸè¢«é•å
- **å…¨å¤±æ•—** - æ•´å€‹æ‰¹æ¬¡å¯«å…¥å®Œå…¨å¤±æ•—
- **åŽŸå­ä¿è­‰** - ACID åŽŸå­æ€§ä¿è­‰
- **ä¸éƒ¨åˆ†** - ä¸æœƒéƒ¨åˆ†æ’å…¥æˆåŠŸçš„è¨˜éŒ„

### å°æ¯”è¡¨ï¼šç´„æŸé•åè™•ç†æ©Ÿåˆ¶

| æ©Ÿåˆ¶ | éƒ¨åˆ†æˆåŠŸ | éš”é›¢è¡¨ | å¸ƒæž—æ¨™è¨˜ | è­¦å‘Šæ—¥èªŒ | å¯¦éš›è¡Œç‚º |
|-----|---------|--------|---------|---------|---------|
| **CHECK ç´„æŸ** | âŒ | âŒ | âŒ | âŒ | âœ… å…¨éƒ¨å¤±æ•— |
| **æ‡‰ç”¨å±¤é©—è­‰** | âœ… å¯å¯¦ä½œ | âœ… å¯å¯¦ä½œ | âœ… å¯å¯¦ä½œ | âœ… å¯å¯¦ä½œ | éœ€æ‰‹å‹•å¯¦ä½œ |
| **ä¸²æµéŒ¯èª¤è™•ç†** | âœ… å¯é…ç½® | âœ… å¯é…ç½® | âŒ | âœ… å¯é…ç½® | ä¾é…ç½®è€Œå®š |

### æ±ºç­–æ¨¹ï¼šç´„æŸé•åå¾Œçš„è¡Œç‚º

```
å¯«å…¥æ“ä½œé•å CHECK ç´„æŸï¼Ÿ
â”‚
â”œâ”€ æ˜¯ â†’ æ•´å€‹äº‹å‹™å›žæ»¾
â”‚      â””â”€ æ²’æœ‰ä»»ä½•è¨˜éŒ„è¢«æ’å…¥ âœ…
â”‚
â””â”€ å¦ â†’ å¯«å…¥æˆåŠŸ
       â””â”€ æ‰€æœ‰è¨˜éŒ„éƒ½ç¬¦åˆç´„æŸ
```

### è¨˜æ†¶è¦é»ž

1. **All or Nothing**ï¼šCHECK ç´„æŸéµå¾ªã€Œå…¨æœ‰æˆ–å…¨ç„¡ã€åŽŸå‰‡
2. **äº‹å‹™å±¤ç´š**ï¼šç´„æŸåœ¨äº‹å‹™å±¤ç´šé©—è­‰ï¼Œä¸æ˜¯è¨˜éŒ„å±¤ç´š
3. **ç„¡è‡ªå‹•éš”é›¢**ï¼šä¸æœƒè‡ªå‹•å»ºç«‹éš”é›¢è¡¨æˆ–æ¬„ä½
4. **æ‹‹å‡ºç•°å¸¸**ï¼šé•åç´„æŸæœƒæ‹‹å‡ºç•°å¸¸ï¼Œä¸æ˜¯è­¦å‘Š

---

## ðŸ“š å®˜æ–¹æ–‡ä»¶

### ä¸»è¦åƒè€ƒ
1. **Delta Lake Constraints æ–‡ä»¶**  
   [Constraints on Delta Lake](https://docs.databricks.com/delta/delta-constraints.html)

2. **CHECK Constraint èªžæ³•**  
   [ALTER TABLE ADD CONSTRAINT](https://docs.databricks.com/sql/language-manual/sql-ref-syntax-ddl-alter-table.html#add-constraint)

### å»¶ä¼¸é–±è®€
3. **Delta Lake ACID ä¿è­‰**  
   [ACID Guarantees](https://docs.databricks.com/delta/concurrency-control.html)

4. **è³‡æ–™å“è³ªé©—è­‰æœ€ä½³å¯¦è¸**  
   [Data Quality Best Practices](https://docs.databricks.com/lakehouse/data-quality.html)

---

## ðŸŽ“ å­¸ç¿’å»ºè­°

1. **ç†è§£ ACID åŽŸå‰‡**ï¼šç‰¹åˆ¥æ˜¯åŽŸå­æ€§ï¼ˆAtomicityï¼‰åœ¨ç´„æŸé©—è­‰ä¸­çš„æ‡‰ç”¨ã€‚

2. **å¯¦é©—ç´„æŸé•å**ï¼šåœ¨æ¸¬è©¦ç’°å¢ƒä¸­å»ºç«‹è¡¨ä¸¦æ•…æ„é•åç´„æŸï¼Œè§€å¯ŸéŒ¯èª¤è¨Šæ¯èˆ‡è¡Œç‚ºã€‚

3. **å€åˆ†ç´„æŸé¡žåž‹**ï¼š
   - CHECK ç´„æŸï¼šé©—è­‰æ¬„ä½å€¼çš„æ¢ä»¶
   - NOT NULL ç´„æŸï¼šç¢ºä¿æ¬„ä½ä¸ç‚ºç©º
   - PRIMARY KEY/FOREIGN KEYï¼šï¼ˆDelta Lake ç›®å‰ä¸æ”¯æ´ï¼‰

4. **æ‡‰ç”¨å±¤é©—è­‰è¨­è¨ˆ**ï¼šäº†è§£ä½•æ™‚éœ€è¦åœ¨æ‡‰ç”¨å±¤å¯¦ä½œé¡å¤–çš„è³‡æ–™é©—è­‰èˆ‡éš”é›¢é‚è¼¯ã€‚

5. **éŒ¯èª¤è™•ç†ç­–ç•¥**ï¼šè¨­è¨ˆé©ç•¶çš„éŒ¯èª¤è™•ç†èˆ‡é‡è©¦æ©Ÿåˆ¶ï¼Œè™•ç†ç´„æŸé•åçš„æƒ…æ³ã€‚

---

## ðŸ’¡ å¯¦å‹™æç¤º

### ä½•æ™‚ä½¿ç”¨ CHECK ç´„æŸï¼Ÿ
- âœ… éœ€è¦å¼·åˆ¶åŸ·è¡Œè³‡æ–™å®Œæ•´æ€§è¦å‰‡
- âœ… é©—è­‰æ•¸å€¼ç¯„åœï¼ˆå¦‚åæ¨™ã€å¹´é½¡ã€é‡‘é¡ï¼‰
- âœ… ç¢ºä¿é—œéµæ¬„ä½ç¬¦åˆæ¥­å‹™è¦å‰‡
- âœ… é˜²æ­¢ç„¡æ•ˆè³‡æ–™å¯«å…¥è¡¨

### ä½•æ™‚ä¸ä½¿ç”¨ CHECK ç´„æŸï¼Ÿ
- âŒ éœ€è¦å½ˆæ€§è™•ç†ç„¡æ•ˆè³‡æ–™ï¼ˆè€ƒæ…®æ‡‰ç”¨å±¤é©—è­‰ï¼‰
- âŒ é©—è­‰è¦å‰‡ç¶“å¸¸è®Šæ›´ï¼ˆç´„æŸä¿®æ”¹éœ€è¦ ALTER TABLEï¼‰
- âŒ éœ€è¦è¨˜éŒ„ç„¡æ•ˆè³‡æ–™ä»¥ä¾›åˆ†æžï¼ˆä½¿ç”¨éš”é›¢è¡¨æ¨¡å¼ï¼‰
- âŒ æ•ˆèƒ½æ•æ„Ÿçš„é«˜é »å¯«å…¥ï¼ˆç´„æŸé©—è­‰æœƒå¢žåŠ å»¶é²ï¼‰

### éŒ¯èª¤è™•ç†æœ€ä½³å¯¦è¸

```python
from pyspark.sql.functions import col
from pyspark.sql import DataFrame

def write_with_constraint_handling(df: DataFrame, table_name: str):
    """
    å¯«å…¥è³‡æ–™ä¸¦è™•ç†ç´„æŸé•å
    """
    try:
        # æ–¹æ³• 1ï¼šç›´æŽ¥å¯«å…¥ï¼Œå¤±æ•—å‰‡æ‹‹å‡ºç•°å¸¸
        df.write.mode("append").saveAsTable(table_name)
        print(f"æˆåŠŸå¯«å…¥ {df.count()} ç­†è¨˜éŒ„")
        
    except Exception as e:
        if "constraint" in str(e).lower():
            print(f"ç´„æŸé•å: {e}")
            
            # æ–¹æ³• 2ï¼šåœ¨æ‡‰ç”¨å±¤é å…ˆé©—è­‰ä¸¦éš”é›¢ç„¡æ•ˆè¨˜éŒ„
            valid_df = df.filter(
                (col("latitude") >= -90) & (col("latitude") <= 90) &
                (col("longitude") >= -180) & (col("longitude") <= 180)
            )
            
            invalid_df = df.filter(
                ~((col("latitude") >= -90) & (col("latitude") <= 90) &
                  (col("longitude") >= -180) & (col("longitude") <= 180))
            )
            
            # å¯«å…¥æœ‰æ•ˆè¨˜éŒ„
            if valid_df.count() > 0:
                valid_df.write.mode("append").saveAsTable(table_name)
                print(f"æˆåŠŸå¯«å…¥ {valid_df.count()} ç­†æœ‰æ•ˆè¨˜éŒ„")
            
            # è¨˜éŒ„ç„¡æ•ˆè¨˜éŒ„
            if invalid_df.count() > 0:
                invalid_df.write.mode("append").saveAsTable(f"{table_name}_invalid")
                print(f"éš”é›¢ {invalid_df.count()} ç­†ç„¡æ•ˆè¨˜éŒ„")
        else:
            raise

# ä½¿ç”¨ç¯„ä¾‹
write_with_constraint_handling(df, "activity_details")
```

### ç´„æŸç®¡ç†

```sql
-- æ–°å¢žç´„æŸ
ALTER TABLE activity_details
ADD CONSTRAINT valid_coordinates
CHECK (latitude >= -90 AND latitude <= 90 AND longitude >= -180 AND longitude <= 180);

-- æŸ¥çœ‹ç´„æŸ
SHOW TBLPROPERTIES activity_details;

-- åˆªé™¤ç´„æŸï¼ˆå¦‚æžœéœ€è¦ä¿®æ”¹é©—è­‰è¦å‰‡ï¼‰
ALTER TABLE activity_details
DROP CONSTRAINT valid_coordinates;

-- åˆªé™¤ç´„æŸå¾Œé‡æ–°æ–°å¢žï¼ˆä¿®æ”¹é©—è­‰è¦å‰‡ï¼‰
ALTER TABLE activity_details
ADD CONSTRAINT valid_coordinates
CHECK (
  latitude BETWEEN -90 AND 90 AND
  longitude BETWEEN -180 AND 180 AND
  latitude IS NOT NULL AND
  longitude IS NOT NULL
);
```

---

## ðŸ”— ç›¸é—œé¡Œç›®

- Q-XXX: Delta Lake NOT NULL ç´„æŸ
- Q-XXX: Delta Lake Schema Evolution
- Q-XXX: è³‡æ–™å“è³ªé©—è­‰ç­–ç•¥
- Q-XXX: ACID äº‹å‹™è™•ç†

---

**æœ€å¾Œæ›´æ–°:** 2026-01-15
