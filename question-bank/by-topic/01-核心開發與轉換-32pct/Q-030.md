# Question #30

---

## 題目資訊

### 題目編號
**ID:** `Q-01-030`

### 來源
**來源:** Real Exam Recall

### 難度等級
**難度:** `L3-Advanced`

---

## 題目內容

### 題幹

A nightly job ingests data into a Delta Lake table using the following code:

```python
from pyspark.sql.functions import current_timestamp, input_file_name, col
from pyspark.sql.column import Column

def ingest_daily_batch(time_col: Column, year: int, month: int, day: int):
    (spark.read
     .format("parquet")
     .load(f"/mnt/daily_batch/{year}/{month}/{day}")
     .withColumn("ingest_time", time_col)
     .withColumn("source_file", input_file_name())
     .write
     .mode("append")
     .saveAsTable("bronze")
    )
```

The next step in the pipeline requires a function that returns an object that can be used to manipulate new records that have not yet been processed to the next table in the pipeline.

Which code snippet completes this function definition?

```python
def new_records():
```

### 選項

- **A.** `return spark.readStream.table("bronze")`
- **B.** `return spark.readStream.load("bronze")`
- **C.** `return spark.read.table("bronze").filter(col("ingest_time") > current_timestamp())`
- **D.** `return spark.read.option("readChangeFeed", "true").table("bronze")`
- **E.** `return spark.read.table("bronze").filter(col("source_file").contains(f"/mnt/daily_batch/{year}/{month}/{day}"))`

---

## 標籤系統

### Topic Tags (技術主題標籤)
**Topics:** `Change-Data-Feed`, `Incremental-Processing`, `Delta-Lake`, `Batch-vs-Stream`

### Trap Tags (陷阱類型標籤)
**Traps:** `Read-Method`, `Incremental-Detection`

### Knowledge Domain (知識領域)
**Domain:** `Data Engineering`

---

## 答案與解析連結

### 正確答案
**正解:** `D`

### 解析檔案
**詳細解析:** [點此查看解析](../analysis/Q-01-030-analysis.md)

**備註:** Community discussion is split between A, D, and E depending on context not fully visible.

---

## 相關資源

### 官方文件
- [Change Data Feed](https://docs.databricks.com/delta/delta-change-data-feed.html)
- [Incremental Processing Patterns](https://docs.databricks.com/delta/delta-streaming.html)
- [readStream vs readChangeFeed](https://docs.databricks.com/structured-streaming/delta-lake.html)
