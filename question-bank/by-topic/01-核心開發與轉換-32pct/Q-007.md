# Question #7

---

## 題目資訊

### 題目編號
**ID:** `Q-01-007`

### 來源
**來源:** Real Exam Recall

### 難度等級
**難度:** `L2-Intermediate`

---

## 題目內容

### 題幹

The data science team has created and logged a production model using MLflow. The following code correctly imports and applies the production model to output the predictions as a new DataFrame named preds with the schema "customer_id LONG, predictions DOUBLE, date DATE".

```python
from pyspark.sql.functions import current_date
model = mlflow.pyfunc.spark_udf(spark, model_uri="models:/churn/prod")
df = spark.table("customers")
preds = df.select(
    "customer_id",
    model(columns).alias("predictions"),
    current_date().alias("date")
)
```

The data science team would like predictions saved to a Delta Lake table with the ability to compare all predictions across time. Churn predictions will be made at most once per day.

Which code block accomplishes this task while minimizing potential compute costs?

### 選項

- **A.** `preds.write.mode("append").saveAsTable("churn_preds")`
- **B.** `preds.write.format("delta").save("/preds/churn_preds")`
- **C.** `(preds.writeStream.outputMode("overwrite").option("checkpointPath", "...").start("/preds/churn_preds"))`
- **D.** `preds.write.format("delta").mode("overwrite").saveAsTable("churn_preds")`
- **E.** `(preds.writeStream.outputMode("append").option("checkpointPath", "...").table("churn_preds"))`

---

## 標籤系統

### Topic Tags (技術主題標籤)
**Topics:** `MLflow`, `Delta-Lake`, `Batch-Processing`, `Cost-Optimization`

### Trap Tags (陷阱類型標籤)
**Traps:** `Batch-vs-Stream`, `Write-Mode`

### Knowledge Domain (知識領域)
**Domain:** `Machine Learning`

---

## 答案與解析連結

### 正確答案
**正解:** `A`

### 解析檔案
**詳細解析:** [點此查看解析](../analysis/Q-01-007-analysis.md)

---

## 相關資源

### 官方文件
- [MLflow Model Deployment](https://docs.databricks.com/mlflow/models.html)
- [Delta Lake Write Operations](https://docs.databricks.com/delta/delta-batch.html)
