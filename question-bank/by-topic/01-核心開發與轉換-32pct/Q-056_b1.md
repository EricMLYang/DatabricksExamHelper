# Question #056

---

## é¡Œç›®è³‡è¨Š
### é¡Œç›®ç·¨è™Ÿ
**ID:** `Q-056`
### ä¾†æº
**ä¾†æº:** Community
### é›£åº¦ç­‰ç´š
**é›£åº¦:** `L2-Intermediate`

---

## é¡Œç›®å…§å®¹
### é¡Œå¹¹
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
Which of the following approaches allows to correctly perform streaming deduplication?

### é¸é …
<!-- âš ï¸ ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è­¯ -->
- **A.** De-duplicate records in all batches with watermarking, and then overwrite the target table by the result
- **B.** De-duplicate records within each batch, rank the result, and then insert only records having rank = 1 into the target table
- **C.** De-duplicate records within each batch, and then merge the result into the target table using insert-only merge
- **D.** De-duplicate records within each batch, and then append the result into the target table

---

## æ¨™ç±¤ç³»çµ±
### Topic Tags (æŠ€è¡“ä¸»é¡Œæ¨™ç±¤)
**Topics:** `Streaming`, `Delta-MERGE`
### Trap Tags (é™·é˜±é¡å‹æ¨™ç±¤)
**Traps:** `Execution-Behavior`
### Knowledge Domain (çŸ¥è­˜é ˜åŸŸ)
**Domain:** Data Engineering / Data Quality

---

## ç­”æ¡ˆèˆ‡ä¾†æº
### æ­£ç¢ºç­”æ¡ˆ
**æ­£è§£:** `C`
### ç­”æ¡ˆä¾†æº
- **ä¾†æºæ¨™è¨»ç­”æ¡ˆ:** C
- **ç¤¾ç¾¤å…±è­˜:** C

---

# é¡Œç›®è§£æ

---

## ğŸ“ è€ƒé»è­˜åˆ¥
**æ ¸å¿ƒæŠ€è¡“:** Streaming Deduplication with Delta Lake
**é—œéµæ¦‚å¿µ:** `dropDuplicates()`ã€Insert-only MERGEã€æ‰¹æ¬¡å…§èˆ‡æ‰¹æ¬¡é–“å»é‡
**é¡Œç›®é—œéµå­—ï¼š**
- **streaming deduplication**: ä¸²æµè³‡æ–™å»é‡
- **within each batch**: æ‰¹æ¬¡å…§å»é‡
- **insert-only merge**: åƒ…æ’å…¥å¼åˆä½µ

---

## âœ… æ­£è§£èªªæ˜
### ç‚ºä»€éº¼ C æ˜¯æ­£ç¢ºç­”æ¡ˆï¼Ÿ

Streaming å»é‡éœ€è¦è™•ç†å…©å€‹å±¤é¢ï¼š
1. **æ‰¹æ¬¡å…§å»é‡**ï¼šåŒä¸€ micro-batch ä¸­çš„é‡è¤‡
2. **æ‰¹æ¬¡é–“å»é‡**ï¼šæ–°è³‡æ–™èˆ‡ç›®æ¨™è¡¨ä¸­å·²å­˜åœ¨è³‡æ–™çš„é‡è¤‡

#### å®Œæ•´çš„ Streaming Deduplication å¯¦ç¾
```python
def process_batch(batch_df, batch_id):
    # æ­¥é©Ÿ 1: æ‰¹æ¬¡å…§å»é‡
    deduplicated = batch_df.dropDuplicates(["id"])

    # æ­¥é©Ÿ 2: ä½¿ç”¨ insert-only merge è™•ç†æ‰¹æ¬¡é–“é‡è¤‡
    deduplicated.createOrReplaceTempView("updates")

    spark.sql("""
        MERGE INTO target_table t
        USING updates u
        ON t.id = u.id
        WHEN NOT MATCHED THEN INSERT *
    """)

# ä¸²æµå¯«å…¥
(streaming_df
    .writeStream
    .foreachBatch(process_batch)
    .option("checkpointLocation", "/checkpoint")
    .start()
)
```

#### å»é‡ç­–ç•¥åˆ†è§£
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Micro-batch 1                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ A-1 â”‚ â”‚ A-1 â”‚ â”‚ B-1 â”‚ â”‚ C-1 â”‚  â† åŸå§‹è³‡æ–™          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚           â†“                                          â”‚
â”‚  dropDuplicates(["id"])  â† æ‰¹æ¬¡å…§å»é‡                 â”‚
â”‚           â†“                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚ A-1 â”‚ â”‚ B-1 â”‚ â”‚ C-1 â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Insert-only MERGE                        â”‚
â”‚                                                      â”‚
â”‚  Target Table:     Updates:                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ A-0 â”‚           â”‚ A-1 â”‚ â”‚ B-1 â”‚ â”‚ C-1 â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                      â”‚
â”‚  ON t.id = u.id                                      â”‚
â”‚  WHEN NOT MATCHED THEN INSERT *                      â”‚
â”‚                                                      â”‚
â”‚  çµæœï¼šåªæ’å…¥ B-1, C-1ï¼ˆA å·²å­˜åœ¨ï¼Œè·³éï¼‰              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âŒ éŒ¯èª¤é¸é …æ’é™¤

### A. ...overwrite the target table by the result
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- **Overwrite æœƒä¸Ÿå¤±æ­·å²è³‡æ–™**
- æ¯æ¬¡åŸ·è¡Œæœƒæ¸…ç©ºç›®æ¨™è¡¨ï¼Œåªä¿ç•™ç•¶å‰ batch
- é€™ä¸æ˜¯å»é‡ï¼Œæ˜¯è³‡æ–™éºå¤±

### B. ...rank the result, and then insert only records having rank = 1
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- Rank åªèƒ½è™•ç†**æ‰¹æ¬¡å…§**çš„é‡è¤‡
- ç„¡æ³•è™•ç†æ–°è³‡æ–™èˆ‡**ç›®æ¨™è¡¨**ä¸­å·²å­˜åœ¨è³‡æ–™çš„é‡è¤‡
- ç¼ºå°‘æ‰¹æ¬¡é–“å»é‡æ©Ÿåˆ¶

### D. ...append the result into the target table
**ç‚ºä»€éº¼éŒ¯èª¤ï¼Ÿ**
- Append åªæ˜¯è¿½åŠ ï¼Œ**ä¸æœƒæª¢æŸ¥é‡è¤‡**
- å¦‚æœæ–°æ‰¹æ¬¡çš„è³‡æ–™åœ¨ç›®æ¨™è¡¨å·²å­˜åœ¨ï¼Œæœƒç”¢ç”Ÿé‡è¤‡
- ç¼ºå°‘æ‰¹æ¬¡é–“å»é‡æ©Ÿåˆ¶

---

## ğŸ§  è¨˜æ†¶æ³•
### å£è¨£
**ã€Œæ‰¹æ¬¡å…§ dropDuplicatesï¼Œæ‰¹æ¬¡é–“ insert-only MERGEã€**

### Streaming å»é‡å…©å±¤æ©Ÿåˆ¶
```
å±¤æ¬¡ 1: æ‰¹æ¬¡å…§å»é‡
â”œâ”€â”€ æ–¹æ³•: dropDuplicates()
â”œâ”€â”€ ç›®çš„: ç§»é™¤åŒä¸€ micro-batch ä¸­çš„é‡è¤‡
â””â”€â”€ ç¯„åœ: åƒ…é™ç•¶å‰æ‰¹æ¬¡

å±¤æ¬¡ 2: æ‰¹æ¬¡é–“å»é‡
â”œâ”€â”€ æ–¹æ³•: INSERT-only MERGE
â”œâ”€â”€ ç›®çš„: ç¢ºä¿æ–°è³‡æ–™ä¸èˆ‡ç›®æ¨™è¡¨é‡è¤‡
â””â”€â”€ ç¯„åœ: æ–°æ‰¹æ¬¡ vs ç›®æ¨™è¡¨
```

### Insert-only MERGE èªæ³•
```sql
MERGE INTO target t
USING source s
ON t.key = s.key
WHEN NOT MATCHED THEN INSERT *
-- æ³¨æ„ï¼šæ²’æœ‰ WHEN MATCHED å­å¥
-- åŒ¹é…æ™‚ä¸åšä»»ä½•äº‹ï¼ˆè·³éé‡è¤‡ï¼‰
```

### å»é‡æ–¹æ³•æ¯”è¼ƒ
| æ–¹æ³• | æ‰¹æ¬¡å…§ | æ‰¹æ¬¡é–“ | é©ç”¨å ´æ™¯ |
|------|--------|--------|---------|
| `dropDuplicates()` | âœ… | âŒ | å¿«é€Ÿæ‰¹æ¬¡å…§å»é‡ |
| `MERGE` (insert-only) | âŒ | âœ… | ç¢ºä¿ç›®æ¨™è¡¨å”¯ä¸€ |
| `dropDuplicates()` + `MERGE` | âœ… | âœ… | å®Œæ•´ä¸²æµå»é‡ |

---

## ğŸ“š å®˜æ–¹æ–‡ä»¶
- [Data deduplication when writing into Delta tables](https://docs.databricks.com/en/delta/merge.html#data-deduplication-when-writing-into-delta-tables)
- [dropDuplicates](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.dropDuplicates.html)

---

**[è¿”å›é¡Œç›®](#question-056)**
