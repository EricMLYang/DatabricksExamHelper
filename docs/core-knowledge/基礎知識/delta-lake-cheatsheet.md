# Delta Lake æ ¸å¿ƒæ¦‚å¿µé€ŸæŸ¥è¡¨

> Databricks èªè­‰è€ƒè©¦å¿…å‚™ï¼šDelta Lake æ ¸å¿ƒ API èˆ‡é…ç½®å¿«é€Ÿåƒè€ƒ

**æœ€å¾Œæ›´æ–°:** 2024-01-15
**é©ç”¨è€ƒè©¦:** Data Engineer Associate / Professional

---

## ðŸ“‹ ç›®éŒ„

1. [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
2. [è³‡æ–™è¡¨ç®¡ç†æŒ‡ä»¤](#è³‡æ–™è¡¨ç®¡ç†æŒ‡ä»¤)
3. [è³‡æ–™æ“ä½œ (DML)](#è³‡æ–™æ“ä½œ-dml)
4. [Time Travel](#time-travel)
5. [è³‡æ–™è¡¨ç¶­è­·](#è³‡æ–™è¡¨ç¶­è­·)
6. [Schema ç®¡ç†](#schema-ç®¡ç†)
7. [Change Data Feed (CDF)](#change-data-feed-cdf)
8. [é…ç½®åƒæ•¸](#é…ç½®åƒæ•¸)
9. [å¸¸è¦‹éŒ¯èª¤èˆ‡æŽ’é™¤](#å¸¸è¦‹éŒ¯èª¤èˆ‡æŽ’é™¤)

---

## æ ¸å¿ƒæ¦‚å¿µ

### Delta Lake æ˜¯ä»€éº¼ï¼Ÿ

Delta Lake æ˜¯å»ºç«‹åœ¨ Data Lake ä¹‹ä¸Šçš„é–‹æºå„²å­˜å±¤ï¼Œæä¾› ACID äº¤æ˜“ã€å¯æ“´å±•çš„å…ƒè³‡æ–™è™•ç†ã€ä»¥åŠçµ±ä¸€çš„æ‰¹æ¬¡èˆ‡ä¸²æµè³‡æ–™è™•ç†ã€‚

### æ ¸å¿ƒç‰¹æ€§

| ç‰¹æ€§ | èªªæ˜Ž | è€ƒè©¦é‡é»ž |
|------|------|---------|
| **ACID äº¤æ˜“** | åŽŸå­æ€§ã€ä¸€è‡´æ€§ã€éš”é›¢æ€§ã€æŒä¹…æ€§ | å¤šå€‹å¯«å…¥æ“ä½œçš„ä¸€è‡´æ€§ä¿è­‰ |
| **Time Travel** | æŸ¥è©¢æ­·å²ç‰ˆæœ¬è³‡æ–™ | VERSION AS OF èªžæ³• |
| **Schema Evolution** | å‹•æ…‹èª¿æ•´ Schema | mergeSchema, overwriteSchema é¸é … |
| **Upsert (MERGE)** | åˆä½µæ’å…¥/æ›´æ–° | MERGE INTO èªžæ³• |
| **DML æ”¯æ´** | UPDATE, DELETE, MERGE | èˆ‡ Parquet çš„å·®ç•° |

---

## è³‡æ–™è¡¨ç®¡ç†æŒ‡ä»¤

### å»ºç«‹ Delta Table

| æ–¹æ³• | èªžæ³• | ä½¿ç”¨æ™‚æ©Ÿ |
|------|------|---------|
| **SQL** | `CREATE TABLE table_name USING DELTA AS SELECT ...` | å¾žæŸ¥è©¢çµæžœå»ºç«‹ |
| **DataFrameWriter** | `df.write.format("delta").save("/path")` | PySpark ç¨‹å¼åŒ–å»ºç«‹ |
| **Convert Parquet** | `CONVERT TO DELTA parquet.\`/path\`` | è½‰æ›ç¾æœ‰ Parquet è³‡æ–™ |

**ç¯„ä¾‹:**
```sql
-- SQL å»ºç«‹
CREATE TABLE events
USING DELTA
PARTITIONED BY (date)
AS SELECT * FROM raw_events;
```

```python
# PySpark å»ºç«‹
df.write \
  .format("delta") \
  .partitionBy("date") \
  .save("/mnt/delta/events")
```

---

### è³‡æ–™è¡¨å±¬æ€§

| å±¬æ€§ | èªªæ˜Ž | ç¯„ä¾‹ |
|------|------|------|
| `LOCATION` | å¯¦é«”å„²å­˜è·¯å¾‘ | `LOCATION '/mnt/delta/events'` |
| `PARTITIONED BY` | åˆ†å‰²æ¬„ä½ | `PARTITIONED BY (date, region)` |
| `TBLPROPERTIES` | è‡ªè¨‚å±¬æ€§ | `TBLPROPERTIES ('delta.autoOptimize.optimizeWrite' = 'true')` |

---

## è³‡æ–™æ“ä½œ (DML)

### UPDATE

```sql
UPDATE table_name
SET column = value
WHERE condition;
```

**è€ƒè©¦é‡é»ž:**
- Delta Lake æ”¯æ´ UPDATEï¼ŒParquet ä¸æ”¯æ´
- WHERE å­å¥æ˜¯é¸å¡«çš„ï¼ˆä½†å¼·çƒˆå»ºè­°ä½¿ç”¨ï¼‰

---

### DELETE

```sql
DELETE FROM table_name
WHERE condition;
```

**è€ƒè©¦é‡é»ž:**
- DELETE æ˜¯**é‚è¼¯åˆªé™¤**ï¼Œä¸æœƒç«‹å³é‡‹æ”¾ç©ºé–“
- éœ€é…åˆ VACUUM æ‰èƒ½å¯¦é«”åˆªé™¤æª”æ¡ˆ

---

### MERGE (Upsert)

```sql
MERGE INTO target_table
USING source_table
ON target_table.id = source_table.id
WHEN MATCHED THEN UPDATE SET *
WHEN NOT MATCHED THEN INSERT *;
```

**å®Œæ•´èªžæ³•çµæ§‹:**
```sql
MERGE INTO target
USING source
ON merge_condition
WHEN MATCHED [AND condition] THEN UPDATE SET ...
WHEN MATCHED [AND condition] THEN DELETE
WHEN NOT MATCHED [AND condition] THEN INSERT ...
```

**è€ƒè©¦é‡é»ž:**
- `ON` å­å¥å®šç¾©åŒ¹é…æ¢ä»¶
- å¯çµ„åˆå¤šå€‹ WHEN å­å¥
- `UPDATE SET *` æ›´æ–°æ‰€æœ‰æ¬„ä½
- æ”¯æ´æ¢ä»¶å¼æ›´æ–°/åˆªé™¤

---

## Time Travel

### æŸ¥è©¢æ­·å²ç‰ˆæœ¬

| æ–¹æ³• | èªžæ³• | èªªæ˜Ž |
|------|------|------|
| **ç‰ˆæœ¬è™Ÿ** | `SELECT * FROM table VERSION AS OF 42` | æŸ¥è©¢ç‰¹å®šç‰ˆæœ¬ |
| **æ™‚é–“æˆ³è¨˜** | `SELECT * FROM table TIMESTAMP AS OF '2024-01-01'` | æŸ¥è©¢ç‰¹å®šæ™‚é–“é»ž |
| **DataFrameReader** | `spark.read.format("delta").option("versionAsOf", 42)` | PySpark å¯«æ³• |

**è€ƒè©¦é‡é»ž:**
- ç‰ˆæœ¬è™Ÿå¾ž 0 é–‹å§‹è¨ˆæ•¸
- VACUUM æœƒåˆªé™¤èˆŠç‰ˆæœ¬ï¼Œå½±éŸ¿ Time Travel å¯ç”¨ç¯„åœ
- Time Travel ä¾è³´å¯¦é«”æª”æ¡ˆï¼Œä¸åƒ…åƒ…æ˜¯å…ƒè³‡æ–™

---

### æŸ¥è©¢ç‰ˆæœ¬æ­·å²

```sql
DESCRIBE HISTORY table_name [LIMIT n];
```

**è¼¸å‡ºæ¬„ä½:**
- `version`: ç‰ˆæœ¬è™Ÿ
- `timestamp`: æ™‚é–“æˆ³è¨˜
- `operation`: æ“ä½œé¡žåž‹ (WRITE, MERGE, DELETEç­‰)
- `operationMetrics`: æ“ä½œçµ±è¨ˆè³‡æ–™

---

## è³‡æ–™è¡¨ç¶­è­·

### VACUUM - æ¸…ç†èˆŠç‰ˆæœ¬æª”æ¡ˆ

```sql
VACUUM table_name [RETAIN num HOURS];
```

| åƒæ•¸ | èªªæ˜Ž | é è¨­å€¼ | è€ƒè©¦é™·é˜± |
|------|------|--------|---------|
| `RETAIN` | ä¿ç•™æ™‚é–“ï¼ˆå°æ™‚ï¼‰ | 168 å°æ™‚ (7 å¤©) | **åªæŽ¥å— HOURS**ï¼Œéœ€æ›ç®—å¤©æ•¸ |
| `DRY RUN` | é è¦½å°‡åˆªé™¤çš„æª”æ¡ˆ | - | ä¸å¯¦éš›åˆªé™¤ï¼Œç”¨æ–¼æª¢æŸ¥ |

**é‡è¦æé†’:**
- âš ï¸ VACUUM æ˜¯**æ°¸ä¹…åˆªé™¤**ï¼Œç„¡æ³•å¾©åŽŸ
- âš ï¸ åŸ·è¡Œå¾Œæœƒå½±éŸ¿ Time Travel å¯ç”¨ç¯„åœ
- âš ï¸ é è¨­ä¿ç•™ 7 å¤©ï¼Œå»ºè­°æ ¹æ“šæ¥­å‹™éœ€æ±‚èª¿æ•´

**ç¯„ä¾‹:**
```sql
-- ä¿ç•™ 30 å¤©è³‡æ–™
VACUUM events RETAIN 720 HOURS;

-- é è¦½å°‡åˆªé™¤çš„æª”æ¡ˆï¼ˆdry-runï¼‰
VACUUM events RETAIN 168 HOURS DRY RUN;
```

---

### OPTIMIZE - åˆä½µå°æª”æ¡ˆ

```sql
OPTIMIZE table_name [WHERE partition_filter]
[ZORDER BY (column1, column2, ...)];
```

| åŠŸèƒ½ | èªªæ˜Ž | ä½¿ç”¨æ™‚æ©Ÿ |
|------|------|---------|
| **åˆä½µå°æª”æ¡ˆ** | å°‡å°æª”æ¡ˆåˆä½µç‚ºè¼ƒå¤§æª”æ¡ˆ | å¯«å…¥é »ç¹å°Žè‡´å¤§é‡å°æª”æ¡ˆ |
| **Z-Order** | å¤šç¶­åº¦èšé›†è³‡æ–™ | å¤šæ¬„ä½ç¯©é¸æŸ¥è©¢ |

**è€ƒè©¦é‡é»ž:**
- OPTIMIZE **ä¸æœƒåˆªé™¤èˆŠç‰ˆæœ¬**ï¼ˆèˆ‡ VACUUM çš„å·®ç•°ï¼‰
- ZORDER æœ€å¤šå»ºè­° 4 å€‹æ¬„ä½
- åŸ·è¡Œå¾ŒçŸ­æœŸå¯èƒ½å¢žåŠ ç©ºé–“ä½¿ç”¨ï¼ˆéœ€æ­é… VACUUMï¼‰

**ç¯„ä¾‹:**
```sql
-- åˆä½µå°æª”æ¡ˆ
OPTIMIZE events;

-- é‡å°ç‰¹å®šåˆ†å‰²å€
OPTIMIZE events WHERE date >= '2024-01-01';

-- Z-Order å„ªåŒ–
OPTIMIZE events ZORDER BY (user_id, event_type);
```

---

### DESCRIBE DETAIL - æŸ¥çœ‹è³‡æ–™è¡¨è©³ç´°è³‡è¨Š

```sql
DESCRIBE DETAIL table_name;
```

**è¼¸å‡ºé—œéµæ¬„ä½:**
- `format`: è³‡æ–™æ ¼å¼ï¼ˆæ‡‰ç‚º `delta`ï¼‰
- `location`: å„²å­˜è·¯å¾‘
- `numFiles`: æª”æ¡ˆæ•¸é‡
- `sizeInBytes`: è³‡æ–™å¤§å°
- `partitionColumns`: åˆ†å‰²æ¬„ä½

---

## Schema ç®¡ç†

### Schema Evolution é¸é …

| é¸é … | èªªæ˜Ž | ä½¿ç”¨æ™‚æ©Ÿ | ç¯„ä¾‹ |
|------|------|---------|------|
| `mergeSchema` | åˆä½µæ–°èˆŠ Schema | æ–°å¢žæ¬„ä½ | `.option("mergeSchema", "true")` |
| `overwriteSchema` | å®Œå…¨è¦†å¯« Schema | è®Šæ›´æ¬„ä½åž‹åˆ¥æˆ–åˆªé™¤æ¬„ä½ | `.option("overwriteSchema", "true")` |

**ç¯„ä¾‹:**
```python
# æ–°å¢žæ¬„ä½
df_with_new_column.write \
  .format("delta") \
  .mode("append") \
  .option("mergeSchema", "true") \
  .save("/mnt/delta/events")
```

**è€ƒè©¦é‡é»ž:**
- `mergeSchema` åªèƒ½**æ–°å¢ž**æ¬„ä½ï¼Œä¸èƒ½åˆªé™¤æˆ–è®Šæ›´åž‹åˆ¥
- `overwriteSchema` æœƒè¦†å¯«æ•´å€‹ Schemaï¼Œéœ€è¬¹æ…Žä½¿ç”¨
- é è¨­ä¸å•Ÿç”¨ï¼Œéœ€æ˜Žç¢ºæŒ‡å®š

---

### Constraints (ç´„æŸæ¢ä»¶)

```sql
ALTER TABLE table_name ADD CONSTRAINT constraint_name CHECK (condition);
```

**ç¯„ä¾‹:**
```sql
-- æª¢æŸ¥æ•¸å€¼ç¯„åœ
ALTER TABLE events ADD CONSTRAINT valid_age CHECK (age >= 0 AND age <= 120);

-- æª¢æŸ¥éžç©ºå€¼
ALTER TABLE events ADD CONSTRAINT user_id_not_null CHECK (user_id IS NOT NULL);
```

---

## Change Data Feed (CDF)

### å•Ÿç”¨ CDF

```sql
ALTER TABLE table_name SET TBLPROPERTIES (delta.enableChangeDataFeed = true);
```

æˆ–åœ¨å»ºç«‹æ™‚å•Ÿç”¨ï¼š
```sql
CREATE TABLE table_name
USING DELTA
TBLPROPERTIES (delta.enableChangeDataFeed = true)
AS SELECT ...;
```

### æŸ¥è©¢è®Šæ›´è³‡æ–™

```sql
SELECT * FROM table_changes('table_name', 2, 5);  -- ç‰ˆæœ¬ 2 åˆ° 5 çš„è®Šæ›´
SELECT * FROM table_changes('table_name', '2024-01-01', '2024-01-31');  -- æ™‚é–“ç¯„åœ
```

**è¼¸å‡ºé¡å¤–æ¬„ä½:**
- `_change_type`: INSERT, UPDATE_PREIMAGE, UPDATE_POSTIMAGE, DELETE
- `_commit_version`: è®Šæ›´ç™¼ç”Ÿçš„ç‰ˆæœ¬è™Ÿ
- `_commit_timestamp`: è®Šæ›´æ™‚é–“

---

## é…ç½®åƒæ•¸

### å¸¸ç”¨ Table Properties

| å±¬æ€§ | èªªæ˜Ž | é è¨­å€¼ | å»ºè­°å€¼ |
|------|------|--------|--------|
| `delta.logRetentionDuration` | Log ä¿ç•™æ™‚é–“ | 30 å¤© | æ ¹æ“š Time Travel éœ€æ±‚èª¿æ•´ |
| `delta.deletedFileRetentionDuration` | åˆªé™¤æª”æ¡ˆä¿ç•™æ™‚é–“ | 7 å¤© | èˆ‡ VACUUM RETAIN ä¸€è‡´ |
| `delta.enableChangeDataFeed` | å•Ÿç”¨ CDF | false | éœ€è¦ CDC åŠŸèƒ½æ™‚å•Ÿç”¨ |
| `delta.autoOptimize.optimizeWrite` | å¯«å…¥æ™‚è‡ªå‹•å„ªåŒ– | false | å¯«å…¥é »ç¹æ™‚å•Ÿç”¨ |
| `delta.autoOptimize.autoCompact` | è‡ªå‹•åˆä½µå°æª”æ¡ˆ | false | é…åˆ optimizeWrite ä½¿ç”¨ |

**è¨­å®šç¯„ä¾‹:**
```sql
ALTER TABLE events SET TBLPROPERTIES (
  'delta.logRetentionDuration' = '90 days',
  'delta.deletedFileRetentionDuration' = '30 days',
  'delta.autoOptimize.optimizeWrite' = 'true'
);
```

---

## å¸¸è¦‹éŒ¯èª¤èˆ‡æŽ’é™¤

### éŒ¯èª¤ 1: ConcurrentAppendException
**åŽŸå› :** å¤šå€‹å¯«å…¥æ“ä½œåŒæ™‚é€²è¡Œ
**è§£æ±º:** ä½¿ç”¨ MERGE æˆ–èª¿æ•´å¯«å…¥ç­–ç•¥

---

### éŒ¯èª¤ 2: ProtocolChangedException
**åŽŸå› :** Delta Lake ç‰ˆæœ¬ä¸ç›¸å®¹
**è§£æ±º:** å‡ç´š Delta Lake ç‰ˆæœ¬æˆ–ä½¿ç”¨ç›¸å®¹è¨­å®š

---

### éŒ¯èª¤ 3: VACUUM å¾Œç„¡æ³• Time Travel
**åŽŸå› :** VACUUM åˆªé™¤äº†éœ€è¦çš„æ­·å²æª”æ¡ˆ
**è§£æ±º:** èª¿æ•´ RETAIN åƒæ•¸ï¼Œç¢ºä¿å¤§æ–¼ Time Travel éœ€æ±‚

---

## ðŸŽ¯ è€ƒè©¦é«˜é »è€ƒé»žç¸½çµ

### å¿…è€ƒè§€å¿µ

1. **VACUUM vs OPTIMIZE vs DELETE çš„å·®ç•°**
   - VACUUM: å¯¦é«”åˆªé™¤èˆŠç‰ˆæœ¬æª”æ¡ˆï¼Œé‡‹æ”¾ç©ºé–“
   - OPTIMIZE: åˆä½µå°æª”æ¡ˆï¼Œæå‡æ•ˆèƒ½ï¼Œ**ä¸åˆªé™¤èˆŠç‰ˆæœ¬**
   - DELETE: é‚è¼¯åˆªé™¤è³‡æ–™ï¼Œ**ä¸é‡‹æ”¾ç©ºé–“**

2. **Time Travel èˆ‡ VACUUM çš„é—œä¿‚**
   - VACUUM æœƒæ°¸ä¹…åˆªé™¤æª”æ¡ˆï¼Œå½±éŸ¿ Time Travel å¯ç”¨ç¯„åœ
   - éœ€å¹³è¡¡å„²å­˜æˆæœ¬èˆ‡è³‡æ–™å¾©åŽŸéœ€æ±‚

3. **MERGE èªžæ³•çµæ§‹**
   - ON æ¢ä»¶ã€WHEN MATCHEDã€WHEN NOT MATCHED
   - æ”¯æ´æ¢ä»¶å¼æ›´æ–°èˆ‡åˆªé™¤

4. **Schema Evolution**
   - mergeSchema åªèƒ½æ–°å¢žæ¬„ä½
   - overwriteSchema å®Œå…¨è¦†å¯«

5. **å–®ä½é™·é˜±**
   - VACUUM RETAIN åªæŽ¥å— HOURSï¼Œéœ€æ›ç®—å¤©æ•¸

---

## ðŸ“š å»¶ä¼¸é–±è®€

- [Delta Lake Official Documentation](https://docs.delta.io/)
- [Databricks Delta Lake Guide](https://docs.databricks.com/delta/index.html)
- [Delta Lake Best Practices](https://docs.databricks.com/delta/best-practices.html)

---

**å¿«é€Ÿè¤‡ç¿’å®Œæˆï¼å»ºè­°æ­é…å¯¦éš›ç·´ç¿’é¡Œéžå›ºç†è§£ã€‚** ðŸš€
