# Databricks 資深資料工程師認證考試指南 (2025-2026)

## 1. 引言：考試的新篇章

不同於過往著重於複雜的 Spark 底層調校或手動分區策略，新版考試更側重於：

- **Lakeflow 自動化編排**
- **Unity Catalog 系統表（System Tables）的治理洞察**
- **Liquid Clustering 的智慧儲存優化**
- **Databricks Asset Bundles (DABs) 的現代化 CI/CD 實踐**

本報告將透過六大核心領域的深度剖析，為資深資料工程師提供構建現代化資料架構的戰略藍圖。

---

## 2. 核心領域權重分佈與戰略重點

新版考綱將知識點進行了更細緻的拆解，特別強調了「治理」、「監控」與「部署」的獨立性。

| 領域 | 權重 | 關鍵技術能力 |
|------|------|-------------|
| **資料處理程式碼開發** | 22% | PySpark 與 SQL 複雜轉換、UDF 優化、巢狀結構資料處理 |
| **成本與效能優化** | 13% | Serverless 計算、Liquid Clustering、File Pruning、自動擴展策略 |
| **資料轉換、清理與品質** | 10% | Null 值處理、資料品質約束 (Expectations)、Lakeflow 管道異常處理 |
| **資料安全與合規** | 10% | Unity Catalog 權限模型、Dynamic Views、GDPR 刪除權技術落實 |
| **監控與警報** | 10% | Lakehouse Monitoring、System Tables 營運分析、Databricks SQL 警報 |
| **除錯與部署** | 10% | DABs CI/CD、Spark UI 效能瓶頸識別、管道故障根因分析 |
| **資料攝取與獲取** | 7% | Auto Loader 進階配置、串流攝取模式、Schema Drift 處理 |
| **資料治理** | 7% | System Tables 資料血緣追蹤、目錄層級設計、Unity Catalog Metastore |
| **資料建模** | 6% | Medallion Architecture、SCD Type 1/2 實作策略 |
| **資料共享與聯邦** | 5% | Delta Sharing 協議、Lakehouse Federation 跨資料庫查詢虛擬化 |

---

## 3. Lakeflow 範式：宣告式管道與編排的演進

2025-2026 年考試最顯著的變革是 **Lakeflow 的概念整合**。這是 Databricks 將資料攝取（Ingestion）、轉換（Transformation）與編排（Orchestration）統一至一個智慧化框架下的戰略舉措。

考生必須熟悉從「Delta Live Tables (DLT)」與「Databricks Jobs」過渡到 **Lakeflow Spark Declarative Pipelines** 與 **Lakeflow Jobs** 的術語與技術細節。

### 3.1 Lakeflow Spark Declarative Pipelines（前身為 DLT）

考試重點在於評估考生是否能夠從「指令式」（Imperative）的程式編寫思維，轉向「宣告式」（Declarative）的架構設計思維。在 Lakeflow 框架下，工程師只需定義資料的「最終狀態」，而由引擎自動決定執行的順序、並行度與檢查點管理。

#### 3.1.1 核心語法結構與語言限制

Lakeflow Spark Declarative Pipelines 支援 **Python** 與 **SQL** 兩種語言，但有重要限制：**不支援 JVM 語言（Scala/Java）**。這是一個常見的考點，若場景涉及依賴特定 Java 庫的複雜處理，則 Lakeflow Pipeline 可能不是正確的架構選擇。

**Python 定義模式**：使用 `@dlt.table` 或 `@dlt.view` 裝飾器來封裝 DataFrame 邏輯。考生需熟悉如何透過 Python 函數動態生成多張表（Meta-programming），這是 Python 介面相較於 SQL 的一大優勢。

**SQL 定義模式**：使用 `CREATE OR REFRESH STREAMING TABLE` 或 `CREATE MATERIALIZED VIEW` 語法。考生必須能區分這兩者的差異。

#### 3.1.2 變更資料擷取 (CDC) 與 SCD 處理策略

CDC 的實作在 Lakeflow 中透過 `APPLY CHANGES INTO` 語法得到了極大簡化（此功能常被稱為 Auto CDC）。

**運作機制**：此指令抽象化了傳統 Delta Lake MERGE 操作的複雜性。它能夠自動處理亂序到達（Out-of-order）的資料，這是透過 `SEQUENCE BY` 子句來實現的。Lakeflow 引擎會依據序列鍵（通常是時間戳記）來決定哪一筆資料是「最新」的，而非單純依賴處理時間。

**SCD 類型配置**：

| 類型 | 說明 |
|------|------|
| **SCD Type 1（覆寫）** | 保持目標表與來源表完全一致，不保留歷史 |
| **SCD Type 2（歷史保留）** | 追蹤資料變更歷史，`APPLY CHANGES INTO` 會自動管理 `__START_AT` 與 `__END_AT` 欄位 |

**序列化邏輯與去重**：處理延遲到達的更新是常見考題。考生需理解若 `SEQUENCE BY` 欄位相同，引擎如何處理（通常是非確定性的），以及如何透過 `KEYS` 子句定義主鍵來進行去重。

#### 3.1.3 物化視圖 vs 串流表的戰略選擇

| 類型 | 適用場景 | 技術特徵 | 限制 |
|------|---------|---------|------|
| **串流表 (Streaming Tables)** | Bronze 層、Append-only 資料攝取 | 支援增量處理、Delta Lake Time Travel | - |
| **物化視圖 (Materialized Views)** | Gold 層複雜聚合與報表 | 快取查詢結果加速讀取 | 更新延遲秒/分鐘級，非確定性函數或 PIVOT 會觸發全量重算 |

### 3.2 Lakeflow Jobs 與工作流程自動化

Lakeflow Jobs 代表了 Databricks Workflows 的進化，是調度與編排的中樞神經系統。

**整合能力**：能夠將宣告式的 Pipelines、指令式的 Notebooks、以及獨立的 SQL 查詢串聯成一個有向無環圖（DAG）。

**參數傳遞與上下文共享**：考試重點在於如何在不同的 Task 之間傳遞參數（Task Values）。考生需掌握 `dbutils.jobs.taskValues` 的用法及其在 Lakeflow Jobs 中的配置方式。

---

## 4. Unity Catalog：治理與安全的核心架構

在 2025-2026 年的考試版本中，Unity Catalog (UC) 已不再是選配功能，而是預設的標準配置。傳統的 Hive Metastore (HMS) 在專業級考試的語境下已大多被視為遺留系統（Legacy）。

治理與安全性佔據了約 **17%** 的總分（安全 10% + 治理 7%）。

### 4.1 三層命名空間與隔離策略

考生必須熟練掌握 `Catalog.Schema.Table` 的三層次結構。

**隔離邊界**：Catalog 是最高的隔離層級。考試常見情境是如何設計多環境隔離（Dev/Test/Prod）。最佳實踐通常是在 Catalog 層級進行環境隔離（例如 `prod_catalog` vs `dev_catalog`）。

**System Catalog 的崛起**：2025 年考試的新熱點是 `system catalog` 的應用。這是一個由 Databricks 託管的特殊目錄，包含了所有關於帳戶活動的審計日誌與計費資訊。

### 4.2 外部位置與儲存憑證

這是新版課綱中最為複雜、也最容易混淆的部分。Unity Catalog 透過解耦「儲存存取權」與「資料物件存取權」，實現了更安全的管理模式。

| 物件 | 定義 |
|------|------|
| **儲存憑證 (Storage Credential)** | 封裝了雲端身分（如 AWS IAM Role 或 Azure Managed Identity）的 UC 物件，代表「存取底層雲端儲存的能力」 |
| **外部位置 (External Location)** | 結合「儲存憑證」與「特定雲端路徑」（如 S3 Bucket 路徑）的安全物件 |

**權限階層與考點**（高頻陷阱題）：

- **情境**：一位資料分析師需要創建一個外部表（External Table）
- **錯誤觀念**：給予分析師對 Storage Credential 的權限
- **正確實踐**：授予分析師在特定 Schema 上的 `CREATE EXTERNAL TABLE` 權限，以及在對應 External Location 上的 `READ FILES` 與 `WRITE FILES` 權限

這種設計確保了終端使用者永遠無法直接接觸到雲端的金鑰或角色，貫徹了「最小權限原則」（Least Privilege）。

### 4.3 資料血緣與聯邦查詢

**自動化血緣**：Unity Catalog 會自動捕捉表級（Table-level）與列級（Column-level）的血緣關係。考試會測試考生如何利用 System Tables 中的 `system.access.column_lineage` 表進行衝擊分析（Impact Analysis）。

**Lakehouse Federation**：這項功能允許 Unity Catalog 將外部資料庫（如 PostgreSQL, Snowflake, Redshift）掛載為「外來目錄」（Foreign Catalog）。考試會詢問在何種情況下應使用 Federation 而非 ETL—通常是當需要對資料進行快速的原地查詢（Query in-place）、資料量不大或不需要將資料搬移至 Lakehouse 進行重度加工時。

---

## 5. 次世代儲存優化：Liquid Clustering

在 2025 年的儲存層技術中，**Liquid Clustering** 是最具顛覆性的更新。它被定位為取代傳統 Hive 分區（Partitioning）與 Z-Order 的新一代技術。

### 5.1 傳統分區與 Z-Order 的局限性

| 技術 | 痛點 |
|------|------|
| **分區** | 高基數欄位（如 User ID）會導致數百萬個小檔案，嚴重拖慢讀取效能 |
| **Z-Order** | 需要手動執行 OPTIMIZE 指令，執行過程會重寫大量檔案，容易與並行寫入發生衝突，不具備增量優化特性 |

### 5.2 Liquid Clustering 的運作機制與優勢

Liquid Clustering 放棄了實體目錄結構的分區方式，改用由 Databricks 管理的邏輯分群索引。

| 優勢 | 說明 |
|------|------|
| **動態靈活性** | 允許隨時更改分群鍵（Clustering Keys），無需重寫整張表 |
| **增量並行** | 背景優化作業可以與前台寫入作業並行執行，大幅減少鎖定衝突 |

**考試判斷法則（Rule of Thumb）**：

- **情境**：一張新表，查詢模式多變，且包含高基數欄位過濾
- **舊解法**：分區（若 > 1TB）+ Z-Order
- **2025 年新解法**：啟用 Liquid Clustering
- **關鍵指標**：對於小於 1TB 的表，不要使用分區，應直接使用 Liquid Clustering。建議設定 1-4 個分群鍵

---

## 6. 營運可觀測性：System Tables 與監控

「監控與警報」（10%）領域已從單純的 Spark UI 分析，轉向使用 SQL 對 System Tables 進行大數據級別的日誌分析。

### 6.1 系統架構表深度解析

#### 6.1.1 計費與使用量分析 (`system.billing.usage`)

這是「成本優化」領域的核心數據源。

| 關鍵欄位 | 用途 |
|---------|------|
| `workspace_id` | 區分不同工作區的成本 |
| `sku_name` | 區分 Serverless SQL、Pro SQL 或 Jobs Compute 的成本差異 |
| `usage_quantity` / `usage_unit` | 通常是 DBU（Databricks Unit） |
| `custom_tags` | 解析這個 Map 類型的欄位，將成本歸戶到特定的專案或部門（例如 `custom_tags['cost_center']`） |

#### 6.1.2 安全審計日誌 (`system.access.audit`)

這是安全鑑識的單一真實來源（Source of Truth）。

| 關鍵欄位 | 用途 |
|---------|------|
| `service_name` | 如 unityCatalog、jobs、notebooks |
| `action_name` | 如 createTable、delete |
| `user_identity_email` | 執行操作的使用者 |
| `request_params` | JSON 結構，包含操作細節，需使用 `from_json` 解析 |

### 6.2 Databricks Lakehouse Monitoring

這是一個整合在 Unity Catalog 中的自動化品質監控服務。

| 功能 | 說明 |
|------|------|
| **自動化剖析 (Profiling)** | 自動計算資料表的統計分佈（Null 值比例、平均值、分位數） |
| **漂移檢測 (Drift Detection)** | 比較「當前視窗」與「基準視窗」的資料分佈，偵測資料品質的衰退或模型輸入特徵的偏移 |

### 6.3 監控與警報強調

新版考試強調使用 **Databricks REST/CLI** 進行監控以及設定 **SQL Alerts**，反映平台更新。

---

## 7. 現代化開發體驗：Databricks Asset Bundles (DABs)

在「除錯與部署」（10%）領域，舊有的 `dbx` 工具與單純的 Repos 正在被 **Databricks Asset Bundles (DABs)** 取代，成為 CI/CD 的標準實踐。

### 7.1 基礎設施即程式碼 (IaC) 與 YAML 結構

DABs 允許工程師使用宣告式的 `databricks.yml` 檔案來定義整個專案。

| YAML 區塊 | 說明 |
|-----------|------|
| **Resources** | 定義具體的 Databricks 資源，如 jobs, pipelines, model_serving_endpoints |
| **Targets** | 針對不同環境（dev, staging, prod）定義覆寫規則。例如，在 dev 環境使用小型單節點叢集，而在 prod 環境使用大型自動擴展叢集 |
| **Variables** | 定義跨 Target 共用的動態參數 |

### 7.2 部署生命週期與測試策略

**開發流程**：工程師在本地 IDE（如 VS Code）開發，透過 DABs 同步至 Databricks Workspace。

**CI/CD 整合**：考試會測試如何將 DABs 整合進 GitHub Actions 或 Azure DevOps。

| 關鍵指令 | 用途 |
|---------|------|
| `bundle validate` | 檢查配置語法 |
| `bundle deploy` | 部署資源 |

**單元測試與整合測試**：DABs 鼓勵將 Python 模組化並使用 `pytest` 進行測試。若在 DABs 環境下執行 pytest 失敗，通常與檔案路徑或模組匯入（Relative Import）有關，這是常見的除錯考題。

---

## 8. 運算架構：Serverless 與 SQL Warehouses

「成本與效能優化」（13%）領域大量涉及 Serverless Compute 的應用。

### 8.1 Serverless SQL Warehouses 的架構優勢與限制

| 面向 | 說明 |
|------|------|
| **核心優勢** | 即時啟動（消除冷啟動時間）、自動擴展與負載平衡，適合 Ad-hoc SQL 查詢與 BI 儀表板 |
| **網路限制（關鍵考點）** | Serverless 運算資源位於 Databricks 的控制平面，而非客戶的 VPC 內。存取私有網路內的資料來源需配置 Private Link 或 Network Connectivity Config |
| **成本考量** | 對於長期運行且負載穩定的工作負載，Serverless 的單價可能高於預留實例 |

### 8.2 運算策略 (Compute Policies)

管理員利用策略（Policies）來強制執行標籤（Tags）規範，這直接關聯到 System Tables 的成本歸戶。例如，強制所有叢集必須包含 `Project_ID` 標籤，否則無法創建。這也是防止使用者創建超大規格叢集（如 GPU 叢集）的有效手段。

---

## 9. 深度領域分析：資料處理與進階轉換

### 9.1 進階 Spark 轉換與效能調校

#### 巢狀資料處理

| 方法 | 說明 |
|------|------|
| `explode()` | 導致資料列數膨脹（Shuffle），可能引發 OOM |
| **Higher-Order Functions** | 如 `transform`, `filter`, `aggregate`，在 SQL 中直接操作陣列，避免 Shuffle，大幅提升效能 |

#### Skew（資料傾斜）處理

當某個 Partition 的資料量遠大於其他 Partition 時，會拖慢整個 Stage。

| 解法 | 說明 |
|------|------|
| AQE 自動傾斜處理 | 啟用 Adaptive Query Execution |
| 手動加鹽（Salting） | 在 Join 鍵上加入隨機數以打散資料分佈 |

### 9.2 Auto Loader (Cloud Files) 的進階模式

| 模式 | 適用場景 |
|------|---------|
| **Directory Listing（預設）** | 檔案數量較少的情況 |
| **File Notification** | S3/ADLS 上有數百萬個檔案的情境，利用雲端事件通知觸發攝取 |

#### Schema Evolution 配置 (`cloudFiles.schemaEvolutionMode`)

| 模式 | 說明 |
|------|------|
| `addNewColumns` | 自動新增欄位 |
| `rescue` | 最穩健的生產環境設置，將不符合 Schema 的資料放入 `_rescued_data` 欄位，確保 Pipeline 不會因單一筆髒資料而崩潰 |

### 9.3 Delta Lake 內部機制與維護

**交易日誌 (`_delta_log`)**：理解 Delta 如何透過 JSON Commit 檔案與 Parquet Checkpoint 檔案來實現 ACID。

#### VACUUM 與 Time Travel

| 項目 | 說明 |
|------|------|
| **預設保留期** | 7 天 |
| **安全機制** | 嘗試執行 `VACUUM RETAIN 0 HOURS` 系統會報錯 |
| **繞過檢查** | 設置 `spark.databricks.delta.retentionDurationCheck.enabled = false`（生產環境不建議） |

#### 樂觀並發控制

當兩個作業同時寫入同一分區時，需理解 `WriteSerializable` 與 `Serializable` 隔離級別的差異，以及如何透過重試機制解決 `ConcurrentModificationException`。

---

## 10. 新增考試主題

### Delta Sharing & Federation

使用 Databricks-to-Databricks Delta Sharing (D2D) 與開放協議分享到其他平台 (D2O) 的安全資料共享。這些概念在舊版考試中不存在。

### Autoloader 與現代串流

新版考試明確對比 **Spark Structured Streaming** 與 **Lakeflow pipelines** 在串流攝取的差異，強調較新的串流範式。

### 資料隱私機制

除了舊有的「dynamic views」，新版考試還測試 **row-level security（列級安全）** 與 **column masking（欄位遮罩）** 功能，以及 PII 的匿名化/代碼化方法。