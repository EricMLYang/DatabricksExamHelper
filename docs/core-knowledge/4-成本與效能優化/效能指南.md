Databricks 上的效能監控、調整與優化指南
在大規模資料處理環境中，效能調校是確保工作負載順暢和節省成本的關鍵課題。Databricks 以 Apache Spark 為核心，在雲端上提供便捷的資料處理平台，但隨著資料量和工作負載複雜度提高，常會遇到各種效能瓶頸。本文針對具備 Databricks 操作經驗和中等 Spark 架構理解的讀者，說明如何監控效能、解讀關鍵指標，並介紹常見的調校技巧與避免反模式的實務建議（內容反映截至 2026 年 Databricks 的最新功能與趨勢）。
常見的效能瓶頸來源
在 Databricks 執行 Spark 工作負載時，以下是幾個常見的效能瓶頸來源：
大量 Shuffle 資料交換：Shuffle（俗稱「洗牌」）是 Spark 在執行 Join、GroupBy 這類寬依賴轉換時將資料重新分區的過程
。Shuffle 涉及節點間的大量網路資料傳輸與磁碟 I/O，開銷昂貴，常成為效能瓶頸
。尤其當進行大型表連接（Sort-Merge Join）或聚合時，如果預設的分區數不足，單個分區資料過大，就會導致 Shuffle 階段耗時長、Shuffle Read/Write 數據量巨大
。這不但拉長執行時間，也可能引發節點記憶體壓力。
資料傾斜 (Data Skew)：當某些 Key 對應的資料量遠大於其他 Key 時，就會出現資料傾斜問題。結果是執行該 Key 的某個 Task 需要處理大量資料，而其他 Tasks 很快完成，導致整個 Stage 被少數慢節點拖延
。症狀通常是在 Spark UI 中觀察到某些 Task 的執行時間遠高於同 Stage 其他 Tasks
。常見於某欄位值高度集中（例如某熱門ID出現頻率極高）或不平均分佈的 Join/聚合。資料傾斜會使並行處理失衡，導致整體運行時間大幅延長。
記憶體不足與 Spill：當 Driver 或 Executor 記憶體配置不足以容納 Shuffle、Join 等操作的中間結果時，Spark 會將溢出的資料寫入磁碟（spill）
。記憶體溢出 (Spill) 的症狀是作業期間磁碟I/O頻繁，Shuffle 階段讀寫發生大量磁碟寫入/讀取
。由於磁碟速度比記憶體慢兩個數量級以上，spill 會極大降低效能；一旦開始大量 spill，任務執行速度會急遽下降
。常見原因包括：Executor 記憶體配置太小無法支撐巨大 shuffle/join 結果、分區設定不當導致單一 Task 處理資料量過大（例如 200 個 Shuffle 分區卻處理 500GB，平均每分區2.5GB，單個 Task 記憶體壓力沉重）
。如果 Spark UI 的 Stage 詳細資訊裡看到 Spill (Memory Spill/Disk Spill) 指標不為零，就表示發生了 spill，應予以關注與調整
。
叢集資源配置不當：Driver/Executor 資源不足或規格不當也會引發效能問題。一方面，叢集算力過低（如 CPU 核心太少）導致長時間排隊等待資源，或 CPU 使用率長期100%飽和，使任務執行變慢
。另一方面，過度提升叢集規格（大量閒置資源）則徒增成本且對速度幫助有限。正確的做法是根據 Spark UI Executors 頁籤觀察 CPU 利用率：接近100%且任務耗時長，可考慮擴充節點或升級機型；反之如果大部分時間 CPU 閒置，叢集過大就浪費資源
。Driver 節點資源不足則可能表現在 Driver OOM 或過慢（例如誤用 .collect() 將巨量資料拉回 Driver）。總之，未能根據工作負載調整叢集大小會導致效能不佳或成本浪費。
I/O 瓶頸（慢速儲存或小檔案過多）：雲端儲存（如 S3、Azure Data Lake）延遲相對高，因此第一次讀取大量資料通常較慢。Databricks 提供機制緩存近期讀取的資料塊，但冷啟動時常見「第一輪查詢慢，第二輪明顯較快」的現象
。此外，若資料以大量小檔案存放，作業需開啟、關閉非常多檔案，產生顯著開銷
。這被稱為 小檔案問題，會導致 Spark 在檔案列表、開檔上耗費大量時間而不是真正的資料處理。未經優化的資料佈局（如無分區、無排序）也會使查詢無法有效跳過不相關資料，出現不必要的全表掃描。
上述瓶頸往往同時存在或相互影響。例如，資料傾斜會導致部分任務需要處理巨量資料，不得不 spill 到磁碟；小檔案過多會拖慢讀取，進而拉長 Shuffle 等操作的整體耗時。因此，我們需要結合監控工具來辨識瓶頸所在，再採取適當的調校措施。
實用的效能監控工具與指標
Databricks 提供多種工具來監控Spark 作業與叢集資源，以下是常用的幾種及其指標：
Spark UI：Spark UI 是 Spark 內建的網頁介面，能深入呈現 Jobs/Stages/Tasks 的執行細節
。在 Databricks 上，每當提交一個作業（例如 notebook cell），可透過連結開啟 Spark UI 查看當前作業進度。Spark UI 的 Jobs 頁籤概覽各任務的階段（Stage）數量、每個 Stage 的任務數與執行時間
。Stages 頁籤則提供更細節的資料，包括每個 Stage 的輸入/輸出資料量、Shuffle Read/Write 大小、Task 執行時間分佈、記憶體與磁碟溢寫量等資訊，方便診斷問題
。透過 Spark UI，我們可以直觀定位最耗時的 Stage，以及觀察 Task 的分佈是否均勻、是否存在資料傾斜或記憶體溢寫等現象
。
Ganglia 叢集監控：Ganglia 是一套分散式系統的資源監控工具，Databricks 傳統上整合 Ganglia 來監控叢集的 CPU、記憶體、網路和磁碟使用情況
。在 Databricks 的叢集頁面可找到 Ganglia 儀表板，觀察整體資源走向。例如，利用 Ganglia 圖表可以發現整個叢集的 CPU 使用率是否長期接近飽和、記憶體是否耗盡導致頻繁 GC，或者網路流量是否在 Shuffle 階段達到峰值。這些指標有助於判斷瓶頸是在計算還是 I/O 層面：如果 CPU 長期100%，可能計算成為瓶頸；反之 CPU 很低而任務仍慢，可能是在等待 I/O 或資料分佈不均。需要注意的是，Databricks Runtime 13.x 以後引入更新的叢集監控介面，取代舊的 Ganglia Dashboard
。但無論介面如何，更重要是解讀那些資源利用率曲線，以輔助調整叢集規模和設定。
Query History 與 Query Profile（Photon Profiler）：Databricks 提供了 查詢歷史 介面來追蹤過去執行的 SQL 查詢（特別是在 Databricks SQL Warehouse 或筆記本中使用 Photon 引擎時）。在 Query History 中點選某個查詢，可看到該查詢的詳細資訊，包括執行時間、掃描的資料量、輸出行數等
。更進一步的利器是 Query Profile（又稱 Photon Profiler），它以視覺化方式呈現查詢執行的詳細計畫與效能資料
。Query Profile 會顯示查詢的 DAG（有向無環圖），圖中各節點代表查詢中的運算元（如資料掃描、過濾、Join、Shuffle 等）並標註每個運算所耗費的時間、處理的資料列數、記憶體峰值等
。藉由 Query Profile，使用者可以一目了然識別查詢執行中最耗時的部分，並檢視每個運算元的資源使用情形，以協助調整查詢或資料模型
。特別在 Photon 引擎加速的環境下，Query Profile 能將傳統 Spark 內部看不到的一些 C++ Vectorized Engine 操作也可視化呈現。有了 Query Profile，我們能發現像是資料爆炸（例如不小心產生過多列）或未利用索引導致的全表掃描等問題
。在 Databricks SQL 查詢頁面或 Notebook 結果下方通常可以找到 “See query profile” 或 “查看效能” 的連結來開啟這個分析視圖。

https://docs.databricks.com/aws/en/sql/user/queries/query-profile
Databricks 的 Query Profile 工具提供查詢執行計畫的可視化 DAG。在上圖範例中，各個節點代表不同的運算操作（Scan、Shuffle、Join 等），並附帶時間消耗、處理列數和記憶體峰值等指標。透過這種視覺化分析，使用者可以快速定位查詢的最慢部分，針對性地進行優化
。 值得一提的是，Query Profile 與 Spark UI 是相輔相成的：前者偏重於查詢計畫與操作層級的分析，而後者則可深入到Spark 低階執行（Stages/Tasks）的細節。Databricks 允許在 Query Profile 介面直接點選 Open in Spark UI，跳轉到對應 Spark 作業的執行詳情
。綜合運用這些工具，我們可以從叢集資源耗用、作業階段瓶頸、直到查詢計畫優化各層面，全方位監控效能。
解讀 Spark UI 關鍵資訊
掌握 Spark UI 中呈現的關鍵指標，有助於我們迅速找出性能問題所在。以下說明在 Spark UI 中幾項重要資訊的解讀方式：
Stage DAG 與執行序列：每當提交一個 Spark 作業時，Spark 會將它切分成一系列的 Stage（階段）。Stage DAG 是 Spark UI Job 頁面上展示的有向無環圖，它描述了各階段的執行順序和依賴關係
。從 DAG 上可以看到哪些 Stage 串接在一起，以及哪些地方存在 Shuffle 邊界（通常Stage切分處即表示有資料重新分區發生）。透過 DAG，我們能判斷整個作業的拓撲：例如先讀取資料 -> 經過某些轉換 -> Shuffle -> 接著另一階段聚合。若某個 Stage 尤其耗時，可在 DAG 中將其標註出來，作為重點優化對象。同時，DAG 也揭示了並行度：例如上游一個 Stage 完成後才能觸發下游 Stage。瞭解 DAG 架構有助於分析哪一步驟最可能成為瓶頸階段（如涉及資料匯總的大型 Shuffle）並對症下藥。
Task 時間分佈與資料傾斜：點進 Spark UI 的某個 Stage，可以查看該 Stage 所有 Tasks 的統計資訊，包括每個 Task 執行時間、處理資料量等。關注Task Duration的分佈（Spark UI 會顯示最長、最短、平均執行時間），若最大 Task 時間遠高於平均值，則高度懷疑該 Stage 出現資料傾斜
。例如，在100個 Tasks 中有1個跑了幾十分鐘而其他都幾秒結束，表示該 Task 負載明顯過重
。我們可以點選該 Stage 的 Summary 來查看各 Task 的輸入、輸出和 Shuffle 讀寫量，常會發現那個異常緩慢的 Task 處理了極大份量的資料（例如 Shuffle Read 非常大），印證資料傾斜的存在。此時應思考如何改善資料分佈，如後續章節討論的重新分區或傾斜鍵特殊處理。反之，如果所有 Task 都緩慢且耗時相近，則可能是整體計算量大或資源不足，需要從其它方面著手。
Shuffle Read/Write 及資料量指標：Spark UI 每個 Stage 的摘要裡列出了 Shuffle Read 和 Shuffle Write 大小，代表該階段讀取和寫出到下一階段的資料量。這些指標可以揭示資料移動成本：Shuffle Write 大幅增加表示此 Stage 輸出了遠超過輸入的資料量，可能發生了資料膨脹（data explosion）
。例如使用不當的 explode() 轉換或某些 Join 產生了預期外的大量列
。Shuffle Read 若數值龐大且耗時長，則下游 Stage 在網路接收大量資料，確認 Shuffle 是主要瓶頸
。比較 Shuffle Read 與 Write 還可推測 Stage 之間資料減少或增加的情況，幫助判斷是否有多餘的資料在 pipeline 中流動。除了 Shuffle 數據量，Spark UI 也顯示每個 Stage 的 Input Size（輸入資料量）及 Output Records（輸出列數）。透過這些，我們可以發現有無全表掃描（例如輸入數據非常大但其實很多不需要）、或者 Join 後資料量是否出現爆炸性成長。總的來說，Shuffle 和資料量相關指標讓我們量化每步操作的開銷，定位資料流動是否有效率。
記憶體與 Spill 狀況：在 Stage 詳情中，我們也能看到每個 Task 的記憶體使用和 spill 指標。如果出現 Disk Spill 或 Memory Spill 的計數，表示該 Stage 有任務因記憶體不足而將部分資料寫入磁碟
。例如某 Stage 顯示「Spill (Memory) = 5.0 GB」，那麼可以確定有嚴重的記憶體壓力導致溢寫。此時除了增大節點記憶體或調整佈建，也應檢查是否分區過少導致每個 Task 處理資料過多
。Spark UI 的 Executor 頁籤亦提供每個節點 JVM 記憶體、儲存記憶體使用情況以及 GC 時間等資訊。如果看到 GC 時間佔比較高（例如超過總執行時間的15%以上），意味著 JVM 為釋放記憶體頻繁停頓，這將嚴重影響效能
。總之，透過 Spark UI 的這些記憶體相關指標，可以判斷是否需要調高記憶體、調整分區或利用其它手段（如 Photon 引擎減少 JVM 記憶體負擔
）來降低溢寫發生。
綜合上述，Spark UI 提供從宏觀階段到微觀任務的詳盡效能數據。我們應養成習慣在作業完成或出現異常時，仔細瀏覽相關的 Spark UI 頁面，因為「數據不會說謊」——任一瓶頸都會在某些指標上留下蛛絲馬跡。例如，一個 Shuffle Stage 極慢往往伴隨巨大的 Shuffle Read/Write；資料傾斜必然反映在 Task 耗時分佈極不均；記憶體不足則可從 spill 和 GC 痕跡辨識出來。懂得解讀這些關鍵資訊，是進一步調校優化的基礎。
常見調校技巧
在確認了效能瓶頸的來源後，我們可以採取多種調校與優化手段來改善 Databricks 上 Spark 作業的效能。以下介紹幾種常見且實用的技巧：
使用 Broadcast Join：針對需要 Join 的作業，若其中一個資料集相對很小（例如小於數百MB級別），可採用 廣播連接 (Broadcast Join) 來避免大型 Shuffle
。Spark 的 Catalyst Optimizer 會在預設條件下自動將小表廣播到各 Executor，以用 Broadcast Hash Join 替代耗費昂貴的 Sort-Merge Join。廣播後，大表按照小表的 key 進行本地比對，不需要全網 Shuffle。調校上，可以透過設定 spark.sql.autoBroadcastJoinThreshold 閾值或使用 DataFrame API 的 broadcast() 提示來控制廣播行為。例如，當某維度表只有數百MB而事實表數十GB時，啟用 Broadcast Join 通常能大幅降低 Join 耗時
。但要注意廣播表仍會佔用每個節點記憶體，因此不能過大。總體而言，廣播小表、Shuffle 大表是優化 Join 的黃金法則，在保證單機放得下小表的前提下應盡量利用，以換取線性加速效果。
調整分區並行度：正確的分區數 (parallelism) 對效能至關重要。如果分區過少，每個 Task 要處理的資料太多，容易導致任務時間過長甚至記憶體溢出
；反之，分區過多又會讓大量 Task 處理很小的資料塊，引入不必要的排程和 I/O 開銷
。Spark 3 已支援 Adaptive Query Execution (AQE) 自動調整 Shuffle 分區數，但在某些情況下我們仍需手動調校。例如，Spark SQL 預設 spark.sql.shuffle.partitions=200，對少量資料來說可能過高（應減少分區以免大量小任務）
；對極大量資料又偏低（應增加分區以避免每分區資料過大）
。實務做法是根據資料量逐步嘗試不同分區值，觀察 Spark UI 上 Task 的大小和耗時變化，找到恰當的分區數
。例如，一個500GB的 shuffle 從200分區提高到1000分區，使每個分區從2.5GB降至0.5GB，大幅減少了 spill
。除了 Shuffle 分區，針對讀取資料時也可考慮使用 repartition() 或 coalesce() 來調整初始分區數，以平衡叢集負載。總之，分區調整的目標是在 Task 大小與 Task 數量間取得平衡，使每個 Task 的工作量既不至過大造成瓶頸，也不至過小造成浪費。
善用 Photon 引擎：Photon 是 Databricks 自行研發的向量化查詢引擎，以 C++實作並深度整合於 Databricks Runtime 中，可顯著加速 SQL 和 DataFrame 操作。Photon 將資料處理改為向量化批次模式，充分利用現代 CPU 的 SIMD 平行能力，以實現比傳統 Spark JVM 內逐列處理快2～10倍的效能
。在啟用 Photon 後，許多 SQL 聚合、Join、掃描操作都能獲得數倍加速，尤其資料量愈大收益愈明顯。例如官方案例中，一個沒有 Photon 需45分鐘的多表聚合查詢，開啟 Photon 後縮短為6～8分鐘
。此外，由於 Photon 移除了 JVM GC 和序列化開銷，採用更高效的記憶體資料結構，實務觀察可減少約20～40%的記憶體使用
。這意味著在記憶體吃緊導致 spill 的作業中，Photon 常能緩解壓力
。使用 Photon 的場合包括：大型 ETL 批次處理、複雜 SQL 分析查詢（多重 Join 和聚合）、以及主要針對 Delta/Parquet 表的操作等
。反之，一些不適合 Photon 的情況則有：大量使用 RDD 低階 API 的工作（Photon 僅優化 DataFrame/Dataset）、高度依賴 Python UDF 的作業（UDF 在 Python 執行，Photon 無法加速）
。因此，建議將 Photon 策略性部署在對象量大且 SQL/資料幀密集的工作負載上，以發揮其最大價值。如在 Databricks SQL Warehouse 中，Photon 引擎通常預設開啟；在自建叢集上也可於建立叢集時勾選啟用 Photon。但切忌盲目全部啟用（因每單位計算成本略增），而應優先用於能 明顯縮短時間 的任務上，以獲得最佳的成本效益
。
合理運用 Cache/Persist：Spark 提供快取 (cache/persist) 機制，允許將中間結果緩存在記憶體或磁碟，以避免重複計算。正確運用快取可以大幅節省多次使用同一資料集時的時間開銷。然而，快取也不是越多越好：過度或不當的快取反而可能拖慢作業。一般建議只有當某個中間結果會被多次重用時再考慮 cache/persist
；若僅後續使用一次，快取只會額外增加一次計算與存儲開銷。使用快取時要選擇適當的儲存等級（Storage Level）：預設的 MEMORY-ONLY 對記憶體需求最高，但效能最佳；如資料較大可考慮 MEMORY_AND_DISK 允許溢出磁碟；而極大的資料集也許根本不適合快取。務必確保快取的資料能放入叢集總記憶體，否則會引發頻繁的資料淘汰和重新計算，適得其反。另外一個技巧是在長工作流程中，當某階段快取結果不再需要時，記得調用 unpersist() 釋放快取，避免佔據寶貴的記憶體資源。總之，快取策略的核心是在重用與資源之間權衡：明智地快取高重用、小體積的資料集，能換取顯著的迴圈計算加速；反之胡亂快取大型資料不但無益，還會壓垮叢集效能
。
其他優化技巧：除了上述要點，還有一些值得注意的調校實踐：
啟用 AQE (Adaptive Query Execution)：Spark 3 的 AQE 能動態優化查詢計劃，例如自動調整 Shuffle 分區數、改變 Join 策略（如在執行時決定是否採用 Broadcast Join）以及對傾斜分區進行拆分
。Databricks Runtime 預設已開啟 AQE，但務必確認 spark.sql.adaptive.enabled=true
。AQE 能在不修改程式的情況下幫助解決不少 shuffle 和傾斜問題。
資料讀取優化：盡量利用資料來源的預過濾 (Predicate Pushdown) 和欄位裁剪能力，讓查詢只讀取必要的資料列與欄位
。例如 Parquet/Delta 格式支援按照查詢條件自動略過不相關的檔案或分區，減少 IO。務必在讀取前就篩選資料（如 .filter 盡早執行），而非把所有資料讀進來再在 Spark 層面過濾
。這能減少下游處理的資料量，對整體效能有直接幫助。
資料佈局與索引：對於大型資料表，善用 分區 (Partitioning) 或 Z-Order 優化 來改善查詢性能。如果經常根據某欄位篩選資料，考慮將該欄作為分區鍵或使用 Delta Lake 的 Z-ORDER 讓相關資料儲存在一起，減少掃描範圍
。另外，Databricks 推出的 Liquid Clustering（動態分區聚合）功能可在不中斷資料寫入的情況下自動維護資料的分散度與順序
。良好的資料佈局能讓查詢只關注有效的資料區塊，避免不必要的掃描和 Shuffle。
透過以上各種調校技巧的組合運用，我們通常可以針對不同類型的瓶頸採取對應的措施。例如，對小表大表 Join 問題同時採取「提前過濾 + 廣播小表 + 提高分區數降低單機負載」，對 spill 嚴重的作業則考慮「啟用 Photon + 增加記憶體 + 調整 shuffle 分區」，等等。在進行優化時，建議一次只改動一兩項參數或策略並觀察效果，透過 Spark UI/Query Profile 的指標變化來驗證調整是否奏效，逐步逼近最佳設定。
實務建議與反模式
最後，我們總結一些 Databricks/Spark 效能調校的實務建議，以及常見的反模式（不良做法）需避免：
避免過度快取 (Over-caching)：一個常見反模式是在流程中不加分析地對多個中間結果呼叫 cache()，以為「先算一次存起來」總是有益。然而過度快取會導致記憶體資源被大量佔用，甚至引發頻繁的 JVM GC 和記憶體溢位，反而拖慢計算
。正確的做法是有的放矢：僅對確實重複使用多次且計算昂貴的資料集進行快取，並確保叢集有足夠空間容納它。對一次性使用的資料決不要快取，對超大型資料集要慎重考慮（也許透過重新計算更實際）。此外，如果快取了不再使用的資料集，務必及時 unpersist()。總之，「快取不是越多越好」，而是需要整體權衡的工具。
大型表 Join 的錯誤打開方式：在對兩個大型資料表進行 Join 時，一些錯誤模式會嚴重影響效能。其一是未預先過濾資料就直接 Join。例如事實表和維度表各十億行，如果可以在 Join 前先用 where 條件各篩掉90%的不相關資料，那麼千萬別等 Join 後再過濾。先過濾可讓 Join 輸出行數大減少，節省後續大量計算
（一項經驗分享中，團隊在 Join 前增加過濾，使 Join 結果行數減少了90%，直接提升了效能
）。其二是當一方明明很小卻沒利用 Broadcast，導致不必要的 Shuffle。遇到這種情況應參考上節廣播連接技巧。其三是沒有考慮資料傾斜的 Join。例如用低選擇性的欄位（cardinality 很低）進行 Join，會導致少數幾個 Key 匯聚巨大資料。這種情況下一定要採取對策，如使用 Spark 提供的 Skew Join Hint 或人工為傾斜 Key 做 Salting（加鹽拆分）
。大型表 Join 可以說是 Spark 作業中最耗資源的操作之一，但透過正確順序（先過濾再Join）、選擇適當鍵、善用廣播等手段，可以極大緩解其對效能的影響。
盲目調高叢集規格：當作業效能不理想時，第一反應往往是「加大叢集」或「給更多資源」。然而，盲目地升級 VM 規格或節點數量不一定解決問題，反而可能只是燒錢且收效甚微。首先，找出瓶頸所在非常重要：如果問題在於資料傾斜或程式寫法低效，就算叢集翻倍大，依然會有某個 Task 得處理傾斜資料導致整體變慢，或者 CPU 大部分時間在等待 I/O。其次，叢集過大也有邊際效益遞減問題，Spark 的併行度並非無限制線性擴展
。大量節點也帶來調度開銷，對小規模資料反而可能變慢
。因此，建議先透過 Spark UI 和 Ganglia 檢視資源利用率
：如果確定 CPU 已100%且無明顯其他瓶頸，可以考慮垂直或水平擴充一些；若 CPU 很空閒但作業仍慢，表示瓶頸在計算以外（可能是等待資料或鎖），加資源無濟於事。更好的方法是啟用 自動縮放 (Autoscaling) 讓叢集根據負載彈性擴容縮容
。總之，不要把升級硬體當作萬靈丹，在釐清問題前盲目加資源通常事倍功半，而且容易掩蓋根本問題。
其他反模式：還有一些需要避免的習慣：
亂調參數：Spark 有許多參數可以調整，但一次改動太多或隨意設置極端值，可能導致不可預期的效果。應根據觀察與理論依據調參，而非病急亂投醫。特別是 memory, core 數, partition 數等，要平衡設定。
忽視資料問題：有時效能不好不是 Spark 本身設定問題，而是資料質量或模型問題。例如數據包含大量小檔案卻未合併、無效數據過多未過濾、或者上游重複寫入導致同一計算重覆等等。優化時要從資料源頭改善，技術調校只能救一部分瓶頸。
將 Python 端計算用於大量資料：在 Databricks 使用 PySpark 時，如果在 driver 上用 Python 原生處理大量資料（例如用 collect() 拉回本地做計算），會失去分散式的優勢並拖垮 driver。應盡量把計算邏輯下推到 Spark 的分散式計算框架內（使用 Spark UDF、SQL 等），避免過多的 driver 本地計算。
總而言之，做好效能優化需要全面的觀察與適當的取捨。善用 Databricks 提供的各種監控工具（Spark UI、Ganglia、新版查詢分析器等）來定位瓶頸，再針對問題選擇恰當的優化策略（從調參到改寫SQL，再到增減資源），才能有效提升作業表現。同時保持對最新功能的關注，例如 Photon 引擎、Delta Lake 的優化特性等，這些都可能為效能帶來突破性的提升。避免落入反模式的陷阱，多參考實務經驗與最佳做法，在 Databricks 上你將能駕馭各種規模的資料工作負載，達到事半功倍的效能表現！
 參考資料: Databricks 官方文件與部落格
、真實使用經驗分享
以及 Spark 最佳實踐文獻等。以上內容希望能為您在 Databricks 上的效能監控與優化提供全面的指引。祝您在大數據的旅程中乘風破浪，讓效能問題不再成為前進路上的絆腳石！